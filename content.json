{"meta":{"title":"青山","subtitle":"青山の博客","description":"本科 | 计算机科学与技术 ","author":"青山","url":"https://macongmc.github.io","root":"/"},"pages":[{"title":"404","date":"2019-08-10T08:41:10.000Z","updated":"2022-07-24T04:15:35.448Z","comments":true,"path":"404.html","permalink":"https://macongmc.github.io/404.html","excerpt":"","text":""},{"title":"","date":"2022-07-24T04:15:35.513Z","updated":"2022-07-24T04:15:35.513Z","comments":true,"path":"baidu_verify_xxxxxxx.html","permalink":"https://macongmc.github.io/baidu_verify_xxxxxxx.html","excerpt":"","text":"wvlc3L96QK"},{"title":"about","date":"2019-10-24T16:00:00.000Z","updated":"2022-07-24T04:15:35.513Z","comments":true,"path":"about/index.html","permalink":"https://macongmc.github.io/about/index.html","excerpt":"","text":""},{"title":"","date":"2022-07-24T04:15:35.513Z","updated":"2022-07-24T04:15:35.513Z","comments":true,"path":"google1xxxxxxx0.html","permalink":"https://macongmc.github.io/google1xxxxxxx0.html","excerpt":"","text":"google-site-verification: google110e5e5e14c8dcf0.html"},{"title":"archives","date":"2019-10-24T16:00:00.000Z","updated":"2022-07-24T04:15:35.513Z","comments":true,"path":"archives/index.html","permalink":"https://macongmc.github.io/archives/index.html","excerpt":"","text":""},{"title":"留言板","date":"2019-10-24T16:00:00.000Z","updated":"2022-07-24T06:48:47.115Z","comments":true,"path":"contact/index.html","permalink":"https://macongmc.github.io/contact/index.html","excerpt":"","text":"畅所欲言 在这里可以留下你的足迹，欢迎在下方留言，欢迎交换友链，一起交流学习！ 友链 青山の友链信息 博客名称: 青山の博客 博客网址: http://82.157.254.101/ 博客头像: https://s1.ax1x.com/2020/05/17/YRWsYT.png 博客介绍: 越努力，越幸运！"},{"title":"统计","date":"2020-10-31T02:11:28.000Z","updated":"2022-07-24T04:15:35.513Z","comments":true,"path":"census/index.html","permalink":"https://macongmc.github.io/census/index.html","excerpt":"","text":""},{"title":"友链","date":"2019-07-19T08:42:10.000Z","updated":"2022-07-24T04:15:35.513Z","comments":true,"path":"friends/index.html","permalink":"https://macongmc.github.io/friends/index.html","excerpt":"","text":""},{"title":"资源分享","date":"2019-07-19T08:40:27.000Z","updated":"2022-07-24T04:15:35.513Z","comments":true,"path":"resource/index.html","permalink":"https://macongmc.github.io/resource/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-10-24T16:00:00.000Z","updated":"2022-07-24T04:15:35.513Z","comments":true,"path":"categories/index.html","permalink":"https://macongmc.github.io/categories/index.html","excerpt":"","text":""},{"title":"放松一下","date":"2019-08-10T08:41:10.000Z","updated":"2022-07-24T04:15:35.460Z","comments":true,"path":"List/index.html","permalink":"https://macongmc.github.io/List/index.html","excerpt":"","text":"影音资源共享"},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2022-07-24T04:15:35.461Z","comments":true,"path":"List/tools/index.html","permalink":"https://macongmc.github.io/List/tools/index.html","excerpt":"","text":""},{"title":"相册","date":"2022-07-24T04:15:35.454Z","updated":"2022-07-24T04:15:35.454Z","comments":true,"path":"List/galleries/index.html","permalink":"https://macongmc.github.io/List/galleries/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2022-07-24T04:15:35.460Z","comments":true,"path":"List/music/index.html","permalink":"https://macongmc.github.io/List/music/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-07-19T08:40:27.000Z","updated":"2022-07-24T04:15:35.513Z","comments":true,"path":"tags/index.html","permalink":"https://macongmc.github.io/tags/index.html","excerpt":"","text":""},{"title":"视频","date":"2019-08-10T08:41:10.000Z","updated":"2022-07-24T04:15:35.460Z","comments":true,"path":"List/movies/index.html","permalink":"https://macongmc.github.io/List/movies/index.html","excerpt":"","text":""},{"title":"动漫风景","date":"2022-07-24T04:15:35.456Z","updated":"2022-07-24T04:15:35.456Z","comments":true,"path":"List/galleries/动漫风景/index.html","permalink":"https://macongmc.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""},{"title":"乖巧小狗","date":"2022-07-24T04:15:35.455Z","updated":"2022-07-24T04:15:35.455Z","comments":true,"path":"List/galleries/乖巧小狗/index.html","permalink":"https://macongmc.github.io/List/galleries/%E4%B9%96%E5%B7%A7%E5%B0%8F%E7%8B%97/index.html","excerpt":"","text":""},{"title":"动漫人物","date":"2022-07-24T04:15:35.455Z","updated":"2022-07-24T04:15:35.455Z","comments":true,"path":"List/galleries/动漫人物/index.html","permalink":"https://macongmc.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E4%BA%BA%E7%89%A9/index.html","excerpt":"","text":""},{"title":"二次元风","date":"2022-07-24T04:15:35.455Z","updated":"2022-07-24T04:15:35.455Z","comments":true,"path":"List/galleries/二次元风/index.html","permalink":"https://macongmc.github.io/List/galleries/%E4%BA%8C%E6%AC%A1%E5%85%83%E9%A3%8E/index.html","excerpt":"","text":""},{"title":"炫酷跑车","date":"2022-07-24T04:15:35.458Z","updated":"2022-07-24T04:15:35.458Z","comments":true,"path":"List/galleries/炫酷跑车/index.html","permalink":"https://macongmc.github.io/List/galleries/%E7%82%AB%E9%85%B7%E8%B7%91%E8%BD%A6/index.html","excerpt":"","text":""},{"title":"清新花卉","date":"2022-07-24T04:15:35.458Z","updated":"2022-07-24T04:15:35.458Z","comments":true,"path":"List/galleries/清新花卉/index.html","permalink":"https://macongmc.github.io/List/galleries/%E6%B8%85%E6%96%B0%E8%8A%B1%E5%8D%89/index.html","excerpt":"","text":""},{"title":"甜美食品","date":"2022-07-24T04:15:35.459Z","updated":"2022-07-24T04:15:35.459Z","comments":true,"path":"List/galleries/甜美食品/index.html","permalink":"https://macongmc.github.io/List/galleries/%E7%94%9C%E7%BE%8E%E9%A3%9F%E5%93%81/index.html","excerpt":"","text":""},{"title":"城市风光","date":"2022-07-24T04:15:35.457Z","updated":"2022-07-24T04:15:35.457Z","comments":true,"path":"List/galleries/城市风光/index.html","permalink":"https://macongmc.github.io/List/galleries/%E5%9F%8E%E5%B8%82%E9%A3%8E%E5%85%89/index.html","excerpt":"","text":""},{"title":"动漫插画","date":"2022-07-24T04:15:35.456Z","updated":"2022-07-24T04:15:35.456Z","comments":true,"path":"List/galleries/动漫插画/index.html","permalink":"https://macongmc.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/index.html","excerpt":"","text":""},{"title":"璀璨星空","date":"2022-07-24T04:15:35.459Z","updated":"2022-07-24T04:15:35.459Z","comments":true,"path":"List/galleries/璀璨星空/index.html","permalink":"https://macongmc.github.io/List/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/index.html","excerpt":"","text":""},{"title":"自然风景","date":"2022-07-24T04:15:35.460Z","updated":"2022-07-24T04:15:35.460Z","comments":true,"path":"List/galleries/自然风景/index.html","permalink":"https://macongmc.github.io/List/galleries/%E8%87%AA%E7%84%B6%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""},{"title":"呆萌猫咪","date":"2022-07-24T04:15:35.457Z","updated":"2022-07-24T04:15:35.457Z","comments":true,"path":"List/galleries/呆萌猫咪/index.html","permalink":"https://macongmc.github.io/List/galleries/%E5%91%86%E8%90%8C%E7%8C%AB%E5%92%AA/index.html","excerpt":"","text":""}],"posts":[{"title":"docker（一）","slug":"docker","date":"2023-02-06T01:50:53.000Z","updated":"2023-02-06T01:50:53.000Z","comments":true,"path":"posts/f255ffad.html","link":"","permalink":"https://macongmc.github.io/posts/f255ffad.html","excerpt":"","text":"一. docker 安装并启动1.1 CentOS安装Docker如果yum更新显示 Another app is currently holding the yum lock; waiting for it to exit... 则删除案例重新更新 rm -f /var/run/yum.pid 使用yum安装 # 安装yum工具 [root@localhost ~]# yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 --skip-broken # 设置docker镜像源 [root@localhost ~]#yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo sed -i 's/download.docker.com/mirrors.aliyun.com\\/docker-ce/g' /etc/yum.repos.d/docker-ce.repo [root@localhost ~]#yum makecache fast # 安装docker [root@localhost ~]yum install -y docker-ce # 关闭 [root@localhost ~]systemctl stop firewalld # 禁止开机启动防火墙 [root@localhost ~]systemctl disable firewalld #查看是否关闭防火墙 [root@localhost ~]systemctl status firewalld [root@localhost ~]# docker info # 启动docker、设置开机自启 [root@localhost ~]# systemctl start docker [root@localhost ~]# systemctl enable docker 设置镜像 yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo sed -i 's/download.docker.com/mirrors.aliyun.com\\/docker-ce/g' /etc/yum.repos.d/docker-ce.repo yum makecache fast 1.2配置镜像加速创建文件夹 sudo mkdir -p /etc/docker 输入 &gt; ##在文件夹内新建一个daemon.json文件 sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF' { \"registry-mirrors\": [\"https://akchsmlh.mirror.aliyuncs.com\"] } EOF 重新加载文件 sudo systemctl daemon-reload 重启docker sudo systemctl restart docker 二. 镜像常用命令2.1使用语法和参数[root@localhost ~]# docker image --help Usage: docker image COMMAND Manage images Options: --help Print usage Commands: build 从Dockerfile构建映像 history 显示image的历史 import 从压缩文件中导入内容以创建文件系统映像 inspect 显示一个或多个image的详细信息 load 从tar存档文件或STDIN加载映像 ls image列表 prune 删除未使用的image pull 从注册表中提取映像或存储库 push 将映像或存储库推入注册表 rm 删除一个或多个image save 保存一个或多个image到tar存档(默认流到STDOUT) tag 创建指向SOURCE_IMAGE的标签TARGET_IMAGE 2.2列表 -a列出所有镜像[root@localhost ~]# docker image ls -a 2.3删除镜像-froot@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos-7 latest 7e989e1e46e7 2 weeks ago 380 MB [root@localhost ~]# docker image rm -f 7e989 [root@base ~]# docker rmi b692 2.4dockerfile构建镜像Usage: docker image build [OPTIONS] PATH | URL | - Build an image from a Dockerfile Options: --build-arg list 设置构建时变量(默认[]) --cache-from stringSlice 将镜像视为缓存源 --cgroup-parent string 可选父容器cgroup --compress 使用gzip压缩构建上下文 --cpu-period int 限制CPU CFS(完全公平调度程序)周期 --cpu-quota int 限制CPU CFS(完全公平调度程序)配额 -c, --cpu-shares int CPU份额(相对权重) --cpuset-cpus string 允许执行的cpu(0-3、0、1) --cpuset-mems string 允许执行的MEMs (0- 3,0,1) --disable-content-trust 跳过图像验证(默认为true) -f, --file string Dockerfile的名称(默认为'PATH/Dockerfile') --force-rm 总是删除中间容器 --help Print usage --isolation string 容器隔离技术 --label list 设置image的元数据(默认[]) -m, --memory string 内存限制 --memory-swap string 交换限制等于内存加上交换:'-1'来启用无限交换 --network string 在构建期间为RUN指令设置网络模式(默认为\"default\") --no-cache 在构建映像时不使用缓存 --pull 总是尝试拉出更新版本的image -q, --quiet 关闭构建输出并在成功时打印image ID --rm 在成功构建后移除中间容器(默认为true) --security-opt stringSlice 安全选项 --shm-size string “/dev/shm”的大小，默认为64MB -t, --tag list 以' Name:tag'格式命名和可选的标记(default []) --ulimit ulimit Ulimit选项(默认[]) -v, --volume list 设置构建时绑定挂载(默认[]) 构建一个带有openssh-server的容器镜像 [root@localhost ~]# cat Dockerfile FROM centos:7 RUN yum install -y openssh-server sudo RUN sed -i 's/UsePAM yes/UsePAM no/g' /etc/ssh/sshd_config #RUN useradd admin #RUN echo \"admin:admin\" | chpasswd RUN echo \"root:123456\" | chpasswd #RUN echo \"admin ALL=(ALL) ALL\" &gt;&gt; /etc/sudoers RUN ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key RUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key RUN mkdir /var/run/sshd EXPOSE 22 CMD [\"/usr/sbin/sshd\", \"-D\"] [root@localhost ~]# docker build -t ssh-server . 2.5创建容器 docker runUsage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] 03. -d, --detach=false 指定容器运行于前台还是后台，默认为false 04. -i, --interactive=false 打开STDIN，用于控制台交互 05. -t, --tty=false 分配tty设备，该可以支持终端登录，默认为false 06. -u, --user=\"\" 指定容器的用户 07. -a, --attach=[] 登录容器（必须是以docker run -d启动的容器） 08. -w, --workdir=\"\" 指定容器的工作目录 09. -c, --cpu-shares=0 设置容器CPU权重，在CPU共享场景使用 10. -e, --env=[] 指定环境变量，容器中可以使用该环境变量 11. -m, --memory=\"\" 指定容器的内存上限 12. -P, --publish-all=false 指定容器暴露的端口 13. -p, --publish=[] 指定容器暴露的端口 14. -h, --hostname=\"\" 指定容器的主机名 15. -v, --volume=[] 给容器挂载存储卷，挂载到容器的某个目录 16. --volumes-from=[] 给容器挂载其他容器上的卷，挂载到容器的某个目录 17. --cap-add=[] 添加权限，权限清单详见：http://linux.die.net/man/7/capabilities 18. --cap-drop=[] 删除权限，权限清单详见：http://linux.die.net/man/7/capabilities 19. --cidfile=\"\" 运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法 20. --cpuset=\"\" 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU 21. --device=[] 添加主机设备给容器，相当于设备直通 22. --dns=[] 指定容器的dns服务器 23. --dns-search=[] 指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件 24. --entrypoint=\"\" 覆盖image的入口点 25. --env-file=[] 指定环境变量文件，文件格式为每行一个环境变量 26. --expose=[] 指定容器暴露的端口，即修改镜像的暴露端口 27. --link=[] 指定容器间的关联，使用其他容器的IP、env等信息 28. --lxc-conf=[] 指定容器的配置文件，只有在指定--exec-driver=lxc时使用 29. --name=\"\" 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字 30. --net=\"bridge\" 容器网络设置: 31. bridge 使用docker daemon指定的网桥 32. host //容器使用主机的网络 33. container:NAME_or_ID &gt;//使用其他容器的网路，共享IP和PORT等网络资源 34. none 容器使用自己的网络（类似--net=bridge），但是不进行配置 35. --privileged=false 指定容器是否为特权容器，特权容器拥有所有的capabilities 36. --restart=\"no\" 指定容器停止后的重启策略: 37. no：容器退出时不重启 38. on-failure：容器故障退出（返回值非零）时重启 39. always：容器退出时总是重启 40. --rm=false 指定容器停止后自动删除容器(不支持以docker run -d启动的容器) 41. --sig-proxy=true 设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理 2.6进入容器docker exec -it cd35b32c8c15 /bin/bash 三. docker 安装tomcat# 查看镜像 docker search tomcat # 默认最新 docker pull tomcat # 指定版本 docker pull tomcat:[tag] # 如拉取 tomcat 8 docker pull tomcat:8 # 运行 docker run -d -p 8080:8080 --name tomcat1 tomcat:8 测试 进入容器 docker exec -it cd35b32c8c15 /bin/bash 再次刷新 四. 安装mysql拉取镜像 docker pull mysql:5.7 run docker run --name mysql --restart=always -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql 五. 安装redis拉取镜像 docker pull redis run docker run --name redis --restart=always -p 6379:6379 -d redis --requirepass \"123456\" //启动Redis 六. 安装minio拉取 docker pull minio/minio run docker run -p 9000:9000 -p 9090:9090 \\ --name minio \\ -d --restart=always \\ -e \"MINIO_ACCESS_KEY=minioadmin\" \\ -e \"MINIO_SECRET_KEY=minioadmin\" \\ -v /mydata/minio/data:/data \\ minio/minio server \\ /data --console-address \":9090\" -address \":9000\" 七. 安装ES和kibana拉取 docker pull elasticsearch:7.2.0 docker pull kibana:7.2.0 run docker run --name elasticsearch --restart always -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e ES_JAVA_OPTS=\"-Xms200M -Xmx200M\" -d elasticsearch:7.2.0 解决es跨域问题 docker exec -it elasticsearch /bin/bash vi config/elasticsearch.yml 添加 http.cors.enabled: true http.cors.allow-origin: \"*\" 安装ik分词器 ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.2.0/elasticsearch-analysis-ik-7.2.0.zip 重启 docker restart elasticsearch 测试 http://192.168.200.142:9200/_analyze { \"analyzer\": \"ik_smart\", \"text\": \"我是中国人\" } 结果 { \"tokens\": [ { \"token\": \"我\", \"start_offset\": 0, \"end_offset\": 1, \"type\": \"CN_CHAR\", \"position\": 0 }, { \"token\": \"是\", \"start_offset\": 1, \"end_offset\": 2, \"type\": \"CN_CHAR\", \"position\": 1 }, { \"token\": \"中国人\", \"start_offset\": 2, \"end_offset\": 5, \"type\": \"CN_WORD\", \"position\": 2 } ] } run docker run --name kibana -e ELASTICSEARCH_URL=http://192.168.200.142:9200 -p 5601:5601 -d kibana:7.2.0 修改 docker exec -it kibana /bin/bash vi /config/kibana.yml 重启 docker restart kibana","categories":[{"name":"docker","slug":"docker","permalink":"https://macongmc.github.io/categories/docker/"}],"tags":[{"name":"容器","slug":"容器","permalink":"https://macongmc.github.io/tags/%E5%AE%B9%E5%99%A8/"}],"author":"马聪"},{"title":"Linux","slug":"Linux","date":"2023-01-10T06:42:39.000Z","updated":"2023-01-10T06:42:39.000Z","comments":true,"path":"posts/53d0684b.html","link":"","permalink":"https://macongmc.github.io/posts/53d0684b.html","excerpt":"","text":"linux入门一. linux固定ip进入配置页面vim /etc/sysconfig/network-scripts/ifcfg-ens33 配置样例 TYPE=\"Ethernet\" PROXY_METHOD=\"none\" BROWSER_ONLY=\"no\" BOOTPROTO=\"static\" DEFROUTE=\"yes\" IPV4_FAILURE_FATAL=\"no\" IPV6INIT=\"yes\" IPV6_AUTOCONF=\"yes\" IPV6_DEFROUTE=\"yes\" IPV6_FAILURE_FATAL=\"no\" IPV6_ADDR_GEN_MODE=\"stable-privacy\" NAME=\"ens33\" UUID=\"a47452cd-f124-445e-a700-77863a40c560\" DEVICE=\"ens33\" ONBOOT=\"yes\" IPADDR=\"192.168.200.141\" NETMAST=\"255.255.255.0\" GATEWAY=\"192.168.200.2\" DNS1=\"8.8.8.8\" DNS2=\"114.114.114.114\" PEERDNS=\"no\" ZONE=public 重启网卡 service network restart 二. 常用命令ll 查看文件列表 ll -lrt 文件列表按时间排序 grep -rl ERROR 查看错误日志 view 查看日志 shift +G 到最后一页 Ctrl + f：向下翻页快捷键(下一页) Ctrl + b：向上翻页快捷键(上一页) 关闭防火墙 # 关闭 systemctl stop firewalld # 禁止开机启动防火墙 systemctl disable firewalld #查看是否关闭防火墙 systemctl status firewalld grep -rl 交易日期不能为空","categories":[{"name":"Linux","slug":"Linux","permalink":"https://macongmc.github.io/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://macongmc.github.io/tags/linux/"}],"author":"马聪"},{"title":"elasticsearch","slug":"elasticsearch-0","date":"2022-09-21T12:21:25.000Z","updated":"2022-09-21T12:21:25.000Z","comments":true,"path":"posts/60537c10.html","link":"","permalink":"https://macongmc.github.io/posts/60537c10.html","excerpt":"","text":"安装elasticsearchGithub地址https://github.com/Macongmc/hotel-demo.git 1.部署单点es1.1.创建网络因为我们还需要部署kibana容器，因此需要让es和kibana容器互联。这里先创建一个网络： docker network create es-net 1.2.加载镜像这里我们采用elasticsearch的7.12.1版本的镜像，这个镜像体积非常大，接近1G。不建议大家自己pull。 课前资料提供了镜像的tar包： 大家将其上传到虚拟机中，然后运行命令加载即可： # 导入数据 docker load -i es.tar 同理还有kibana的tar包也需要这样做。 1.3.运行运行docker命令，部署单点es： docker run -d \\ --name es \\ -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\ -e \"discovery.type=single-node\" \\ -v es-data:/usr/share/elasticsearch/data \\ -v es-plugins:/usr/share/elasticsearch/plugins \\ --privileged \\ --network es-net \\ -p 9200:9200 \\ -p 9300:9300 \\ elasticsearch:7.12.1 命令解释： -e \"cluster.name=es-docker-cluster\"：设置集群名称 -e \"http.host=0.0.0.0\"：监听的地址，可以外网访问 -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"：内存大小 -e \"discovery.type=single-node\"：非集群模式 -v es-data:/usr/share/elasticsearch/data：挂载逻辑卷，绑定es的数据目录 -v es-logs:/usr/share/elasticsearch/logs：挂载逻辑卷，绑定es的日志目录 -v es-plugins:/usr/share/elasticsearch/plugins：挂载逻辑卷，绑定es的插件目录 --privileged：授予逻辑卷访问权 --network es-net ：加入一个名为es-net的网络中 -p 9200:9200：端口映射配置 在浏览器中输入：http://192.168.150.101:9200 即可看到elasticsearch的响应结果： 2.部署kibanakibana可以给我们提供一个elasticsearch的可视化界面，便于我们学习。 2.1.部署运行docker命令，部署kibana docker run -d \\ --name kibana \\ -e ELASTICSEARCH_HOSTS=http://192.168.200.141:9200 \\ --network=es-net \\ -p 5601:5601 \\ kibana:7.12.1 --network es-net ：加入一个名为es-net的网络中，与elasticsearch在同一个网络中 -e ELASTICSEARCH_HOSTS=http://es:9200\"：设置elasticsearch的地址，因为kibana已经与elasticsearch在一个网络，因此可以用容器名直接访问elasticsearch -p 5601:5601：端口映射配置 kibana启动一般比较慢，需要多等待一会，可以通过命令： docker logs -f kibana 查看运行日志，当查看到下面的日志，说明成功： 此时，在浏览器输入地址访问：http://192.168.150.101:5601，即可看到结果 2.2.DevToolskibana中提供了一个DevTools界面： 这个界面中可以编写DSL来操作elasticsearch。并且对DSL语句有自动补全功能。 3.安装IK分词器3.1.在线安装ik插件（较慢）# 进入容器内部 docker exec -it elasticsearch /bin/bash # 在线下载并安装 ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip #退出 exit #重启容器 docker restart elasticsearch 3.2.离线安装ik插件（推荐）1）查看数据卷目录安装插件需要知道elasticsearch的plugins目录位置，而我们用了数据卷挂载，因此需要查看elasticsearch的数据卷目录，通过下面命令查看: docker volume inspect es-plugins 显示结果： [ { \"CreatedAt\": \"2022-05-06T10:06:34+08:00\", \"Driver\": \"local\", \"Labels\": null, \"Mountpoint\": \"/var/lib/docker/volumes/es-plugins/_data\", \"Name\": \"es-plugins\", \"Options\": null, \"Scope\": \"local\" } ] 说明plugins目录被挂载到了：/var/lib/docker/volumes/es-plugins/_data 这个目录中。 2）解压缩分词器安装包下面我们需要把课前资料中的ik分词器解压缩，重命名为ik 3）上传到es容器的插件数据卷中也就是/var/lib/docker/volumes/es-plugins/_data ： 4）重启容器# 4、重启容器 docker restart es # 查看es日志 docker logs -f es 5）测试：IK分词器包含两种模式： ik_smart：最少切分 ik_max_word：最细切分 GET /_analyze { \"analyzer\": \"ik_max_word\", \"text\": \"黑马程序员学习java太棒了\" } 结果： { \"tokens\" : [ { \"token\" : \"黑马\", \"start_offset\" : 0, \"end_offset\" : 2, \"type\" : \"CN_WORD\", \"position\" : 0 }, { \"token\" : \"程序员\", \"start_offset\" : 2, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 1 }, { \"token\" : \"程序\", \"start_offset\" : 2, \"end_offset\" : 4, \"type\" : \"CN_WORD\", \"position\" : 2 }, { \"token\" : \"员\", \"start_offset\" : 4, \"end_offset\" : 5, \"type\" : \"CN_CHAR\", \"position\" : 3 }, { \"token\" : \"学习\", \"start_offset\" : 5, \"end_offset\" : 7, \"type\" : \"CN_WORD\", \"position\" : 4 }, { \"token\" : \"java\", \"start_offset\" : 7, \"end_offset\" : 11, \"type\" : \"ENGLISH\", \"position\" : 5 }, { \"token\" : \"太棒了\", \"start_offset\" : 11, \"end_offset\" : 14, \"type\" : \"CN_WORD\", \"position\" : 6 }, { \"token\" : \"太棒\", \"start_offset\" : 11, \"end_offset\" : 13, \"type\" : \"CN_WORD\", \"position\" : 7 }, { \"token\" : \"了\", \"start_offset\" : 13, \"end_offset\" : 14, \"type\" : \"CN_CHAR\", \"position\" : 8 } ] } 3.3 扩展词词典随着互联网的发展，“造词运动”也越发的频繁。出现了很多新的词语，在原有的词汇列表中并不存在。比如：“奥力给”，“传智播客” 等。 所以我们的词汇也需要不断的更新，IK分词器提供了扩展词汇的功能。 1）打开IK分词器config目录： 2）在IKAnalyzer.cfg.xml配置文件内容添加： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"&gt; &lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典--&gt; &lt;entry key=\"ext_dict\"&gt;ext.dic&lt;/entry&gt; &lt;/properties&gt; 3）新建一个 ext.dic，可以参考config目录下复制一个配置文件进行修改 传智播客 奥力给 4）重启elasticsearch docker restart es # 查看 日志 docker logs -f elasticsearch 日志中已经成功加载ext.dic配置文件 5）测试效果： GET /_analyze { \"analyzer\": \"ik_max_word\", \"text\": \"传智播客Java就业超过90%,奥力给！\" } 注意当前文件的编码必须是 UTF-8 格式，严禁使用Windows记事本编辑 3.4 停用词词典在互联网项目中，在网络间传输的速度很快，所以很多语言是不允许在网络上传递的，如：关于宗教、政治等敏感词语，那么我们在搜索时也应该忽略当前词汇。 IK分词器也提供了强大的停用词功能，让我们在索引时就直接忽略当前的停用词汇表中的内容。 1）IKAnalyzer.cfg.xml配置文件内容添加： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"&gt; &lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典--&gt; &lt;entry key=\"ext_dict\"&gt;ext.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典 *** 添加停用词词典--&gt; &lt;entry key=\"ext_stopwords\"&gt;stopword.dic&lt;/entry&gt; &lt;/properties&gt; 3）在 stopword.dic 添加停用词 习大大 4）重启elasticsearch # 重启服务 docker restart elasticsearch docker restart kibana # 查看 日志 docker logs -f elasticsearch 日志中已经成功加载stopword.dic配置文件 5）测试效果： GET /_analyze { \"analyzer\": \"ik_max_word\", \"text\": \"传智播客Java就业率超过95%,习大大都点赞,奥力给！\" } 注意当前文件的编码必须是 UTF-8 格式，严禁使用Windows记事本编辑 4.部署es集群部署es集群可以直接使用docker-compose来完成，不过要求你的Linux虚拟机至少有4G的内存空间 首先编写一个docker-compose文件，内容如下： version: '2.2' services: es01: image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1 container_name: es01 environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" ulimits: memlock: soft: -1 hard: -1 volumes: - data01:/usr/share/elasticsearch/data ports: - 9200:9200 networks: - elastic es02: image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1 container_name: es02 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" ulimits: memlock: soft: -1 hard: -1 volumes: - data02:/usr/share/elasticsearch/data networks: - elastic es03: image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1 container_name: es03 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" ulimits: memlock: soft: -1 hard: -1 volumes: - data03:/usr/share/elasticsearch/data networks: - elastic volumes: data01: driver: local data02: driver: local data03: driver: local networks: elastic: driver: bridge Run docker-compose to bring up the cluster: docker-compose up 5.RestAPI1.创建索引库代码分为三步： 1）创建Request对象。因为是创建索引库的操作，因此Request是CreateIndexRequest。 2）添加请求参数，其实就是DSL的JSON参数部分。因为json字符串很长，这里是定义了静态字符串常量MAPPING_TEMPLATE，让代码看起来更加优雅。 3）发送请求，client.indices()方法的返回值是IndicesClient类型，封装了所有与索引库操作有关的方法。 代码示例 在hotel-demo的cn.itcast.hotel.constants包下，创建一个类，定义mapping映射的JSON字符串常量： package cn.itcast.hotel.constants; public class HotelConstants { public static final String MAPPING_TEMPLATE = \"{\\n\" + \" \\\"mappings\\\": {\\n\" + \" \\\"properties\\\": {\\n\" + \" \\\"id\\\": {\\n\" + \" \\\"type\\\": \\\"keyword\\\"\\n\" + \" },\\n\" + \" \\\"name\\\":{\\n\" + \" \\\"type\\\": \\\"text\\\",\\n\" + \" \\\"analyzer\\\": \\\"ik_max_word\\\",\\n\" + \" \\\"copy_to\\\": \\\"all\\\"\\n\" + \" },\\n\" + \" \\\"address\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\",\\n\" + \" \\\"index\\\": false\\n\" + \" },\\n\" + \" \\\"price\\\":{\\n\" + \" \\\"type\\\": \\\"integer\\\"\\n\" + \" },\\n\" + \" \\\"score\\\":{\\n\" + \" \\\"type\\\": \\\"integer\\\"\\n\" + \" },\\n\" + \" \\\"brand\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\",\\n\" + \" \\\"copy_to\\\": \\\"all\\\"\\n\" + \" },\\n\" + \" \\\"city\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\",\\n\" + \" \\\"copy_to\\\": \\\"all\\\"\\n\" + \" },\\n\" + \" \\\"starName\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\"\\n\" + \" },\\n\" + \" \\\"business\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\"\\n\" + \" },\\n\" + \" \\\"location\\\":{\\n\" + \" \\\"type\\\": \\\"geo_point\\\"\\n\" + \" },\\n\" + \" \\\"pic\\\":{\\n\" + \" \\\"type\\\": \\\"keyword\\\",\\n\" + \" \\\"index\\\": false\\n\" + \" },\\n\" + \" \\\"all\\\":{\\n\" + \" \\\"type\\\": \\\"text\\\",\\n\" + \" \\\"analyzer\\\": \\\"ik_max_word\\\"\\n\" + \" }\\n\" + \" }\\n\" + \" }\\n\" + \"}\"; } 单元测试 /** * 创建索引 * @throws IOException */ @Test public void createIndex() throws IOException { //1.创建Request CreateIndexRequest request = new CreateIndexRequest(\"hotel\"); //2.准备DSL语句 request.source(HotelConstants.MAPPING_TEMPLATE, XContentType.JSON); //3.发送请求 restClient.indices().create(request, RequestOptions.DEFAULT); } 2.删除索引库以代码的差异，注意体现在Request对象上。依然是三步走： 1）创建Request对象。这次是DeleteIndexRequest对象 2）准备参数。这里是无参 3）发送请求。改用delete方法 代码示例 /** * 删除索引 * @throws IOException */ @Test public void deleteIndex() throws IOException { //1.创建Request DeleteIndexRequest request = new DeleteIndexRequest(\"hotel\"); //2.发送请求 restClient.indices().delete(request,RequestOptions.DEFAULT); } 3.判断索引库是否存在因此与删除的Java代码流程是类似的。依然是三步走： 1）创建Request对象。这次是GetIndexRequest对象 2）准备参数。这里是无参 3）发送请求。改用exists方法 代码示例 /** * 检测索引是否存在 * @throws IOException */ @Test public void existIndex() throws IOException { //1.创建Request GetIndexRequest request = new GetIndexRequest(\"hotel\"); //2.发送请求 boolean exists = restClient.indices().exists(request, RequestOptions.DEFAULT); System.out.println(exists); } 4.总结JavaRestClient操作elasticsearch的流程基本类似。核心是client.indices()方法来获取索引库的操作对象。 索引库操作的基本步骤： 初始化RestHighLevelClient 创建XxxIndexRequest。XXX是Create、Get、Delete 准备DSL（ Create时需要，其它是无参） 发送请求。调用RestHighLevelClient#indices().xxx()方法，xxx是create、exists、delete 6.RestClient操作文档1.新增文档可以看到与创建索引库类似，同样是三步走： 1）创建Request对象 2）准备请求参数，也就是DSL中的JSON文档 3）发送请求 变化的地方在于，这里直接使用client.xxx()的API，不再需要client.indices()了。 代码示例 @Test void testAddDocument() throws IOException { // 1.根据id查询酒店数据 Hotel hotel = hotelService.getById(61083L); // 2.转换为文档类型 HotelDoc hotelDoc = new HotelDoc(hotel); // 3.将HotelDoc转json String json = JSON.toJSONString(hotelDoc); // 1.准备Request对象 IndexRequest request = new IndexRequest(\"hotel\").id(hotelDoc.getId().toString()); // 2.准备Json文档 request.source(json, XContentType.JSON); // 3.发送请求 client.index(request, RequestOptions.DEFAULT); } 2.查询文档非常简单，因此代码大概分两步： 准备Request对象 发送请求 代码示例 @Test void testGetDocumentById() throws IOException { // 1.准备Request GetRequest request = new GetRequest(\"hotel\", \"61082\"); // 2.发送请求，得到响应 GetResponse response = client.get(request, RequestOptions.DEFAULT); // 3.解析响应结果 String json = response.getSourceAsString(); HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class); System.out.println(hotelDoc); } 3.删除文档 1）准备Request对象，因为是删除，这次是DeleteRequest对象。要指定索引库名和id 2）准备参数，无参 3）发送请求。因为是删除，所以是client.delete()方法 代码示例 @Test void testDeleteDocument() throws IOException { // 1.准备Request DeleteRequest request = new DeleteRequest(\"hotel\", \"61083\"); // 2.发送请求 client.delete(request, RequestOptions.DEFAULT); } 4.修改文档修改我们讲过两种方式： 全量修改：本质是先根据id删除，再新增 增量修改：修改文档中的指定字段值 在RestClient的API中，全量修改与新增的API完全一致，判断依据是ID： 如果新增时，ID已经存在，则修改 如果新增时，ID不存在，则新增 之前类似，也是三步走： 1）准备Request对象。这次是修改，所以是UpdateRequest 2）准备参数。也就是JSON文档，里面包含要修改的字段 3）更新文档。这里调用client.update()方法 代码示例 @Test void testUpdateDocument() throws IOException { // 1.准备Request UpdateRequest request = new UpdateRequest(\"hotel\", \"61083\"); // 2.准备请求参数 request.doc( \"price\", \"952\", \"starName\", \"四钻\" ); // 3.发送请求 client.update(request, RequestOptions.DEFAULT); } 5.批量导入文档其实还是三步走： 1）创建Request对象。这里是BulkRequest 2）准备参数。批处理的参数，就是其它Request对象，这里就是多个IndexRequest 3）发起请求。这里是批处理，调用的方法为client.bulk()方法 代码示例 @Test void testBulkRequest() throws IOException { // 批量查询酒店数据 List&lt;Hotel&gt; hotels = hotelService.list(); // 1.创建Request BulkRequest request = new BulkRequest(); // 2.准备参数，添加多个新增的Request for (Hotel hotel : hotels) { // 2.1.转换为文档类型HotelDoc HotelDoc hotelDoc = new HotelDoc(hotel); // 2.2.创建新增文档的Request对象 request.add(new IndexRequest(\"hotel\") .id(hotelDoc.getId().toString()) .source(JSON.toJSONString(hotelDoc), XContentType.JSON)); } // 3.发送请求 client.bulk(request, RequestOptions.DEFAULT); } 6.总结文档操作的基本步骤： 初始化RestHighLevelClient 创建XxxRequest。XXX是Index、Get、Update、Delete、Bulk 准备参数（Index、Update、Bulk时需要） 发送请求。调用RestHighLevelClient#.xxx()方法，xxx是index、get、update、delete、bulk 解析结果（Get时需要） 7.RestClient查询文档代码解读： 第一步，创建SearchRequest对象，指定索引库名 第二步，利用request.source()构建DSL，DSL中可以包含查询、分页、排序、高亮等 query()：代表查询条件，利用QueryBuilders.matchAllQuery()构建一个match_all查询的DSL 第三步，利用client.search()发送请求，得到响应 @Test void testMatchAll() throws IOException { // 1.准备Request SearchRequest request = new SearchRequest(\"hotel\"); // 2.准备DSL request.source() .query(QueryBuilders.matchAllQuery()); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } private void handleResponse(SearchResponse response) { // 4.解析响应 SearchHits searchHits = response.getHits(); // 4.1.获取总条数 long total = searchHits.getTotalHits().value; System.out.println(\"共搜索到\" + total + \"条数据\"); // 4.2.文档数组 SearchHit[] hits = searchHits.getHits(); // 4.3.遍历 for (SearchHit hit : hits) { // 获取文档source String json = hit.getSourceAsString(); // 反序列化 HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class); System.out.println(\"hotelDoc = \" + hotelDoc); } } 1.match查询全文检索的match和multi_match查询与match_all的API基本一致。差别是查询条件，也就是query的部分。 @Test void testMatch() throws IOException { // 1.准备Request SearchRequest request = new SearchRequest(\"hotel\"); // 2.准备DSL request.source() .query(QueryBuilders.matchQuery(\"all\", \"如家\")); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } 2.精确查询term:词条精确匹配 ranage:范围查询 3.布尔查询 @Test void testBool() throws IOException { // 1.准备Request SearchRequest request = new SearchRequest(\"hotel\"); // 2.准备DSL // 2.1.准备BooleanQuery BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); // 2.2.添加term boolQuery.must(QueryBuilders.termQuery(\"city\", \"杭州\")); // 2.3.添加range boolQuery.filter(QueryBuilders.rangeQuery(\"price\").lte(250)); request.source().query(boolQuery); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } 4.排序，分页 @Test void testPageAndSort() throws IOException { // 页码，每页大小 int page = 1, size = 5; // 1.准备Request SearchRequest request = new SearchRequest(\"hotel\"); // 2.准备DSL // 2.1.query request.source().query(QueryBuilders.matchAllQuery()); // 2.2.排序 sort request.source().sort(\"price\", SortOrder.ASC); // 2.3.分页 from、size request.source().from((page - 1) * size).size(5); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } 5.高亮 @Test void testHighlight() throws IOException { // 1.准备Request SearchRequest request = new SearchRequest(\"hotel\"); // 2.准备DSL // 2.1.query request.source().query(QueryBuilders.matchQuery(\"all\", \"如家\")); // 2.2.高亮 request.source().highlighter(new HighlightBuilder().field(\"name\").requireFieldMatch(false)); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response); } 代码解读： 第一步：从结果中获取source。hit.getSourceAsString()，这部分是非高亮结果，json字符串。还需要反序列为HotelDoc对象 第二步：获取高亮结果。hit.getHighlightFields()，返回值是一个Map，key是高亮字段名称，值是HighlightField对象，代表高亮值 第三步：从map中根据高亮字段名称，获取高亮字段值对象HighlightField 第四步：从HighlightField中获取Fragments，并且转为字符串。这部分就是真正的高亮字符串了 第五步：用高亮的结果替换HotelDoc中的非高亮结果 private void handleResponse(SearchResponse response) { // 4.解析响应 SearchHits searchHits = response.getHits(); // 4.1.获取总条数 long total = searchHits.getTotalHits().value; System.out.println(\"共搜索到\" + total + \"条数据\"); // 4.2.文档数组 SearchHit[] hits = searchHits.getHits(); // 4.3.遍历 for (SearchHit hit : hits) { // 获取文档source String json = hit.getSourceAsString(); // 反序列化 HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class); // 获取高亮结果 Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields(); if (!CollectionUtils.isEmpty(highlightFields)) { // 根据字段名获取高亮结果 HighlightField highlightField = highlightFields.get(\"name\"); if (highlightField != null) { // 获取高亮值 String name = highlightField.getFragments()[0].string(); // 覆盖非高亮结果 hotelDoc.setName(name); } } System.out.println(\"hotelDoc = \" + hotelDoc); } }","categories":[{"name":"全文检索","slug":"全文检索","permalink":"https://macongmc.github.io/categories/%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/"}],"tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"https://macongmc.github.io/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"}],"author":"马聪"},{"title":"Mysql总结","slug":"Mysql总结","date":"2022-09-20T08:00:07.000Z","updated":"2022-09-20T08:00:07.000Z","comments":true,"path":"posts/e0d7f1e7.html","link":"","permalink":"https://macongmc.github.io/posts/e0d7f1e7.html","excerpt":"","text":"第一章 优化SQL一.定位慢SQL语句1.开启慢查询日志 2.使用show processlist 二.慢查询日志2.1概述​ 慢查询日志用来记录在 MySQL 中执行时间超过指定时间的查询语句。 通过慢查询日志，可以查找出哪些查询语句的执行效率低，以便进行优化。 ​ 慢查询日志是在SQL执行完毕之后通过设置阈值，来定位慢SQL. 2.2开启慢查询日志默认，MySQL的慢查询日志功能是关闭的。 show variables like 'slow_query%'; 开启MySQL的慢查询日志功能 set global slow_query_log ='ON'; 2.3设置慢查询超时时间show variables like 'long_query_time%'; long_query_time 默认为 10s。生产环境下，如果 SQL 的执行时间超过 1s，我们可以认为这条 SQL是比较慢，我们将long_query_time的值改为 2s set global long_query_time =2; 对于当前会话窗口，查看long_query_time值没有更新。我们需要新开一个会话窗口，可以查询到更新后的值。 2.3测试慢查询执行一个3秒查询 select sleep(3); 2.4查看日志[root@node1 ~]# cat /var/lib/mysql/node1-slow.log /usr/sbin/mysqld, Version: 8.0.27 (MySQL Community Server - GPL). started with: Tcp port: 3306 Unix socket: /var/lib/mysql/mysql.sock Time Id Command Argument # Time: 2021-11-14T19:41:41.225465Z # User@Host: root[root] @ localhost [] Id: 31 # Query_time: 3.003578 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 1 SET timestamp=1636918898; select sleep(3); [root@node1 ~]# 2.5慢日志分析工具-mysqldumpslow[root@node1 ~]# mysqldumpslow -s at -t 1 /var/lib/mysql/node1-slow.log Reading mysql slow query log from /var/lib/mysql/node1-slow.log Count: 3 Time=8.00s (24s) Lock=0.00s (0s) Rows=1.0 (3), root[root]@localhost select sleep(N) [root@node1 ~]# 2.6重启失效重启MySQL服务之后，上面相关设置丢失。 2.7配置文件方式[root@node1 ~]# vi /etc/my.cnf 在[mysqld]最后添加 slow-query-log = on long_query_time = 2 然后重启MySQL服务 三.show processlist 检测正在运行的sqlshow processlist 四.EXPLAIN 分析执行计划在查询语句前面添加 explain explain select * from demo; 1.优化 使用key 2.优化 type 3.优化extra 尽量使用覆盖索引","categories":[{"name":"mysql","slug":"mysql","permalink":"https://macongmc.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://macongmc.github.io/tags/mysql/"}],"author":"马聪"},{"title":"MySQL高级","slug":"MySQL高级","date":"2022-09-15T10:01:29.000Z","updated":"2022-09-15T10:01:29.000Z","comments":true,"path":"posts/9982416a.html","link":"","permalink":"https://macongmc.github.io/posts/9982416a.html","excerpt":"","text":"MySQL高级-day11.索引1.1索引概述索引是帮助MySQL高效获取数据的数据结构。 1.2索引的优势和劣势优势： 1.类似于书籍目录索引，提高数据检索的效率，降低数据库的IO成本。 2.通过索引列对数据进行排序，降低排序成本，降低CPU的消耗。 劣势： 1.索引实际上也是一张表，该表中保存了主键与索引字段，并指向实体类的记录，所以索引列也是要占用空间的。 2.索引提高了查询效率，复杂了INSTER,UPDATE,DELETE. 2.索引结构 2.1BTREE结构 2.2B+TREE结构 2.3MySQL中的B+Tree 2.4索引的分类1.单值索引：即一个索引只包含单个列，一个表可以有多个单列索引。 2.唯一索引：索引列的值必须唯一，但允许有空值 3.复合索引：即一个索引包含多个列 2.5索引语法2.5.1创建索引CREATE [UNIQUE|FULLTEXT|SPATTAL] INDEX index_name [USING INDEX_TYPE] ON tb_name(index_col_name,...) index_col_name:column_name[(length)] [ASC|DESC] 2.5.2查看索引show index from 表名；\\G 主键有默认索引 主键索引。 2.5.3删除索引drop index 索引的名称 on 表名； 2.5.4ALTER命名1. alter table tb_name add primary key(column_list); 该语句添加一个主键 2.alter table tb_name add unique index_name(colum_list); 该语句创建索引的值必须唯一 3.alter table tb_name add index index_name(colum_list); 添加普通索引 4.alter table tb_name add fulltest index_name(column_list); 全文索引 2.6索引的设计原则 3.视图3.1视图概述 3.2创建或者修改视图CREATE VIEW name AS SELECT语句; CREATE [OR PEPLACE] [ALGORIHM ={UNDEFINED |MERGE |TEMPTABLE}] VIEW VIEW_NAME[(COLUM_LLIST)] AS select_statement [WITH[CASCADED | LOCAL] CHECK OPTION] #查询视图 SELECT * FROM VIEW_NAME; #更新 UPDATE VIEW_CITY SET city_name='西安' WHERE city_id = 1; 修改语法 ALTER [ALGORITHM ={UNDEFINED | MERGE| TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement [WITH[CASCADED |LOCAL] CHECK OPTION] 3.3查看视图#查看当前的视图包括表 SHOW TABLES; #查看创建视图的语句 SHOW CREATE VIEW name; 3.4删除视图DROP VIEW view_name; DROP VIEW IF EXISTS view_name; 4.存储过程和函数4.1存储过程和函数概述 存储过程和函数是 事先经过编译并存储在数据库中的一段SQL语句的集合，调用存储过程和函数可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之前的传输，对于提高数据处理的效率是有好处的。 存储过程和函数的区别在于函数必须有返回值，而存储过程没有。 函数：是一个有返回值的过程。 过程：是一个没有返回值的函数。 4.2创建存储过程CREATE PROCEDURE procedure_name([proc_parameter]) begin --sql语句 end; 示例 CREATE PROCEDURE pro_test1() begin select * from demo; end; deimiter $ ; 替换$ #不让SQL执行； deimiter $ CREATE PROCEDURE pro_test1() begin select * from demo; end$ deimiter ; 4.3调用存储过程call pro_name(); 4.4查询存储过程#查询db_name数据库中的所有存储过程 SELECT name from mysql.pro WHERE db ='dbname'; #查询存储过程的状态信息 SHOW procedure status; #查询某个存储过程的定义 SHOW CREATE PROCEDURE test.pro_test1 \\G; 4.5删除存储过程DROP PROCEDURE PRO_TEST; 4.6语法存储过程是可以编程的，意味着可以使用变量，表达式，控制结构， 来完成复杂的功能， 4.6.1变量DECLARE 通过DECLARE 可以定义一个局部变量该变量的作用范围只能在BIGIN…END块中. DECLARE var_name[,...] type [DEFAULT value] 示例 delimiter $ create procedure pro_test2() begin declare byn int default 5; select num+10; end$ delimiter; SET 直接赋值使用SET，可以赋值常量或者表达式； SET var_name = expr[,varname=expr]... 示例 create procedure pro_test() begin declare num int default 0; set num = num +10; select num; end$ call pro_test()$ 也可也通过SELECT … INTO 方式 create procedure pri_test() begin declare num int; select count(*) into num from city; select concat('city表中的记录数为：',num); end$; 4.6.2if条件判断if search_condition then statement_list ​ [else if search_condition then statement_list ]... ​ [else statement_list] end if; 4.6.3传递参数create procedure procedure_name([in/out/inout]参数名 类型) IN 默认 输入 OUT 输出 INOUT 输入输出都可以 OUT输出 call pro_test(188,@description); select @description; 4.6.4case结构 示例 4.6.5while循环while search_condition do statement_list end while; 需求 计算1加到n得值 示例 4.6.6repeat结构满足条件得时候退出 REPEAT statement_list UNTIL search_list END REPEAT; 需求 计算1加到n得值 4.6.7loop语句LOOP实现简单得循环，退出循环使用LEAVE语句实现 [begin_lable:] LOOP statement_list END LOOP [END_LABLE] 如果不加退出会成为死循环。 4.6.8leave语句 4.6.9游标/光标用来存储查询结果集。 声明光标 DECLARE cursor_name CURSOR FOR select_statement; OPEN 光标 OPEN cursor_name； FETCH 光标 FETCH cursor_name INTO var_name[,var_name]... 调用一次 走一个。 CLOSE光标 CLOSE cursor_name; 示例 没有的会报错；循环获取游标，解决报错， 4.7存储函数CREATE FUNCTION function_name([param typr]) RETURNS type begin ... end; 5.触发器5.1介绍 5.2创建触发器 5.3删除触发器drop trigger [schema_name.]trigger_name; 5.4查看触发器show triggers; MySQL高级-day21.Mysql的体系结构概括 2.存储引擎2.1存储引擎概述 和大多数的数据库不同，mysql中有个一个存储引擎的概念，针对不同的存储需求可以选择最优的存储引擎。 存储引擎就是存储数据，建立索引，更新查询数据等等技术的实现方式，存储引擎是基于表的，而不是基于库的。所以存储引擎也可以称为表类型。 #支持的存储引擎 show engines; InnoDB 默认 2.2各种之间的特性 2.2.1InonDB​ InnoDB 存储引擎是Mysql的默认存储引擎。InnoDB 提供了具有 提交，回滚，崩溃恢复能力的事务安全， 事务控制 create table goods_innodb( id int not null AUTO_INCREMENT, name varchar(20) not null, )ENGINE=innodb DEFAULT CHAREST=utf8; START TRANSACTION; insert into goods_innodb(id,name) values(1,'46'); commit; 2.2.2MyISAM MyISAM不支持事务，也不支持外键，优势是访问熟读快，支持表锁。 文件存储方式 .frm(存储表定义)； .MYD(MYData,存储数据)； .MY(MYIndex,存储索引)； 2.2.3 MEMORY 2.2.4MERGE 2.3存储引擎的选择 3.优化SQL步骤3.1查看SQL的执行频率#连接的 show status like 'Com_______' #全局的 show global status like 'Com_______' #InnoDB 查询 show global status like 'Innodb_row_%'; 3.2定位低效率执行SQL SHOW PROCESSLIST; 3.3explain分析执行计划explain select * from demo; 3.3.1explain之idid字段是SELECT查询的序列号，是一组数字，表示的是查询中执行select子句或者表操作的顺序。id有三种情况。 1.id相同表示加载表的顺序是从上到下。 explain select * from t_roler r,t_user u,user_role ur =where r.id=ur.role_id and u.id = ur.user_id; 2.id不同值越大，优先级越高， explain select * from t_role where id= (select role_id from user_role where user_id =(select id = from t_user where username = 'stu1')); 3.id有相同也有不同 explain select * from t_role r(select * from user_role ur where ur.user.id=2) a where r.id = a.role_id; 3.3.2explain之select_type 3.3.3explain之table展示这一行的数据是关于那张表 3.3.4explain之type 3.3.5explain之key 3.3.6explain之row 3.3.7explain之extra 3.4show profile 分析SQL show profiles show profile for query queryID； 3.5trace分析优化器执行计划 set optimizer_trace =\"enable =on\",end_markers_in_json=on; set optimizer_trace_max_mem_size=1000000; 4. 索引的使用索引是数据库优化最常用也是最重要的手段之一, 通过索引通常可以帮助用户解决大多数的MySQL的性能优化问题。 4.1 验证索引提升查询效率在我们准备的表结构tb_item 中， 一共存储了 300 万记录； A. 根据ID查询 select * from tb_item where id = 1999\\G; 查询速度很快， 接近0s ， 主要的原因是因为id为主键， 有索引； 2). 根据 title 进行精确查询 select * from tb_item where title = 'iphoneX 移动3G 32G941'\\G; 处理方案 ， 针对title字段， 创建索引 ： create index idx_item_title on tb_item(title); 索引创建完成之后，再次进行查询 ： 通过explain ， 查看执行计划，执行SQL时使用了刚才创建的索引 4.2 索引的使用4.2.1 准备环境create table `tb_seller` ( `sellerid` varchar (100), `name` varchar (100), `nickname` varchar (50), `password` varchar (60), `status` varchar (1), `address` varchar (100), `createtime` datetime, primary key(`sellerid`) )engine=innodb default charset=utf8mb4; insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('alibaba','阿里巴巴','阿里小店','e10adc3949ba59abbe56e057f20f883e','1','北京市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('baidu','百度科技有限公司','百度小店','e10adc3949ba59abbe56e057f20f883e','1','北京市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('huawei','华为科技有限公司','华为小店','e10adc3949ba59abbe56e057f20f883e','0','北京市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('itcast','传智播客教育科技有限公司','传智播客','e10adc3949ba59abbe56e057f20f883e','1','北京市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('itheima','黑马程序员','黑马程序员','e10adc3949ba59abbe56e057f20f883e','0','北京市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('luoji','罗技科技有限公司','罗技小店','e10adc3949ba59abbe56e057f20f883e','1','北京市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('oppo','OPPO科技有限公司','OPPO官方旗舰店','e10adc3949ba59abbe56e057f20f883e','0','北京市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('ourpalm','掌趣科技股份有限公司','掌趣小店','e10adc3949ba59abbe56e057f20f883e','1','北京市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('qiandu','千度科技','千度小店','e10adc3949ba59abbe56e057f20f883e','2','北京市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('sina','新浪科技有限公司','新浪官方旗舰店','e10adc3949ba59abbe56e057f20f883e','1','北京市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('xiaomi','小米科技','小米官方旗舰店','e10adc3949ba59abbe56e057f20f883e','1','西安市','2088-01-01 12:00:00'); insert into `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('yijia','宜家家居','宜家家居旗舰店','e10adc3949ba59abbe56e057f20f883e','1','北京市','2088-01-01 12:00:00'); create index idx_seller_name_sta_addr on tb_seller(name,status,address); 4.2.2 避免索引失效1). 全值匹配 ，对索引中所有列都指定具体值。 改情况下，索引生效，执行效率高。 explain select * from tb_seller where name='小米科技' and status='1' and address='北京市'\\G; 2). 最左前缀法则 如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始，并且不跳过索引中的列。 匹配最左前缀法则，走索引： 违法最左前缀法则 ， 索引失效： 如果符合最左法则，但是出现跳跃某一列，只有最左列索引生效： 3). 范围查询右边的列，不能使用索引 。 根据前面的两个字段name ， status 查询是走索引的， 但是最后一个条件address 没有用到索引。 4). 不要在索引列上进行运算操作， 索引将失效。 5). 字符串不加单引号，造成索引失效。 由于，在查询是，没有对字符串加单引号，MySQL的查询优化器，会自动的进行类型转换，造成索引失效。 6). 尽量使用覆盖索引，避免select * 尽量使用覆盖索引（只访问索引的查询（索引列完全包含查询列）），减少select * 。 如果查询列，超出索引列，也会降低性能。 TIP : using index ：使用覆盖索引的时候就会出现 using where：在查找使用索引的情况下，需要回表去查询所需的数据 using index condition：查找使用了索引，但是需要回表查询数据 using index ; using where：查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据 7). 用or分割开的条件， 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。 示例，name字段是索引列 ， 而createtime不是索引列，中间是or进行连接是不走索引的 ： explain select * from tb_seller where name='黑马程序员' or createtime = '2088-01-01 12:00:00'\\G; 8). 以%开头的Like模糊查询，索引失效。 如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。 解决方案 ： 通过覆盖索引来解决 9). 如果MySQL评估使用索引比全表更慢，则不使用索引。 10). is NULL ， is NOT NULL 有时索引失效。 11). in 走索引， not in 索引失效。 12). 单列索引和复合索引。 尽量使用复合索引，而少使用单列索引 。 创建复合索引 create index idx_name_sta_address on tb_seller(name, status, address); 就相当于创建了三个索引 ： name name + status name + status + address 创建单列索引 create index idx_seller_name on tb_seller(name); create index idx_seller_status on tb_seller(status); create index idx_seller_address on tb_seller(address); 数据库会选择一个最优的索引（辨识度最高索引）来使用，并不会使用全部索引 。 4.3 查看索引使用情况show status like 'Handler_read%'; show global status like 'Handler_read%'; Handler_read_first：索引中第一条被读的次数。如果较高，表示服务器正执行大量全索引扫描（这个值越低越好）。 Handler_read_key：如果索引正在工作，这个值代表一个行被索引值读的次数，如果值越低，表示索引得到的性能改善不高，因为索引不经常使用（这个值越高越好）。 Handler_read_next ：按照键顺序读下一行的请求数。如果你用范围约束或如果执行索引扫描来查询索引列，该值增加。 Handler_read_prev：按照键顺序读前一行的请求数。该读方法主要用于优化ORDER BY ... DESC。 Handler_read_rnd ：根据固定位置读一行的请求数。如果你正执行大量查询并需要对结果进行排序该值较高。你可能使用了大量需要MySQL扫描整个表的查询或你的连接没有正确使用键。这个值较高，意味着运行效率低，应该建立索引来补救。 Handler_read_rnd_next：在数据文件中读下一行的请求数。如果你正进行大量的表扫描，该值较高。通常说明你的表索引不正确或写入的查询没有利用索引。 5. SQL优化5.1 大批量插入数据环境准备 ： CREATE TABLE `tb_user_2` ( `id` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(45) NOT NULL, `password` varchar(96) NOT NULL, `name` varchar(45) NOT NULL, `birthday` datetime DEFAULT NULL, `sex` char(1) DEFAULT NULL, `email` varchar(45) DEFAULT NULL, `phone` varchar(45) DEFAULT NULL, `qq` varchar(32) DEFAULT NULL, `status` varchar(32) NOT NULL COMMENT '用户状态', `create_time` datetime NOT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `unique_user_username` (`username`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ; 当使用load 命令导入数据的时候，适当的设置可以提高导入的效率。 对于 InnoDB 类型的表，有以下几种方式可以提高导入的效率： 1） 主键顺序插入 因为InnoDB类型的表是按照主键的顺序保存的，所以将导入的数据按照主键的顺序排列，可以有效的提高导入数据的效率。如果InnoDB表没有主键，那么系统会自动默认创建一个内部列作为主键，所以如果可以给表创建一个主键，将可以利用这点，来提高导入数据的效率。 脚本文件介绍 : sql1.log ----&gt; 主键有序 sql2.log ----&gt; 主键无序 插入ID顺序排列数据： 插入ID无序排列数据： 2） 关闭唯一性校验 在导入数据前执行 SET UNIQUE_CHECKS=0，关闭唯一性校验，在导入结束后执行SET UNIQUE_CHECKS=1，恢复唯一性校验，可以提高导入的效率。 3） 手动提交事务 如果应用使用自动提交的方式，建议在导入前执行 SET AUTOCOMMIT=0，关闭自动提交，导入结束后再执行 SET AUTOCOMMIT=1，打开自动提交，也可以提高导入的效率。 5.2 优化insert语句当进行数据的insert操作的时候，可以考虑采用以下几种优化方案。 如果需要同时对一张表插入很多行数据时，应该尽量使用多个值表的insert语句，这种方式将大大的缩减客户端与数据库之间的连接、关闭等消耗。使得效率比分开执行的单个insert语句快。 示例， 原始方式为： insert into tb_test values(1,'Tom'); insert into tb_test values(2,'Cat'); insert into tb_test values(3,'Jerry'); 优化后的方案为 ： insert into tb_test values(1,'Tom'),(2,'Cat')，(3,'Jerry'); 在事务中进行数据插入。 start transaction; insert into tb_test values(1,'Tom'); insert into tb_test values(2,'Cat'); insert into tb_test values(3,'Jerry'); commit; 数据有序插入 insert into tb_test values(4,'Tim'); insert into tb_test values(1,'Tom'); insert into tb_test values(3,'Jerry'); insert into tb_test values(5,'Rose'); insert into tb_test values(2,'Cat'); 优化后 insert into tb_test values(1,'Tom'); insert into tb_test values(2,'Cat'); insert into tb_test values(3,'Jerry'); insert into tb_test values(4,'Tim'); insert into tb_test values(5,'Rose'); 5.3 优化order by语句5.3.1 环境准备CREATE TABLE `emp` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(100) NOT NULL, `age` int(3) NOT NULL, `salary` int(11) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; insert into `emp` (`id`, `name`, `age`, `salary`) values('1','Tom','25','2300'); insert into `emp` (`id`, `name`, `age`, `salary`) values('2','Jerry','30','3500'); insert into `emp` (`id`, `name`, `age`, `salary`) values('3','Luci','25','2800'); insert into `emp` (`id`, `name`, `age`, `salary`) values('4','Jay','36','3500'); insert into `emp` (`id`, `name`, `age`, `salary`) values('5','Tom2','21','2200'); insert into `emp` (`id`, `name`, `age`, `salary`) values('6','Jerry2','31','3300'); insert into `emp` (`id`, `name`, `age`, `salary`) values('7','Luci2','26','2700'); insert into `emp` (`id`, `name`, `age`, `salary`) values('8','Jay2','33','3500'); insert into `emp` (`id`, `name`, `age`, `salary`) values('9','Tom3','23','2400'); insert into `emp` (`id`, `name`, `age`, `salary`) values('10','Jerry3','32','3100'); insert into `emp` (`id`, `name`, `age`, `salary`) values('11','Luci3','26','2900'); insert into `emp` (`id`, `name`, `age`, `salary`) values('12','Jay3','37','4500'); create index idx_emp_age_salary on emp(age,salary); 5.3.2 两种排序方式1). 第一种是通过对返回数据进行排序，也就是通常说的 filesort 排序，所有不是通过索引直接返回排序结果的排序都叫 FileSort 排序。 2). 第二种通过有序索引顺序扫描直接返回有序数据，这种情况即为 using index，不需要额外排序，操作效率高。 多字段排序 了解了MySQL的排序方式，优化目标就清晰了：尽量减少额外的排序，通过索引直接返回有序数据。where 条件和Order by 使用相同的索引，并且Order By 的顺序和索引顺序相同， 并且Order by 的字段都是升序，或者都是降序。否则肯定需要额外的操作，这样就会出现FileSort。 5.3.3 Filesort 的优化通过创建合适的索引，能够减少 Filesort 的出现，但是在某些情况下，条件限制不能让Filesort消失，那就需要加快 Filesort的排序操作。对于Filesort ， MySQL 有两种排序算法： 1） 两次扫描算法 ：MySQL4.1 之前，使用该方式排序。首先根据条件取出排序字段和行指针信息，然后在排序区 sort buffer 中排序，如果sort buffer不够，则在临时表 temporary table 中存储排序结果。完成排序之后，再根据行指针回表读取记录，该操作可能会导致大量随机I/O操作。 2）一次扫描算法：一次性取出满足条件的所有字段，然后在排序区 sort buffer 中排序后直接输出结果集。排序时内存开销较大，但是排序效率比两次扫描算法要高。 MySQL 通过比较系统变量 max_length_for_sort_data 的大小和Query语句取出的字段总大小， 来判定是否那种排序算法，如果max_length_for_sort_data 更大，那么使用第二种优化之后的算法；否则使用第一种。 可以适当提高 sort_buffer_size 和 max_length_for_sort_data 系统变量，来增大排序区的大小，提高排序的效率。 5.4 优化group by 语句由于GROUP BY 实际上也同样会进行排序操作，而且与ORDER BY 相比，GROUP BY 主要只是多了排序之后的分组操作。当然，如果在分组的时候还使用了其他的一些聚合函数，那么还需要一些聚合函数的计算。所以，在GROUP BY 的实现过程中，与 ORDER BY 一样也可以利用到索引。 如果查询包含 group by 但是用户想要避免排序结果的消耗， 则可以执行order by null 禁止排序。如下 ： drop index idx_emp_age_salary on emp; explain select age,count(*) from emp group by age; 优化后 explain select age,count(*) from emp group by age order by null; 从上面的例子可以看出，第一个SQL语句需要进行”filesort”，而第二个SQL由于order by null 不需要进行 “filesort”， 而上文提过Filesort往往非常耗费时间。 创建索引 ： create index idx_emp_age_salary on emp(age,salary)； 5.5 优化嵌套查询Mysql4.1版本之后，开始支持SQL的子查询。这个技术可以使用SELECT语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的SQL操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询是可以被更高效的连接（JOIN）替代。 示例 ，查找有角色的所有的用户信息 : explain select * from t_user where id in (select user_id from user_role ); 执行计划为 : 优化后 : explain select * from t_user u , user_role ur where u.id = ur.user_id; 连接(Join)查询之所以更有效率一些 ，是因为MySQL不需要在内存中创建临时表来完成这个逻辑上需要两个步骤的查询工作。 5.6 优化OR条件对于包含OR的查询子句，如果要利用索引，则OR之间的每个条件列都必须用到索引 ， 而且不能使用到复合索引； 如果没有索引，则应该考虑增加索引。 获取 emp 表中的所有的索引 ： 示例 ： explain select * from emp where id = 1 or age = 30; 建议使用 union 替换 or ： 我们来比较下重要指标，发现主要差别是 type 和 ref 这两项 type 显示的是访问类型，是较为重要的一个指标，结果值从好到坏依次是： system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL UNION 语句的 type 值为 ref，OR 语句的 type 值为 range，可以看到这是一个很明显的差距 UNION 语句的 ref 值为 const，OR 语句的 type 值为 null，const 表示是常量值引用，非常快 这两项的差距就说明了 UNION 要优于 OR 。 5.7 优化分页查询一般分页查询时，通过创建覆盖索引能够比较好地提高性能。一个常见又非常头疼的问题就是 limit 2000000,10 ，此时需要MySQL排序前2000010 记录，仅仅返回2000000 - 2000010 的记录，其他记录丢弃，查询排序的代价非常大 。 5.7.1 优化思路一在索引上完成排序分页操作，最后根据主键关联回原表查询所需要的其他列内容。 5.7.2 优化思路二该方案适用于主键自增的表，可以把Limit 查询转换成某个位置的查询 。 5.8 使用SQL提示SQL提示，是优化数据库的一个重要手段，简单来说，就是在SQL语句中加入一些人为的提示来达到优化操作的目的。 5.8.1 USE INDEX在查询语句中表名的后面，添加 use index 来提供希望MySQL去参考的索引列表，就可以让MySQL不再考虑其他可用的索引。 create index idx_seller_name on tb_seller(name); 5.8.2 IGNORE INDEX如果用户只是单纯的想让MySQL忽略一个或者多个索引，则可以使用 ignore index 作为 hint 。 explain select * from tb_seller ignore index(idx_seller_name) where name = '小米科技'; 5.8.3 FORCE INDEX为强制MySQL使用一个特定的索引，可在查询中使用 force index 作为hint 。 create index idx_seller_address on tb_seller(address); MySQL高级-day31.应用优化前面章节，我们介绍很多数据库优化措施。 1.1使用连接池频繁的创建关闭连接，是比较耗费资源，我们有必要建立数据库连接池，以提高访问性能。 c3p0,druid 1.2减少MySQL的访问1.2.1避免数据重复检索在编写应用代码时，需要能够理清对数据库的访问逻辑。 1.2.2增加cache层使用持久化框架的一级或二及缓存，或者Redis中。 1.3负载均衡1.3.1利用MySQL复制分流查询通过MySQL的主从复制，实现读写分离，使增删改操作走主节点，查询操作走从节点，从而可以降低单台服务器的读写压力。 1.3.2采用分布式数据架构分布式数据库架构适合大数据量，负载高的情况，它有良好的拓展性和高可用性。通过在多台服务器之间分布数据，可以实现多台服务器之间的负载均衡，提高访问效率。 2.Mysql中查询缓存优化2.1概述开启Mysql的查询缓存，当执行完全相同的SQL语句的时候，服务器就会直接从缓存中读取结构，当数据被修改，之前的缓存会失效，修改比较频繁的表不适合做查询缓存。 2.2操作流程 2.3查询缓存配置1.查看当前的MySQL数据库是否支持查询缓存： SHOW VARIABLES LIKE 'have_query_cache'; 2.查看当前MySQL是否开启了查询缓存： SHOW VARIABLES LIKE 'query_cache_type'; 3.查看查询缓存的占用大小： SHOW VATIABLES LIKE 'query_cache_size'; 4.查询查询缓存的状态变量： SHOW STATUS LIKE 'Qcache%'; 2.4开启查询缓存MySQL查询缓存默认是关闭的，需要手动配置参数query_cache_type,来开启查询缓存，query_cache_type该参数的可能取值有三个： 2.5查询缓存SELECT选型可以在SELECT语句中指定两个与查询查询缓存相关的选型： SQL_CACHE:如果查询结果是可缓存的，并且query_cache_type系统变量是ON或者DEMANE，则缓存结果。 SQL_NO_CACHE:服务器不使用查询缓存。它既不检查查询缓存，也不检测结果是否以缓存，也不缓存查询结果。 SELECT SQL_CACHE id,name FROM cuntomer; SELECT SQL_NO_CACHE id,name FROM cuntomer; 2.6查询缓存失效的情况 3.Mysql内存管理优化3.1内存优化原则 3.2MyISAM内存优化 3.3InnoDB内存优化 4.Mysql并发参数调整 5.Mysql锁问题51锁概述锁是计算机协调多个进程或线程并发访问某一资源的机制。 5.2锁分类操作粒度： 1.表锁 2.行锁 操作类型： 1.读锁（共享锁） 2.写锁（排它锁） 5.3MySQL锁 5..2MyISAM表锁MyISAM存储引擎只支持表锁。 5.2.1如何加表锁 5.2.2读锁案例5.2.3写锁案例 5.2.45结论 5.2.查看锁的争用情况 5.3InnoDB锁问题5.3.1行锁介绍 5.3.2背景知识 5.3.3InoDB行锁的模式 5.3.4案例准备工作 5.3.5行锁基本演示 5.3.6无索引行锁升级为表锁 5.3.7间隙锁危害 5.3.8InnoDB行锁争用情况 5.3.9总结 6.常用SQL技巧6.1SQL执行顺序 6.2正则表达式使用 Mysql高级-day041. MySql中常用工具1.1 mysql该mysql不是指mysql服务，而是指mysql的客户端工具。 语法 ： mysql [options] [database] 1.1.1 连接选项参数 ： -u, --user=name 指定用户名 -p, --password[=name] 指定密码 -h, --host=name 指定服务器IP或域名 -P, --port=# 指定连接端口 示例 ： mysql -h 127.0.0.1 -P 3306 -u root -p mysql -h127.0.0.1 -P3306 -uroot -p2143 1.1.2 执行选项-e, --execute=name 执行SQL语句并退出 此选项可以在Mysql客户端执行SQL语句，而不用连接到MySQL数据库再执行，对于一些批处理脚本，这种方式尤其方便。 示例： mysql -uroot -p2143 db01 -e \"select * from tb_book\"; 1.2 mysqladminmysqladmin 是一个执行管理操作的客户端程序。可以用它来检查服务器的配置和当前状态、创建并删除数据库等。 可以通过 ： mysqladmin –help 指令查看帮助文档 示例 ： mysqladmin -uroot -p2143 create 'test01'; mysqladmin -uroot -p2143 drop 'test01'; mysqladmin -uroot -p2143 version; 1.3 mysqlbinlog由于服务器生成的二进制日志文件以二进制格式保存，所以如果想要检查这些文本的文本格式，就会使用到mysqlbinlog 日志管理工具。 语法 ： mysqlbinlog [options] log-files1 log-files2 ... 选项： -d, --database=name : 指定数据库名称，只列出指定的数据库相关操作。 -o, --offset=# : 忽略掉日志中的前n行命令。 -r,--result-file=name : 将输出的文本格式日志输出到指定文件。 -s, --short-form : 显示简单格式， 省略掉一些信息。 --start-datatime=date1 --stop-datetime=date2 : 指定日期间隔内的所有日志。 --start-position=pos1 --stop-position=pos2 : 指定位置间隔内的所有日志。 1.4 mysqldumpmysqldump 客户端工具用来备份数据库或在不同数据库之间进行数据迁移。备份内容包含创建表，及插入表的SQL语句。 语法 ： mysqldump [options] db_name [tables] mysqldump [options] --database/-B db1 [db2 db3...] mysqldump [options] --all-databases/-A 1.4.1 连接选项参数 ： -u, --user=name 指定用户名 -p, --password[=name] 指定密码 -h, --host=name 指定服务器IP或域名 -P, --port=# 指定连接端口 1.4.2 输出内容选项参数： --add-drop-database 在每个数据库创建语句前加上 Drop database 语句 --add-drop-table 在每个表创建语句前加上 Drop table 语句 , 默认开启 ; 不开启 (--skip-add-drop-table) -n, --no-create-db 不包含数据库的创建语句 -t, --no-create-info 不包含数据表的创建语句 -d --no-data 不包含数据 -T, --tab=name 自动生成两个文件：一个.sql文件，创建表结构的语句； 一个.txt文件，数据文件，相当于select into outfile 示例 ： mysqldump -uroot -p2143 db01 tb_book --add-drop-database --add-drop-table &gt; a mysqldump -uroot -p2143 -T /tmp test city 1.5 mysqlimport/sourcemysqlimport 是客户端数据导入工具，用来导入mysqldump 加 -T 参数后导出的文本文件。 语法： mysqlimport [options] db_name textfile1 [textfile2...] 示例： mysqlimport -uroot -p2143 test /tmp/city.txt 如果需要导入sql文件,可以使用mysql中的source 指令 : source /root/tb_book.sql 1.6 mysqlshowmysqlshow 客户端对象查找工具，用来很快地查找存在哪些数据库、数据库中的表、表中的列或者索引。 语法： mysqlshow [options] [db_name [table_name [col_name]]] 参数： --count 显示数据库及表的统计信息（数据库，表 均可以不指定） -i 显示指定数据库或者指定表的状态信息 示例： #查询每个数据库的表的数量及表中记录的数量 mysqlshow -uroot -p2143 --count #查询test库中每个表中的字段书，及行数 mysqlshow -uroot -p2143 test --count #查询test库中book表的详细情况 mysqlshow -uroot -p2143 test book --count 2. Mysql 日志在任何一种数据库中，都会有各种各样的日志，记录着数据库工作的方方面面，以帮助数据库管理员追踪数据库曾经发生过的各种事件。MySQL 也不例外，在 MySQL 中，有 4 种不同的日志，分别是错误日志、二进制日志（BINLOG 日志）、查询日志和慢查询日志，这些日志记录着数据库在不同方面的踪迹。 2.1 错误日志错误日志是 MySQL 中最重要的日志之一，它记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，可以首先查看此日志。 该日志是默认开启的 ， 默认存放目录为 mysql 的数据目录（var/lib/mysql）, 默认的日志文件名为 hostname.err（hostname是主机名）。 查看日志位置指令 ： show variables like 'log_error%'; 查看日志内容 ： tail -f /var/lib/mysql/xaxh-server.err 2.2 二进制日志2.2.1概述二进制日志（BINLOG）记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但是不包括数据查询语句。此日志对于灾难时的数据恢复起着极其重要的作用，MySQL的主从复制， 就是通过该binlog实现的。 二进制日志，默认情况下是没有开启的，需要到MySQL的配置文件中开启，并配置MySQL日志的格式。 配置文件位置 : /usr/my.cnf 日志存放位置 : 配置时，给定了文件名但是没有指定路径，日志默认写入Mysql的数据目录。 #配置开启binlog日志， 日志的文件前缀为 mysqlbin -----&gt; 生成的文件名如 : mysqlbin.000001,mysqlbin.000002 log_bin=mysqlbin #配置二进制日志的格式 binlog_format=STATEMENT 2.2.2 日志格式STATEMENT 该日志格式在日志文件中记录的都是SQL语句（statement），每一条对数据进行修改的SQL都会记录在日志文件中，通过Mysql提供的mysqlbinlog工具，可以清晰的查看到每条语句的文本。主从复制的时候，从库（slave）会将日志解析为原文本，并在从库重新执行一次。 ROW 该日志格式在日志文件中记录的是每一行的数据变更，而不是记录SQL语句。比如，执行SQL语句 ： update tb_book set status=’1’ , 如果是STATEMENT 日志格式，在日志中会记录一行SQL文件； 如果是ROW，由于是对全表进行更新，也就是每一行记录都会发生变更，ROW 格式的日志中会记录每一行的数据变更。 MIXED 这是目前MySQL默认的日志格式，即混合了STATEMENT 和 ROW两种格式。默认情况下采用STATEMENT，但是在一些特殊情况下采用ROW来进行记录。MIXED 格式能尽量利用两种模式的优点，而避开他们的缺点。 2.2.3 日志读取由于日志以二进制方式存储，不能直接读取，需要用mysqlbinlog工具来查看，语法如下 ： mysqlbinlog log-file； 查看STATEMENT格式日志 执行插入语句 ： insert into tb_book values(null,'Lucene','2088-05-01','0'); 查看日志文件 ： mysqlbin.index : 该文件是日志索引文件 ， 记录日志的文件名； mysqlbing.000001 ：日志文件 查看日志内容 ： mysqlbinlog mysqlbing.000001； 查看ROW格式日志 配置 : #配置开启binlog日志， 日志的文件前缀为 mysqlbin -----&gt; 生成的文件名如 : mysqlbin.000001,mysqlbin.000002 log_bin=mysqlbin #配置二进制日志的格式 binlog_format=ROW 插入数据 : insert into tb_book values(null,'SpringCloud实战','2088-05-05','0'); 如果日志格式是 ROW , 直接查看数据 , 是查看不懂的 ; 可以在mysqlbinlog 后面加上参数 -vv mysqlbinlog -vv mysqlbin.000002 2.2.4 日志删除对于比较繁忙的系统，由于每天生成日志量大 ，这些日志如果长时间不清楚，将会占用大量的磁盘空间。下面我们将会讲解几种删除日志的常见方法 ： 方式一 通过 Reset Master 指令删除全部 binlog 日志，删除之后，日志编号，将从 xxxx.000001重新开始 。 查询之前 ，先查询下日志文件 ： 执行删除日志指令： Reset Master 执行之后， 查看日志文件 ： 方式二 执行指令 purge master logs to 'mysqlbin.******' ，该命令将删除 ****** 编号之前的所有日志。 方式三 执行指令 purge master logs before 'yyyy-mm-dd hh24:mi:ss' ，该命令将删除日志为 “yyyy-mm-dd hh24:mi:ss” 之前产生的所有日志 。 方式四 设置参数 –expire_logs_days=# ，此参数的含义是设置日志的过期天数， 过了指定的天数后日志将会被自动删除，这样将有利于减少DBA 管理日志的工作量。 配置如下 ： 2.3 查询日志查询日志中记录了客户端的所有操作语句，而二进制日志不包含查询数据的SQL语句。 默认情况下， 查询日志是未开启的。如果需要开启查询日志，可以设置以下配置 ： #该选项用来开启查询日志 ， 可选值 ： 0 或者 1 ； 0 代表关闭， 1 代表开启 general_log=1 #设置日志的文件名 ， 如果没有指定， 默认的文件名为 host_name.log general_log_file=file_name 在 mysql 的配置文件 /usr/my.cnf 中配置如下内容 ： 配置完毕之后，在数据库执行以下操作 ： select * from tb_book; select * from tb_book where id = 1; update tb_book set name = 'lucene入门指南' where id = 5; select * from tb_book where id &lt; 8; 执行完毕之后， 再次来查询日志文件 ： 2.4 慢查询日志慢查询日志记录了所有执行时间超过参数 long_query_time 设置值并且扫描记录数不小于 min_examined_row_limit 的所有的SQL语句的日志。long_query_time 默认为 10 秒，最小为 0， 精度可以到微秒。 2.4.1 文件位置和格式慢查询日志默认是关闭的 。可以通过两个参数来控制慢查询日志 ： # 该参数用来控制慢查询日志是否开启， 可取值： 1 和 0 ， 1 代表开启， 0 代表关闭 slow_query_log=1 # 该参数用来指定慢查询日志的文件名 slow_query_log_file=slow_query.log # 该选项用来配置查询的时间限制， 超过这个时间将认为值慢查询， 将需要进行日志记录， 默认10s long_query_time=10 2.4.2 日志的读取和错误日志、查询日志一样，慢查询日志记录的格式也是纯文本，可以被直接读取。 1） 查询long_query_time 的值。 2） 执行查询操作 select id, title,price,num ,status from tb_item where id = 1; 由于该语句执行时间很短，为0s ， 所以不会记录在慢查询日志中。 select * from tb_item where title like '%阿尔卡特 (OT-927) 炭黑 联通3G手机 双卡双待165454%' ; 该SQL语句 ， 执行时长为 26.77s ，超过10s ， 所以会记录在慢查询日志文件中。 3） 查看慢查询日志文件 直接通过cat 指令查询该日志文件 ： 如果慢查询日志内容很多， 直接查看文件，比较麻烦， 这个时候可以借助于mysql自带的 mysqldumpslow 工具， 来对慢查询日志进行分类汇总。 3. Mysql复制3.1 复制概述复制是指将主数据库的DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步。 MySQL支持一台主库同时向多台从库进行复制， 从库同时也可以作为其他从服务器的主库，实现链状复制。 3.2 复制原理MySQL 的主从复制原理如下。 从上层来看，复制分成三步： Master 主库在事务提交时，会把数据变更作为时间 Events 记录在二进制日志文件 Binlog 中。 主库推送二进制日志文件 Binlog 中的日志事件到从库的中继日志 Relay Log 。 slave重做中继日志中的事件，将改变反映它自己的数据。 3.3 复制优势MySQL 复制的有点主要包含以下三个方面： 主库出现问题，可以快速切换到从库提供服务。 可以在从库上执行查询操作，从主库中更新，实现读写分离，降低主库的访问压力。 可以在从库中执行备份，以避免备份期间影响主库的服务。 3.4 搭建步骤3.4.1 master1） 在master 的配置文件（/usr/my.cnf）中，配置如下内容： #mysql 服务ID,保证整个集群环境中唯一 server-id=1 #mysql binlog 日志的存储路径和文件名 log-bin=/var/lib/mysql/mysqlbin #错误日志,默认已经开启 #log-err #mysql的安装目录 #basedir #mysql的临时目录 #tmpdir #mysql的数据存放目录 #datadir #是否只读,1 代表只读, 0 代表读写 read-only=0 #忽略的数据, 指不需要同步的数据库 binlog-ignore-db=mysql #指定同步的数据库 #binlog-do-db=db01 2） 执行完毕之后，需要重启Mysql： service mysql restart ； 3） 创建同步数据的账户，并且进行授权操作： grant replication slave on *.* to 'itcast'@'192.168.192.131' identified by 'itcast'; flush privileges; 4） 查看master状态： show master status; 字段含义： File : 从哪个日志文件开始推送日志文件 Position ： 从哪个位置开始推送日志 Binlog_Ignore_DB : 指定不需要同步的数据库 3.4.2 slave1） 在 slave 端配置文件中，配置如下内容： #mysql服务端ID,唯一 server-id=2 #指定binlog日志 log-bin=/var/lib/mysql/mysqlbin 2） 执行完毕之后，需要重启Mysql： service mysql restart； 3） 执行如下指令 ： change master to master_host= '192.168.192.130', master_user='itcast', master_password='itcast', master_log_file='mysqlbin.000001', master_log_pos=413; 指定当前从库对应的主库的IP地址，用户名，密码，从哪个日志文件开始的那个位置开始同步推送日志。 4） 开启同步操作 start slave; show slave status; 5） 停止同步操作 stop slave; 3.4.3 验证同步操作1） 在主库中创建数据库，创建表，并插入数据 ： create database db01; user db01; create table user( id int(11) not null auto_increment, name varchar(50) not null, sex varchar(1), primary key (id) )engine=innodb default charset=utf8; insert into user(id,name,sex) values(null,'Tom','1'); insert into user(id,name,sex) values(null,'Trigger','0'); insert into user(id,name,sex) values(null,'Dawn','1'); 2） 在从库中查询数据，进行验证 ： 在从库中，可以查看到刚才创建的数据库： 在该数据库中，查询user表中的数据： 4. 综合案例4.1 需求分析在业务系统中，需要记录当前业务系统的访问日志，该访问日志包含：操作人，操作时间，访问类，访问方法，请求参数，请求结果，请求结果类型，请求时长 等信息。记录详细的系统访问日志，主要便于对系统中的用户请求进行追踪，并且在系统 的管理后台可以查看到用户的访问记录。 记录系统中的日志信息，可以通过Spring 框架的AOP来实现。具体的请求处理流程，如下： 4.2 搭建案例环境4.2.1 数据库表CREATE DATABASE mysql_demo DEFAULT CHARACTER SET utf8mb4 ； CREATE TABLE `brand` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL COMMENT '品牌名称', `first_char` varchar(1) DEFAULT NULL COMMENT '品牌首字母', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; CREATE TABLE `item` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '商品id', `title` varchar(100) NOT NULL COMMENT '商品标题', `price` double(10,2) NOT NULL COMMENT '商品价格，单位为：元', `num` int(10) NOT NULL COMMENT '库存数量', `categoryid` bigint(10) NOT NULL COMMENT '所属类目，叶子类目', `status` varchar(1) DEFAULT NULL COMMENT '商品状态，1-正常，2-下架，3-删除', `sellerid` varchar(50) DEFAULT NULL COMMENT '商家ID', `createtime` datetime DEFAULT NULL COMMENT '创建时间', `updatetime` datetime DEFAULT NULL COMMENT '更新时间', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='商品表'; CREATE TABLE `user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(45) NOT NULL, `password` varchar(96) NOT NULL, `name` varchar(45) NOT NULL, `birthday` datetime DEFAULT NULL, `sex` char(1) DEFAULT NULL, `email` varchar(45) DEFAULT NULL, `phone` varchar(45) DEFAULT NULL, `qq` varchar(32) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; CREATE TABLE `operation_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID', `operate_class` varchar(200) DEFAULT NULL COMMENT '操作类', `operate_method` varchar(200) DEFAULT NULL COMMENT '操作方法', `return_class` varchar(200) DEFAULT NULL COMMENT '返回值类型', `operate_user` varchar(20) DEFAULT NULL COMMENT '操作用户', `operate_time` varchar(20) DEFAULT NULL COMMENT '操作时间', `param_and_value` varchar(500) DEFAULT NULL COMMENT '请求参数名及参数值', `cost_time` bigint(20) DEFAULT NULL COMMENT '执行方法耗时, 单位 ms', `return_value` varchar(200) DEFAULT NULL COMMENT '返回值', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 4.2.2 pom.xml&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;mybatis.version&gt;3.4.5&lt;/mybatis.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;${mybatis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8080&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;uriEncoding&gt;utf-8&lt;/uriEncoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 4.2.3 web.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" version=\"2.5\"&gt; &lt;!-- 解决post乱码 --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 指定加载的配置文件 ，通过参数contextConfigLocation加载--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;log-datalist.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;/web-app&gt; 4.2.4 db.propertiesjdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://192.168.142.128:3306/mysql_demo jdbc.username=root jdbc.password=itcast 4.2.5 applicationContext.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 加载配置文件 --&gt; &lt;context:property-placeholder location=\"classpath:db.properties\"/&gt; &lt;!-- 配置 spring 创建容器时要扫描的包 --&gt; &lt;context:component-scan base-package=\"cn.itcast\"&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"&gt; &lt;/context:exclude-filter&gt; &lt;/context:component-scan&gt; &lt;!-- 配置 MyBatis 的 Session 工厂 --&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"typeAliasesPackage\" value=\"cn.itcast.pojo\"/&gt; &lt;/bean&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;property name=\"driverClass\" value=\"${jdbc.driver}\"&gt;&lt;/property&gt; &lt;property name=\"jdbcUrl\" value=\"${jdbc.url}\"&gt;&lt;/property&gt; &lt;property name=\"user\" value=\"${jdbc.username}\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置 Mapper 扫描器 --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"cn.itcast.mapper\"/&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器 --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!-- 配置事务的注解驱动 --&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\"&gt;&lt;/tx:annotation-driven&gt; &lt;/beans&gt; 4.2.6 springmvc.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;context:component-scan base-package=\"cn.itcast.controller\"&gt;&lt;/context:component-scan&gt; &lt;mvc:annotation-driven&gt;&lt;/mvc:annotation-driven&gt; &lt;aop:aspectj-autoproxy /&gt; &lt;/beans&gt; 4.2.7 导入基础工程 4.3 通过AOP记录操作日志4.3.1 自定义注解通过自定义注解，来标示方法需不需要进行记录日志，如果该方法在访问时需要记录日志，则在该方法上标示该注解既可。 @Inherited @Documented @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface OperateLog { } 4.3.2 定义通知类@Component @Aspect public class OperateAdvice { private static Logger log = Logger.getLogger(OperateAdvice.class); @Autowired private OperationLogService operationLogService; @Around(\"execution(* cn.itcast.controller.*.*(..)) &amp;&amp; @annotation(operateLog)\") public Object insertLogAround(ProceedingJoinPoint pjp , OperateLog operateLog) throws Throwable{ System.out.println(\" ************************ 记录日志 [start] ****************************** \"); OperationLog op = new OperationLog(); DateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); op.setOperateTime(sdf.format(new Date())); op.setOperateUser(DataUtils.getRandStr(8)); op.setOperateClass(pjp.getTarget().getClass().getName()); op.setOperateMethod(pjp.getSignature().getName()); //获取方法调用时传递的参数 Object[] args = pjp.getArgs(); op.setParamAndValue(Arrays.toString(args)); long start_time = System.currentTimeMillis(); //放行 Object object = pjp.proceed(); long end_time = System.currentTimeMillis(); op.setCostTime(end_time - start_time); if(object != null){ op.setReturnClass(object.getClass().getName()); op.setReturnValue(object.toString()); }else{ op.setReturnClass(\"java.lang.Object\"); op.setParamAndValue(\"void\"); } log.error(JsonUtils.obj2JsonString(op)); operationLogService.insert(op); System.out.println(\" ************************** 记录日志 [end] *************************** \"); return object; } } 4.3.3 方法上加注解在需要记录日志的方法上加上注解@OperateLog。 @OperateLog @RequestMapping(\"/insert\") public Result insert(@RequestBody Brand brand){ try { brandService.insert(brand); return new Result(true,\"操作成功\"); } catch (Exception e) { e.printStackTrace(); return new Result(false,\"操作失败\"); } } 4.4 日志查询后端代码实现4.4.1 Mapper接口public interface OperationLogMapper { public void insert(OperationLog operationLog); public List&lt;OperationLog&gt; selectListByCondition(Map dataMap); public Long countByCondition(Map dataMap); } 4.4.2 Mapper.xml 映射配置文件&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt; &lt;mapper namespace=\"cn.itcast.mapper.OperationLogMapper\" &gt; &lt;insert id=\"insert\" parameterType=\"operationLog\"&gt; INSERT INTO operation_log(id,return_value,return_class,operate_user,operate_time,param_and_value, operate_class,operate_method,cost_time) VALUES(NULL,#{returnValue},#{returnClass},#{operateUser},#{operateTime},#{paramAndValue}, #{operateClass},#{operateMethod},#{costTime}) &lt;/insert&gt; &lt;select id=\"selectListByCondition\" parameterType=\"map\" resultType=\"operationLog\"&gt; select id , operate_class as operateClass , operate_method as operateMethod, return_class as returnClass, operate_user as operateUser, operate_time as operateTime, param_and_value as paramAndValue, cost_time as costTime, return_value as returnValue from operation_log &lt;include refid=\"oplog_where\"/&gt; limit #{start},#{size} &lt;/select&gt; &lt;select id=\"countByCondition\" resultType=\"long\" parameterType=\"map\"&gt; select count(*) from operation_log &lt;include refid=\"oplog_where\"/&gt; &lt;/select&gt; &lt;sql id=\"oplog_where\"&gt; &lt;where&gt; &lt;if test=\"operateClass != null and operateClass != '' \"&gt; and operate_class = #{operateClass} &lt;/if&gt; &lt;if test=\"operateMethod != null and operateMethod != '' \"&gt; and operate_method = #{operateMethod} &lt;/if&gt; &lt;if test=\"returnClass != null and returnClass != '' \"&gt; and return_class = #{returnClass} &lt;/if&gt; &lt;if test=\"costTime != null\"&gt; and cost_time = #{costTime} &lt;/if&gt; &lt;/where&gt; &lt;/sql&gt; &lt;/mapper&gt; 4.4.3 Service@Service @Transactional public class OperationLogService { //private static Logger logger = Logger.getLogger(OperationLogService.class); @Autowired private OperationLogMapper operationLogMapper; //插入数据 public void insert(OperationLog operationLog){ operationLogMapper.insert(operationLog); } //根据条件查询 public PageResult selectListByCondition(Map dataMap, Integer pageNum , Integer pageSize){ if(paramMap ==null){ paramMap = new HashMap(); } paramMap.put(\"start\" , (pageNum-1)*rows); paramMap.put(\"rows\",rows); Object costTime = paramMap.get(\"costTime\"); if(costTime != null){ if(\"\".equals(costTime.toString())){ paramMap.put(\"costTime\",null); }else{ paramMap.put(\"costTime\",new Long(paramMap.get(\"costTime\").toString())); } } System.out.println(dataMap); long countStart = System.currentTimeMillis(); Long count = operationLogMapper.countByCondition(dataMap); long countEnd = System.currentTimeMillis(); System.out.println(\"Count Cost Time : \" + (countEnd-countStart)+\" ms\"); List&lt;OperationLog&gt; list = operationLogMapper.selectListByCondition(dataMap); long queryEnd = System.currentTimeMillis(); System.out.println(\"Query Cost Time : \" + (queryEnd-countEnd)+\" ms\"); return new PageResult(count,list); } } 4.4.4 Controller@RestController @RequestMapping(\"/operationLog\") public class OperationLogController { @Autowired private OperationLogService operationLogService; @RequestMapping(\"/findList\") public PageResult findList(@RequestBody Map dataMap, Integer pageNum , Integer pageSize){ PageResult page = operationLogService.selectListByCondition(dataMap, pageNum, pageSize); return page; } } 4.5 日志查询前端代码实现前端代码使用 BootStrap + AdminLTE 进行布局， 使用Vuejs 进行视图层展示。 4.5.1 js&lt;script&gt; var vm = new Vue({ el: '#app', data: { dataList:[], searchEntity:{ operateClass:'', operateMethod:'', returnClass:'', costTime:'' }, page: 1, //显示的是哪一页 pageSize: 10, //每一页显示的数据条数 total: 150, //记录总数 maxPage:8 //最大页数 }, methods: { pageHandler: function (page) { this.page = page; this.search(); }, search: function () { var _this = this; this.showLoading(); axios.post('/operationLog/findList.do?pageNum=' + _this.page + \"&amp;pageSize=\" + _this.pageSize, _this.searchEntity).then(function (response) { if (response) { _this.dataList = response.data.dataList; _this.total = response.data.total; _this.hideLoading(); } }) }, showLoading: function () { $('#loadingModal').modal({backdrop: 'static', keyboard: false}); }, hideLoading: function () { $('#loadingModal').modal('hide'); }, }, created:function(){ this.pageHandler(1); } }); &lt;/script&gt; 4.5.2 列表数据展示&lt;tr v-for=\"item in dataList\"&gt; &lt;td&gt;&lt;input name=\"ids\" type=\"checkbox\"&gt;&lt;/td&gt; &lt;td&gt;{{item.id}}&lt;/td&gt; &lt;td&gt;{{item.operateClass}}&lt;/td&gt; &lt;td&gt;{{item.operateMethod}}&lt;/td&gt; &lt;td&gt;{{item.returnClass}}&lt;/td&gt; &lt;td&gt;{{item.returnValue}}&lt;/td&gt; &lt;td&gt;{{item.operateUser}}&lt;/td&gt; &lt;td&gt;{{item.operateTime}}&lt;/td&gt; &lt;td&gt;{{item.costTime}}&lt;/td&gt; &lt;td class=\"text-center\"&gt; &lt;button type=\"button\" class=\"btn bg-olive btn-xs\"&gt;详情&lt;/button&gt; &lt;button type=\"button\" class=\"btn bg-olive btn-xs\"&gt;删除&lt;/button&gt; &lt;/td&gt; &lt;/tr&gt; 4.5.3 分页插件 &lt;div class=\"wrap\" id=\"wrap\"&gt; &lt;zpagenav v-bind:page=\"page\" v-bind:page-size=\"pageSize\" v-bind:total=\"total\" v-bind:max-page=\"maxPage\" v-on:pagehandler=\"pageHandler\"&gt; &lt;/zpagenav&gt; &lt;/div&gt; 4.6 联调测试可以通过postman来访问业务系统，再查看数据库中的日志信息，验证能不能将用户的访问日志记录下来。 4.7 分析性能问题系统中用户访问日志的数据量，随着时间的推移，这张表的数据量会越来越大，因此我们需要根据业务需求，来对日志查询模块的性能进行优化。 1） 分页查询优化 由于在进行日志查询时，是进行分页查询，那也就意味着，在查看时，至少需要查询两次： A. 查询符合条件的总记录数。–&gt; count 操作 B. 查询符合条件的列表数据。–&gt; 分页查询 limit 操作 通常来说，count() 都需要扫描大量的行（意味着需要访问大量的数据）才能获得精确的结果，因此是很难对该SQL进行优化操作的。如果需要对count进行优化，可以采用另外一种思路，可以增加汇总表，或者redis缓存来专门记录该表对应的记录数，这样的话，就可以很轻松的实现汇总数据的查询，而且效率很高，但是这种统计并不能保证百分之百的准确 。对于数据库的操作，“快速、精确、实现简单”，三者永远只能满足其二，必须舍掉其中一个。 2） 条件查询优化 针对于条件查询,需要对查询条件,及排序字段建立索引。 3） 读写分离 通过主从复制集群，来完成读写分离，使写操作走主节点， 而读操作，走从节点。 4） MySQL服务器优化 5） 应用优化 4.8 性能优化 - 分页4.8.1 优化count创建一张表用来记录日志表的总数据量： create table log_counter( logcount bigint not null )engine = innodb default CHARSET = utf8; 在每次插入数据之后，更新该表 ： &lt;update id=\"updateLogCounter\" &gt; update log_counter set logcount = logcount + 1 &lt;/update&gt; 在进行分页查询时, 获取总记录数，从该表中查询既可。 &lt;select id=\"countLogFromCounter\" resultType=\"long\"&gt; select logcount from log_counter limit 1 &lt;/select&gt; 4.8.2 优化 limit在进行分页时，一般通过创建覆盖索引，能够比较好的提高性能。一个非常常见，而又非常头疼的分页场景就是 “limit 1000000,10” ，此时MySQL需要搜索出前1000010 条记录后，仅仅需要返回第 1000001 到 1000010 条记录，前1000000 记录会被抛弃，查询代价非常大。 当点击比较靠后的页码时，就会出现这个问题，查询效率非常慢。 优化SQL： select * from operation_log limit 3000000 , 10; 将上述SQL优化为 : select * from operation_log t , (select id from operation_log order by id limit 3000000,10) b where t.id = b.id ; &lt;select id=\"selectListByCondition\" parameterType=\"map\" resultType=\"operationLog\"&gt; select id , operate_class as operateClass , operate_method as operateMethod, return_class as returnClass, operate_user as operateUser, operate_time as operateTime, param_and_value as paramAndValue, cost_time as costTime, return_value as returnValue from operation_log t, (select id from operation_log &lt;where&gt; &lt;include refid=\"oplog_where\"/&gt; &lt;/where&gt; order by id limit #{start},#{rows}) b where t.id = b.id &lt;/select&gt; 4.9 性能优化 - 索引 当根据操作人进行查询时， 查询的效率很低，耗时比较长。原因就是因为在创建数据库表结构时，并没有针对于 操作人 字段建立索引。 CREATE INDEX idx_user_method_return_cost ON operation_log(operate_user,operate_method,return_class,cost_time); 同上 ， 为了查询效率高，我们也需要对 操作方法、返回值类型、操作耗时 等字段进行创建索引，以提高查询效率。 CREATE INDEX idx_optlog_method_return_cost ON operation_log(operate_method,return_class,cost_time); CREATE INDEX idx_optlog_return_cost ON operation_log(return_class,cost_time); CREATE INDEX idx_optlog_cost ON operation_log(cost_time); 4.10 性能优化 - 排序在查询数据时，如果业务需求中需要我们对结果内容进行了排序处理 , 这个时候,我们还需要对排序的字段建立适当的索引, 来提高排序的效率 。 4.11 性能优化 - 读写分离4.11.1 概述在Mysql主从复制的基础上，可以使用读写分离来降低单台Mysql节点的压力，从而来提高访问效率，读写分离的架构如下： 对于读写分离的实现，可以通过Spring AOP 来进行动态的切换数据源，进行操作 ： 4.11.2 实现方式db.properties jdbc.write.driver=com.mysql.jdbc.Driver jdbc.write.url=jdbc:mysql://192.168.142.128:3306/mysql_demo jdbc.write.username=root jdbc.write.password=itcast jdbc.read.driver=com.mysql.jdbc.Driver jdbc.read.url=jdbc:mysql://192.168.142.129:3306/mysql_demo jdbc.read.username=root jdbc.read.password=itcast applicationContext-datasource.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 配置数据源 - Read --&gt; &lt;bean id=\"readDataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\" destroy-method=\"close\" lazy-init=\"true\"&gt; &lt;property name=\"driverClass\" value=\"${jdbc.read.driver}\"&gt;&lt;/property&gt; &lt;property name=\"jdbcUrl\" value=\"${jdbc.read.url}\"&gt;&lt;/property&gt; &lt;property name=\"user\" value=\"${jdbc.read.username}\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"${jdbc.read.password}\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置数据源 - Write --&gt; &lt;bean id=\"writeDataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\" destroy-method=\"close\" lazy-init=\"true\"&gt; &lt;property name=\"driverClass\" value=\"${jdbc.write.driver}\"&gt;&lt;/property&gt; &lt;property name=\"jdbcUrl\" value=\"${jdbc.write.url}\"&gt;&lt;/property&gt; &lt;property name=\"user\" value=\"${jdbc.write.username}\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"${jdbc.write.password}\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置动态分配的读写 数据源 --&gt; &lt;bean id=\"dataSource\" class=\"cn.itcast.aop.datasource.ChooseDataSource\" lazy-init=\"true\"&gt; &lt;property name=\"targetDataSources\"&gt; &lt;map key-type=\"java.lang.String\" value-type=\"javax.sql.DataSource\"&gt; &lt;entry key=\"write\" value-ref=\"writeDataSource\"/&gt; &lt;entry key=\"read\" value-ref=\"readDataSource\"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;property name=\"defaultTargetDataSource\" ref=\"writeDataSource\"/&gt; &lt;property name=\"methodType\"&gt; &lt;map key-type=\"java.lang.String\"&gt; &lt;entry key=\"read\" value=\",get,select,count,list,query,find\"/&gt; &lt;entry key=\"write\" value=\",add,create,update,delete,remove,insert\"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; ChooseDataSource public class ChooseDataSource extends AbstractRoutingDataSource { public static Map&lt;String, List&lt;String&gt;&gt; METHOD_TYPE_MAP = new HashMap&lt;String, List&lt;String&gt;&gt;(); /** * 实现父类中的抽象方法，获取数据源名称 * @return */ protected Object determineCurrentLookupKey() { return DataSourceHandler.getDataSource(); } // 设置方法名前缀对应的数据源 public void setMethodType(Map&lt;String, String&gt; map) { for (String key : map.keySet()) { List&lt;String&gt; v = new ArrayList&lt;String&gt;(); String[] types = map.get(key).split(\",\"); for (String type : types) { if (!StringUtils.isEmpty(type)) { v.add(type); } } METHOD_TYPE_MAP.put(key, v); } System.out.println(\"METHOD_TYPE_MAP : \"+METHOD_TYPE_MAP); } } DataSourceHandler public class DataSourceHandler { // 数据源名称 public static final ThreadLocal&lt;String&gt; holder = new ThreadLocal&lt;String&gt;(); /** * 在项目启动的时候将配置的读、写数据源加到holder中 */ public static void putDataSource(String datasource) { holder.set(datasource); } /** * 从holer中获取数据源字符串 */ public static String getDataSource() { return holder.get(); } } DataSourceAspect @Aspect @Component @Order(-9999) @EnableAspectJAutoProxy(proxyTargetClass = true) public class DataSourceAspect { protected Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 配置前置通知,使用在方法aspect()上注册的切入点 */ @Before(\"execution(* cn.itcast.service.*.*(..))\") @Order(-9999) public void before(JoinPoint point) { String className = point.getTarget().getClass().getName(); String method = point.getSignature().getName(); logger.info(className + \".\" + method + \"(\" + Arrays.asList(point.getArgs())+ \")\"); try { for (String key : ChooseDataSource.METHOD_TYPE_MAP.keySet()) { for (String type : ChooseDataSource.METHOD_TYPE_MAP.get(key)) { if (method.startsWith(type)) { System.out.println(\"key : \" + key); DataSourceHandler.putDataSource(key); break; } } } } catch (Exception e) { e.printStackTrace(); } } } 通过 @Order(-9999) 注解来控制事务管理器, 与该通知类的加载顺序 , 需要让通知类 , 先加载 , 来判定使用哪个数据源 . 4.11.3 验证在主库和从库中，执行如下SQL语句，来查看是否读的时候， 从从库中读取 ； 写入操作的时候，是否写入到主库。 show status like 'Innodb_rows_%' ; 4.11.4 原理 4.12 性能优化 - 应用优化4.12.1 缓存可以在业务系统中使用redis来做缓存，缓存一些基础性的数据，来降低关系型数据库的压力，提高访问效率。 4.12.2 全文检索如果业务系统中的数据量比较大（达到千万级别），这个时候，如果再对数据库进行查询，特别是进行分页查询，速度将变得很慢（因为在分页时首先需要count求合计数），为了提高访问效率，这个时候，可以考虑加入Solr 或者 ElasticSearch全文检索服务，来提高访问效率。 4.13.3 非关系数据库也可以考虑将非核心（重要）数据，存在 MongoDB 中，这样可以提高插入以及查询的效率。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://macongmc.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://macongmc.github.io/tags/mysql/"}],"author":"马聪"},{"title":"SQL","slug":"SQL","date":"2022-09-07T12:29:55.000Z","updated":"2022-09-07T12:29:55.000Z","comments":true,"path":"posts/4d712855.html","link":"","permalink":"https://macongmc.github.io/posts/4d712855.html","excerpt":"","text":"第一章 基本的select语句1.SQL的分类DDL:数据定义语言。create\\alter\\drop\\rename\\truncate DML:数据操作语言。insert\\delete\\update\\select CDL:数据控制语言。cimmit\\rollback\\savepoint 2.SQL语言的规则和规范2.1基本规则 2.2大小写规范 2.3注释 2.4命名规则 3.最基本的SELECT语句3.1SELECT 字段1，字段2 FROM 表名SELECT * FROM employess; *表示所有字段。 3.2列的别名使用空格，as,as加双引号 SELECT employee_id AS \"empid\" ,last_name AS \"name\",department_id FROM employees 注意：起别名中间有空格必须加双引号， 3.3去除重复行 DISTINCTDISTINCT #查询员工表一共有那些部门id SELECT department_id FROM employees; #查询员工表一共有那些部门id SELECT DISTINCT department_id FROM employees; 3.4空值参与运算#空值：NULL #null不等于0 SELECT * FROM employees SELECT employee_id,salary AS \"月工资\" ,salary*(1+commission_pct)*12 AS \"年工资\",commission_pct FROM employees SELECT employee_id,salary AS \"月工资\" ,salary*(1+IFNULL(commission_pct,0))*12 AS \"年工资\",commission_pct FROM employees IFNULL(字段，数值) 3.5着重号 ``SELECT * FROM `关键字的表名` 3.6查询常数SELECT '常数' * FROM 表名 每列都有 3.7显示表结构DESCRIBE employees DESC 表名 3.8WHERE过滤SELECT * FROM emp WHERE id =1 第二章 运算符1.算术运算符 SELECT 100+100,100+35.5,100-35.5 #查询员工id为偶数的员工信息 SELECT employee_id,last_name,salary FROM employees WHERE employee_id %2= 2.比较运算符 2.1 = &lt;=&gt; &lt;&gt;! &lt; &lt;= &gt; &gt;== #= SELECT 1=2,1!=2 有数字会隐士转化 字符串为0 有null参数比较结果为NULL &lt;=&gt;为null而生 当有的字段为null时 SELECT 1 &lt;=&gt; null,null&lt;=&gt;null,1=null 查询表中为null的数据。 SELECT * FROM employees WHERE commission_pct &lt;=&gt; NULL 2.2关键字 #is null \\ is not null \\isnull IS NULL SELECT * FROM employees WHERE commission_pct IS NULL IS NOT NULL SELECT * FROM employees WHERE commission_pct IS NOT NULL ISNULL SELECT * FROM employees WHERE ISNULL(commission_pct ) LEAST() \\ GREATEST BETWEEN AND 之前 #查询工资在6000到8000的 SELECT employee_id,last_name,salary FROM salary BETWEEN 6000 AND 8000; 闭区间 IN id in () NOT IN id NOT IN () LIKE 模糊查询 %任意字符 SELECT * FROM demo WHERE name LIKE '%a' _代表一个字符 REGEXP \\ RLIKE SELECT '字符串' REGEXO '匹配规则' 2.3逻辑运算符 第三章 排序与分页1.排序数据1.1排序规矩 使用ORDER BY 字句 ASC :升序 DESC:降序 SELECT * FROM employee ORDER BY employee_id ASC 列的别名只能在ORDER BY 使用，不能再WHERE 中使用 SELECT employee_id,salary FROM employees WHERE department_id IN (50,60) OREDR BY department_id DESC 1.2二级排序 #练习：显示员工信息，安装department_id的降序排列，salary的升序排列 SELECT employee_id,salary FROM employees WHERE department_id IN (50,60) OREDR BY department_id DESC,salary ASC; 2.分页SELECT * FROM employees LIMIT 0,2; *公式：LIMIT (pageNo-1)pageSize , pageSize; WHERE … OREDER BY … LIMIT mysql8.0新特性 LIMIT … OFFSET … 指定第几条数据 32 33 SELECT employee_id FROM employees LIMIT 2 OFFSET 31; 第四章 多表查询1.熟悉场常见的几个表DESC employees; DESC departments; DESC locations; #查询一个员工名为'Abel'的人在那个城市工作？ SELECT * FROM employees WHERE last_name = 'Abel' SELECT * FROM departments WHERE department_id = 80; select * FROM locations WHERE location_id = 2500; 2.多表查询实现#错误方式 SELECT * FROM employees,departments; 笛卡儿积错误。 正确方式 SELECT employee_id,department_name FROM employees,departments WHERE employees.department_id = departments.department_id; #查询字段中两个表都有，必须指定那张表中。 SELECT employee_id,department_name,departments.department_id FROM employees,departments WHERE employees.department_id = departments.department_id; #建议：从SQL优化的角度，建议每个字段都加上表名。 表名 可以起别名 #练习查询员工employee_id,last_name,department_name,city SELECT employee_id,last_name,department_name,city FROM employees e,departments d,locations l WHERE e.department_id=d.department_id AND d.location_id = l.location_id 3.多表查询分类角度1:等值连接 VS 非等值连接 角度2: 自连接 VS 非自连接 角度3: 内连接 VS 外连接 3.1等值 VS 非等值连接#非等值连接的例子 SELECT * FROM job_grades; SELECT last_name,salary,grade_level FROM employees e,job_grades j WHERE e.salary BETWEEN j.lowest_sal AND j.highest_sal; 3.2自连接 VS 非自连接#练习 查询员工id,员工姓名，及管理者的id和姓名 SELECT emp.employee_id,emp.last_name,mgr.employee_id,mgr.last_name FROM employees emp,employees mgr WHERE emp.manager_id = mgr.employee_id 3.3内连接 VS 外连接内连接 :合并具有同一列的两个以上的表的行，结果集中不包含一个表与另一个表不匹配的行 SELECT employee_id,department_name,departments.department_id FROM employees,departments WHERE employees.department_id = departments.department_id; 外连接：合并具有同一列的两个以上的表的行，结果集中除了匹配的行外，还查询到左表中不匹配的行。 外连接分类： SQL92语法实现内连接：见上 SQL92实现外连接：使用+ MYSQL不支持92的外连接。 SELECT employee_id,department_name,departments.department_id FROM employees,departments WHERE employees.department_id = departments.department_id(+); SQL99语法 join on 内连接 SELECT last_name,department_name FROM employees e JOIN departments d ON e.department_id=d.department_id; SELECT last_name,department_name,city FROM employees e JOIN departments d ON e.department_id=d.department_id JOIN locations l ON d.location_id=l.location_id; 左外连接： #练习 查询所有的员工的last_name,department_name信息 SELECT employee_id,department_name,departments.department_id FROM employees LEFT JOIN departments ON employees.department_id = departments.department_id; 右外连接： #练习 查询所有的员工的last_name,department_name信息 SELECT employee_id,department_name,departments.department_id FROM employees RIGHT JOIN departments ON employees.department_id = departments.department_id; MySQL不支持FULL JOIN … ON 满外连接： #练习 查询所有的员工的last_name,department_name信息 SELECT employee_id,department_name,departments.department_id FROM employees FULL JOIN departments ON employees.department_id = departments.department_id; 3.4UNION UNION 自己去重 UNION ALL 两份中间部分 去重效率低 3.5 7种SQL JOINS 的实现 中图 SELECT employee_id,department_name FROM employees e JOIN departments d ON e.department_id=d.department_id; 左上图 SELECT employee_id,department_name FROM employees e LEFT JOIN departments d ON e.department_id=d.department_id; 右上图 SELECT employee_id,department_name FROM employees e RIGHT JOIN departments d ON e.department_id=d.department_id; 左中图 SELECT employee_id,department_name FROM employees e LEFT JOIN departments d ON e.department_id=d.department_id WHERE d.department_id IS NULL; 右中图 SELECT employee_id,department_name FROM employees e RIGHT JOIN departments d ON e.department_id=d.department_id WHERE e.department_id IS NULL; 左下图 方式一 左上图 UNION ALL 右中图 SELECT employee_id,department_name FROM employees e LEFT JOIN departments d ON e.department_id=d.department_id UNION ALL SELECT employee_id,department_name FROM employees e RIGHT JOIN departments d ON e.department_id=d.department_id WHERE e.department_id IS NULL; 方式二 SELECT employee_id,department_name,departments.department_id FROM employees FULL JOIN departments ON employees.department_id = departments.department_id; 3.6 SQL99新特性SQL99 自然连接 SELECT employee_id,department_name,departments.department_id FROM employees NATURAL JOIN departments; 自动连接所有相同的字段 SQL99 USING SELECT employee_id,department_name,departments.department_id FROM employees JOIN departments USING (department_id); 状态的不同的个数 COUNT(字段==状态 OR NULL)； 第五章 聚合函数1. 聚合函数介绍什么是聚合函数 聚合函数作用于一组数据，并对一组数据返回一个值。 AVG() SUM() MAX() MIN() COUNT() 1.1AVG/SUMSELECT AVG(salary),SUM(salary)*107 From employees; 字符串求和是0； SUM(CASE STATE WHEN '0' THEN 1 ELSE 0 END) 1.2MAX/MIN适用于：数值，字符串，日期。 SELECT MAX(salary),MIN(salary) FROM employees; 1.3COUNTCOUNT(字段==状态 OR NULL)； COUNT(1); COUNT(*); #方式1：COUNT(1); #方式2：COUNT(*); #方式3;COUNT(字段); COUNT(1);=COUNT(*);&gt;COUNT(字段); 控制过滤 SELECT SUM(commission_pct) /COUNT (IFNULL(commission_pct,0)) 终极写法AVG(IFNULL) 2.GROUP BYGROUP BY ID 没有id的自己成一组； SELECT department_id,AVG(salary) FROM employees WHERE department_id &gt; 80 GROUP BY department_id WITH ROLLUP; 3.HAVING\\1. 行已经被分组。 \\2. 使用了聚合函数。 \\3. 满足HAVING 子句中条件的分组将被显示。 \\4. HAVING 不能单独使用，必须要跟 GROUP BY 一起使用。 SELECT department_id, MAX(salary) FROM employees GROUP BY department_id HAVING MAX(salary)&gt;10000 ; SELECT department_id, MAX(salary) FROM employees GROUP BY department_id HAVING MAX(salary)&gt;10000 ; 区别**1**：**WHERE** 可以直接使用表中的字段作为筛选条件，但不能使用分组中的计算函数作为筛选条件； HAVING 必须要与 GROUP BY 配合使用，可以把分组计算的函数和分组字段作为筛选条件。 这决定了，在需要对数据进行分组统计的时候，HAVING 可以完成 WHERE 不能完成的任务。这是因为， 在查询语法结构中，WHERE 在 GROUP BY 之前，所以无法对分组结果进行筛选。HAVING 在 GROUP BY 之 后，可以使用分组字段和分组中的计算函数，对分组的结果集进行筛选，这个功能是 WHERE 无法完成 的。另外，WHERE排除的记录不再包括在分组中。 区别**2**：如果需要通过连接从关联表中获取需要的数据，**WHERE** 是先筛选后连接，而 HAVING 是先连接 后筛选。 这一点，就决定了在关联查询中，WHERE 比 HAVING 更高效。因为 WHERE 可以先筛选，用一 个筛选后的较小数据集和关联表进行连接，这样占用的资源比较少，执行效率也比较高。HAVING 则需要 先把结果集准备好，也就是用未被筛选的数据集进行关联，然后对这个大的数据集进行筛选，这样占用 的资源就比较多，执行效率也较低。 4.SQL 底层原理SELECT**的执行过程** 4.1 查询的结构 4.2顺序关键字的顺序是不能颠倒的： SELECT ... FROM ... WHERE ... GROUP BY ... HAVING ... ORDER BY ... LIMIT... FROM -&gt; WHERE -&gt; GROUP BY -&gt; HAVING -&gt; SELECT 的字段 -&gt; DISTINCT -&gt; ORDER BY -&gt; LIMIT SELECT DISTINCT player_id, player_name, count(*) as num # 顺序 5 FROM player JOIN team ON player.team_id = team.team_id # 顺序 1 WHERE height &gt; 1.80 # 顺序 2 GROUP BY player.team_id # 顺序 3 HAVING num &gt; 2 # 顺序 4 ORDER BY num DESC # 顺序 6 LIMIT 2 # 顺序 7 4.3执行原理FROM ON GROUP HAVING SELECT DISTINCT ORDER BY LIMIT","categories":[{"name":"sql","slug":"sql","permalink":"https://macongmc.github.io/categories/sql/"}],"tags":[{"name":"sql","slug":"sql","permalink":"https://macongmc.github.io/tags/sql/"}],"author":"马聪"},{"title":"java8","slug":"java8","date":"2022-09-04T02:51:55.000Z","updated":"2022-09-04T02:51:55.000Z","comments":true,"path":"posts/92a2fe0d.html","link":"","permalink":"https://macongmc.github.io/posts/92a2fe0d.html","excerpt":"","text":"一.Lambda表达式1.定义lambda表达式：简化匿名内部类调用 2.Lambda表达式规范1.在接口中只能允许有一个抽象方法。 2.在函数接口中定义object类中方法。 3.使用默认或者静态方法。 4.@FunctionalInterface表示函数接口。 package com.it.javanew.service; /** * 只能定义一个接口 */ @FunctionalInterface public interface MyFunctionalInterface { void get(); default void add(){ System.out.println(\"add\"); } static void del(){ System.out.println(\"del\"); } /** * object类的方法可以在函数接口中重写 * @return */ @Override String toString(); } 3.Lambda基本语法 /** * lambda简化 * 无参调用 */ new AcanthopanaxInterface() { @Override public void get() { System.out.println(\"get\"); } }.get(); AcanthopanaxInterface acanthopanaxInterface= ()-&gt;{ System.out.println(\"使用\"); }; acanthopanaxInterface.get(); 有参调用 /** * 有参调用 */ YouShenInterface youShenInterface = new YouShenInterface() { @Override public String get(int i, int j) { return i+\"--\"+j; } }; System.out.println(youShenInterface.get(1,2)); YouShenInterface youShenInterface1=(i,j)-&gt;{ return i+\"--\"+j; }; System.out.println(youShenInterface1.get(1,3)); } 4.精简模式/** * 精简模式 * ((接口类型)(参数列表)-&gt;{ *方法体 * }).方法 */ /** * 精简模式 * ((接口类型)(参数列表)-&gt;{ *方法体 * }).方法 */ ((AcanthopanaxInterface)()-&gt;{ System.out.println(\"调用\"); }).get(); /** * 只有一条语句不需要{} */ AcanthopanaxInterface acanthopanaxInterface1 = ()-&gt; System.out.println(\"简化\"); ((AcanthopanaxInterface)()-&gt; System.out.println(\"简化\")).get(); YouShenInterface youShenInterface2 =(i,j)-&gt;j+\"--\"+i; String s = ((YouShenInterface) (i, j) -&gt; i + \"--\" + j).get(1, 2); 5.集合使用/** * 集合使用 */ List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(\"1\"); list.add(\"2\"); list.forEach(s-&gt;{ System.out.println(s); }); /** * 集合使用 */ List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(\"1\"); list.add(\"2\"); list.forEach(s-&gt;{ System.out.println(s); }); /** * 集合排序 */ List&lt;User&gt; userList = new ArrayList&lt;&gt;(); userList.add(new User(\"1\",1)); userList.add(new User(\"2\",2)); userList.add(new User(\"3\",3)); userList.sort(new Comparator&lt;User&gt;() { @Override public int compare(User o1, User o2) { return o1.getYear()-o2.getYear(); } }); userList.sort(((o1, o2) -&gt; o1.getYear()-o2.getYear())); /** * 多线程 */ new Thread(new Runnable() { @Override public void run() { System.out.println(\"线程开始\"); } }).start(); new Thread(()-&gt; System.out.println(\"线程开始\")).start(); 二.stream流stream:非常方便精简的形式遍历集合实现过滤查询排序； 1.创建流的方式1.串行流l ist.stream();2.并行流 list.parallelStream(); 2.操作//转换set集合 重复数据删除 Set&lt;String&gt; collect = stream.collect(Collectors.toSet()); collect.forEach(s -&gt; System.out.println(s)); list.parallelStream(); /** * 转化为map */ ArrayList&lt;User&gt; users = new ArrayList&lt;&gt;(); users.add(new User(\"java\",1)); users.add(new User(\"c\",2)); users.add(new User(\"c++\",3)); users.stream().collect(Collectors.toMap(User::getName,User::getYear)); List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(\"c++\"); list.add(\"c\"); list.add(\"java\"); /** * 串行 */ Stream&lt;String&gt; stream = list.stream(); //转换set集合 重复数据删除 Set&lt;String&gt; collect = stream.collect(Collectors.toSet()); collect.forEach(s -&gt; System.out.println(s)); list.parallelStream(); /** * 转化为map */ ArrayList&lt;User&gt; users = new ArrayList&lt;&gt;(); users.add(new User(\"java\",1)); users.add(new User(\"c\",2)); users.add(new User(\"c++\",3)); users.stream().collect(Collectors.toMap(User::getName,User::getYear)); /** * 求和 */ Stream&lt;Integer&gt; integerStream = Stream.of(10, 20, 30); integerStream.reduce(new BinaryOperator&lt;Integer&gt;() { @Override public Integer apply(Integer integer, Integer integer2) { return integer+integer2; } }); integerStream.reduce((integer, integer2) -&gt; integer+integer2); /** * match */ boolean b = users.stream().allMatch(new Predicate&lt;User&gt;() { @Override public boolean test(User user) { return \"java\".equals(user.getName()); } }); users.stream().allMatch(user -&gt; \"java\".equals(user.getName())); /** * 过滤器 */ users.stream().filter(new Predicate&lt;User&gt;() { @Override public boolean test(User user) { return \"java\".equals(user.getName()); } }); users.stream().filter(user -&gt; \"java\".equals(user.getName())); /** * 分页 */ users.stream().skip(1).limit(2).forEach(user -&gt; System.out.println(user.getName())); /** * 排序 */ users.stream().sorted((u1,u2)-&gt; u2.getYear()-u1.getYear()); 三.方法引入 4.giteehttps://gitee.com/macongxuexi/javanew.git","categories":[{"name":"流","slug":"流","permalink":"https://macongmc.github.io/categories/%E6%B5%81/"}],"tags":[{"name":"java","slug":"java","permalink":"https://macongmc.github.io/tags/java/"}],"author":"马聪"},{"title":"Git","slug":"Git","date":"2022-09-01T01:47:44.000Z","updated":"2022-09-01T01:47:44.000Z","comments":true,"path":"posts/69c3279c.html","link":"","permalink":"https://macongmc.github.io/posts/69c3279c.html","excerpt":"","text":"一.上传代码步骤1.代码编写完毕 添加到暂存区git add xx; git stash; 2.把线上最新代码合并到自己的代码 3.释放暂存区 如果和线上有代码冲突，在此处解决冲突。 git pop 4.提交代码 5.提交到远程自己的分支 二.合并提交记录当上次提交的代码出错或有两次提交，进行合并。 合并步骤， 重复上述步骤到释放commit. 1.进行合拼 2.push 三.IDEA git和GitLab失去联系1.问题错误信息 2.问题解决方式修改远程Remote 修改前 git remote add origin http://localhost/study/study_project.git 修改后 git remote add origin http://username:password@localhost/study/study_project.git 四.命令总结切换远程分支 git checkout -b 本地分支名 origin/远程分支名 添加到暂存区 git add xx; git stash; 更新本地代码 git pull origin xx; git fetch origin master; git merge origin/master mc-dev 释放暂存区 git stash pop; 解决冲突后 回退版本 git reset --hard commit撤销 git revert commitId 提交代码 git commit -am 'xxx' 获取另外分支的commit git cherry-pick 合并成一条commit git log git rebase -i xxx 改成s 保存 编辑 注释 刷新到远程分支 git push origin xxx 审视错误代码 重新合并 git push -f origin 增量代码包 git diff commitID HEAD --name-only | xargs tar -rf name.tar","categories":[{"name":"Git","slug":"Git","permalink":"https://macongmc.github.io/categories/Git/"}],"tags":[{"name":"git","slug":"git","permalink":"https://macongmc.github.io/tags/git/"}],"author":"马聪"},{"title":"RabbitMQ 高级特性","slug":"RabbitMQ-高级特性","date":"2022-08-26T06:03:31.000Z","updated":"2022-08-26T06:03:31.000Z","comments":true,"path":"posts/cce8d692.html","link":"","permalink":"https://macongmc.github.io/posts/cce8d692.html","excerpt":"","text":"一.RabbitMQ高级 学习目标 掌握RabbitMQ 高级特性 理解RabbitMQ 应用问题 能够搭建RabbitMQ 集群 二. RabbitMQ 高级特性 1.消息可靠性投递在使用 RabbitMQ 的时候，作为消息发送方希望杜绝任何消息丢失或者投递失败场景。RabbitMQ 为我们提供了两种方式用来控制消息的投递可靠性模式。 confirm 确认模式 return 退回模式 rabbitmq 整个消息投递的路径为： producer —&gt; rabbitmq broker —&gt; exchange —&gt; queue —&gt; consumer 消息从 producer 到 exchange 则会返回一个 confirmCallback 。 消息从 exchange 到 queue 投递失败则会返回一个 returnCallback 。 我们将利用这两个 callback 控制消息的可靠性投递 （1）confirm确认模式代码实现1.添加依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 2.配置文件 spring: rabbitmq: host: localhost port: 5672 virtual-host: / username: guest password: guest 3.配置交换机和队列 package com.it.rabbitmq.config; import org.springframework.amqp.core.*; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RabbitConfig { //发布订阅模式 //交换机名称 public static final String FANOUT_EXCHAGE = \"boot_fanout_exchange\"; //队列名称 public static final String FANOUT_QUEUE_1 = \"boot_fanout_queue_1\"; //队列名称 public static final String FANOUT_QUEUE_2 = \"boot_fanout_queue_2\"; @Bean(FANOUT_QUEUE_1) public Queue FANOUT_QUEUE_1(){ return new Queue(FANOUT_QUEUE_1,true,false,false,null); } @Bean(FANOUT_QUEUE_2) public Queue FANOUT_QUEUE_2(){ return new Queue(FANOUT_QUEUE_2,true,false,false,null); } @Bean(FANOUT_EXCHAGE) public Exchange FANOUT_EXCHAGE(){ return ExchangeBuilder.fanoutExchange(FANOUT_EXCHAGE).durable(true).build(); } @Bean public Binding FANOUT_QUEUE_1_FANOUT_EXCHAGE(@Qualifier(FANOUT_QUEUE_1) Queue queue, @Qualifier(FANOUT_EXCHAGE) Exchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(\"\").noargs(); } @Bean public Binding FANOUT_QUEUE_2_FANOUT_EXCHAGE(@Qualifier(FANOUT_QUEUE_2) Queue queue, @Qualifier(FANOUT_EXCHAGE) Exchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(\"\").noargs(); } } 编写发送方 @Test public void confirm(){ rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() { /** * * @param correlationData 相关配置信息 * @param ack exchange交换机 是否成功收到了消息。true 成功，false代表失败 * @param cause 失败原因 */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) { System.out.println(\"confirm方法被执行了....\"); if (ack) { //接收成功 System.out.println(\"接收成功消息\" + cause); } else { //接收失败 System.out.println(\"接收失败消息\" + cause); //做一些处理，让消息再次发送。 } } }); String hello = \"hello\"; rabbitTemplate.convertAndSend(RabbitConfig.FANOUT_EXCHAGE,\"\",hello); } 改配置文件 spring: rabbitmq: host: localhost port: 5672 virtual-host: / username: guest password: guest publisher-confirm-type: correlated #开启确认模式 （2） return退回模式代码实现回退模式： 当消息发送给Exchange后，Exchange路由到Queue失败是 才会执行 ReturnCallBack，具体实现如下： 修改配置文件 spring: rabbitmq: host: localhost port: 5672 virtual-host: / username: guest password: guest # publisher-confirm-type: correlated #开启确认模式 publisher-returns: true 编写生产者 //设置交换机处理失败消息的模式 rabbitTemplate.setMandatory(true); @Test public void returns(){ //设置交换机处理失败消息的模式 rabbitTemplate.setMandatory(true); rabbitTemplate.setReturnsCallback(new RabbitTemplate.ReturnsCallback() { /** * * @param message 消息对象 * @param replyCode 错误码 * @param replyText 错误信息 * @param exchange 交换机 * @param routingKey 路由键 */ @Override public void returnedMessage(ReturnedMessage returnedMessage) { System.out.println(\"returnedMessage.getMessage() = \" + returnedMessage.getMessage()); System.out.println(\"returnedMessage.getExchange() = \" + returnedMessage.getExchange()); System.out.println(\"returnedMessage.getReplyText() = \" + returnedMessage.getReplyText()); System.out.println(\"returnedMessage.getRoutingKey() = \" + returnedMessage.getRoutingKey()); System.out.println(\"returnedMessage.getReplyCode() = \" + returnedMessage.getReplyCode()); } }); String hello = \"hello\"; //成功发送案例 rabbitTemplate.convertAndSend(RabbitConfig.FANOUT_EXCHAGE,\"hello\",hello); } 成功无返回 对于确认模式： 设置ConnectionFactory的publisher-confirms=”true” 开启 确认模式。 使用rabbitTemplate.setConfirmCallback设置回调函数。当消息发送到exchange后回调confirm方法。在方法中判断ack，如果为true，则发送成功，如果为false，则发送失败，需要处理。 对于退回模式 设置ConnectionFactory的publisher-returns=”true” 开启 退回模式。 使用rabbitTemplate.setReturnCallback设置退回函数，当消息从exchange路由到queue失败后，如果设置了rabbitTemplate.setMandatory(true)参数，则会将消息退回给producer。并执行回调函数returnedMessage。 在RabbitMQ中也提供了事务机制，但是性能较差，此处不做讲解。 使用channel列方法，完成事务控制： txSelect(), 用于将当前channel设置成transaction模式 txCommit()，用于提交事务 txRollback(),用于回滚事务 2.Consumer ACKack指 Acknowledge，确认。 表示消费端收到消息后的确认方式。 有三种确认方式： • 自动确认：acknowledge=”none“ • 手动确认：acknowledge=”manual“ • 根据异常情况确认：acknowledge=”auto“，（这种方式使用麻烦，不作讲解） 其中自动确认是指，当消息一旦被Consumer接收到，则自动确认收到，并将相应 message 从 RabbitMQ 的消息缓存中移除。但是在实际业务处理中，很可能消息接收到，业务处理出现异常，那么该消息就会丢失。 如果设置了手动确认方式，则需要在业务处理成功后，调用channel.basicAck()，手动签收，如果出现异常，则调用channel.basicNack()方法，让其自动重新发送消息。 改配置文件 spring: rabbitmq: host: localhost port: 5672 virtual-host: / username: guest password: guest publisher-returns: true listener: direct: acknowledge-mode: manual 编写监听器 @RabbitListener(queues = RabbitConfig.FANOUT_QUEUE_2) public void receiveMsg(Message orderMsg, Channel channel,@Header(AmqpHeaders.DELIVERY_TAG) long tag) throws IOException { byte[] body = orderMsg.getBody(); String s = new String(body); if (s.equals(\"hello\")){ System.out.println(\"ok\"); channel.basicAck(tag, false); }else { channel.basicNack(tag, false, false); } } 消息的接收者也可使用普通类实现ChannelAwareMessageListener接口，重写方法完成，这种是直接全局性接收的。没有最好的，只有最合适的，根据项目情况选择全局接收还是单个类接收自己监听的。 /** * 接收者 * **/ @Component public class Consumer implements ChannelAwareMessageListener { @Override public void onMessage(Message message, Channel channel) throws Exception { long deliveryTag = message.getMessageProperties().getDeliveryTag(); try { if (\"queue_name\".equals(message.getMessageProperties().getConsumerQueue())) { System.out.println(\"消费的消息来自的队列名为：\"+message.getMessageProperties().getConsumerQueue()); System.out.println(\"接收消息: \" + new String(message.getBody(), \"UTF-8\")); System.out.println(\"执行queue_name中的消息的业务处理流程......\"); } if (\"fanout.A\".equals(message.getMessageProperties().getConsumerQueue())) { System.out.println(\"消费的消息来自的队列名为：\" + message.getMessageProperties().getConsumerQueue()); System.out.println(\"接收消息: \" + new String(message.getBody(), \"UTF-8\")); System.out.println(\"执行fanout.A中的消息的业务处理流程......\"); } // 手动提交ack，并且批量确认消息 channel.basicAck(deliveryTag, true); } catch (Exception e) { e.printStackTrace(); /** * 拒绝消息，参数说明： * long deliveryTag：唯一标识 ID。 * boolean requeue：如果 requeue 参数设置为 true， * 则 RabbitMQ 会重新将这条消息存入队列，以便发送给下一个订阅的消费者； * 如果 requeue 参数设置为 false，则 RabbitMQ 立即会还把消息从队列中移除， * 而不会把它发送给新的消费者。 */ channel.basicReject(deliveryTag, true); } } } 3.消费端限流rabbitmq: #服务器 host: 192.168.174.182 #用户名 username: guest #密码 password: guest #虚拟机 virtual-host: / #端口 port: 5672 #监听 listener: simle: #消费者最下数量 concurrency: 10 #消费者最大数量 max-concurrency: 10 #限制消费者每次只处理一条信息，处理完在继续下一条 prefetch: 1 #启动时是否默认启动容器 auto-startup: ture #被拒绝时重新进入队列 default-requeue-rejected: ture #模板 template: retry: #发布重试，默认false enabled: true #重试时间 默认1000ms initial-interval: 1000ms #重试最大次数 最大3 max-attempts: 3 #重试最大间隔时间 max-interval: 10000ms #重试的时间隔乘数，比如配2，0 第一次等于10s，第二次等于20s，第三次等于40s multiplier: 1 配置文件中进行配置 4.TTL设置队列参数、交换机参数、发消息都可以用页面。 也能用代码。 TTL 全称 Time To Live（存活时间/过期时间）。当消息到达存活时间后，还没有被消费，会被自动清除。 RabbitMQ可以对消息设置过期时间，也可以对整个队列（Queue）设置过期时间。 设置队列的过期时间 import org.springframework.amqp.core.Binding; import org.springframework.amqp.core.BindingBuilder; import org.springframework.amqp.core.DirectExchange; import org.springframework.amqp.core.Queue; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.util.HashMap; import java.util.Map; @Configuration public class DirectRabbitConfig { //队列 起名：TestDirectQueue @Bean public Queue TestDirectQueue() { // durable:是否持久化,默认是false,持久化队列：会被存储在磁盘上，当消息代理重启时仍然存在，暂存队列：当前连接有效 // exclusive:默认也是false，只能被当前创建的连接使用，而且当连接关闭后队列即被删除。此参考优先级高于durable // autoDelete:是否自动删除，当没有生产者或者消费者使用此队列，该队列会自动删除。 Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); // 队列中的消息未被消费则10秒后过期 map.put(\"x-message-ttl\", 10000); return new Queue(\"TestDirectQueue\", true, false, false, map); } //Direct交换机 起名：TestDirectExchange @Bean DirectExchange TestDirectExchange() { return new DirectExchange(\"TestDirectExchange\", true, false); } //绑定 将队列和交换机绑定, 并设置用于匹配键：TestDirectRouting @Bean Binding bindingDirect() { return BindingBuilder.bind(TestDirectQueue()).to(TestDirectExchange()).with(\"TestDirectRouting\"); } } 单独设置某条消息的方式 import cn.huawei.rabbitmqtest1.pojo.User; import com.alibaba.fastjson.JSON; import org.springframework.amqp.core.Message; import org.springframework.amqp.core.MessageProperties; import org.springframework.amqp.rabbit.connection.CorrelationData; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import java.nio.charset.StandardCharsets; import java.util.UUID; @RestController public class SendMessageController { @Autowired RabbitTemplate rabbitTemplate; //使用RabbitTemplate,这提供了接收/发送等等方法 @GetMapping(\"/sendDirectMessage\") public void sendDirectMessage() { MessageProperties messageProperties = new MessageProperties(); // 设置过期时间，单位：毫秒 messageProperties.setExpiration(\"30000\"); for (int i = 1; i &lt;= 50; i++) { //这个参数是用来做消息的唯一标识 //发布消息时使用，存储在消息的headers中 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); User user = new User(i + \"\", \"陈四 \" + i); Message message = new Message(JSON.toJSONString(user).getBytes(StandardCharsets.UTF_8), messageProperties); rabbitTemplate.convertAndSend(\"TestDirectExchange\", \"TestDirectRouting\", message, correlationData); } } } 注解方式 //在队列设置超时时间 @RabbitListener(bindings = { @QueueBinding(value = @Queue(value = \"liveQueue\", arguments = {@Argument(name = \"x-dead-letter-exchange\", value = \"deadExchange\"), @Argument(name = \"x-dead-letter-routing-key\", value = \"deadKey\") , @Argument(name = \"x-message-ttl\",value = \"10000\",type = \"java.lang.Integer\") // ,@Argument(name = \"x-max-length\",value = \"5\",type = \"java.lang.Integer\")队列最大长度 }),//可以指定多种属性 exchange = @Exchange(value = \"liveExchange\"), key = {\"info\", \"error\", \"warning\"} ) }) @RabbitHandler public void onMessage(Message message, Channel channel) throws Exception { long consumerTag = message.getMessageProperties().getDeliveryTag(); System.out.println(\"收到消息\"); System.out.println(new String(message.getBody())); channel.basicNack(consumerTag, false, false);//消息确认 } 5.死信队列消息成为死信的三种情况： 队列消息长度到达限制； 消费者拒接消费消息，basicNack/basicReject,并且不把消息重新放入原目标队列,requeue=false； 原队列存在消息过期设置，消息到达超时时间未被消费； 队列绑定死信交换机： 给队列设置参数： x-dead-letter-exchange 和 x-dead-letter-routing-key 在消息的生产方中，在 spring-rabbitmq-producer.xml 配置文件中，添加如下配置 @Configuration public class RabbitMQConfig { // 声明业务Exchange @Bean public TopicExchange businessExchange(){ return new TopicExchange(\"businessExchange\"); } // 声明业务队列A @Bean public Queue businessQueue(){ Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); // x-dead-letter-exchange 这里声明当前队列绑定的死信交换机 args.put(\"x-dead-letter-exchange\", \"deadLetterExchange\"); // x-dead-letter-routing-key 这里声明当前队列的死信路由key args.put(\"x-dead-letter-routing-key\", \"dle.err\"); return new Queue(\"businessQueue\",true,false,false,args); } // 声明业务队列A绑定关系 @Bean public Binding businessBinding(Queue businessQueue, TopicExchange businessExchange){ return BindingBuilder.bind(businessQueue).to(businessExchange).with(\"emp.*\"); } //声明死信Exchange @Bean public TopicExchange deadLetterExchange(){ return new TopicExchange(\"deadLetterExchange\"); } // 声明死信队列A @Bean public Queue deadLetterQueue(){ return new Queue(\"dle-queue\"); } @Bean public Binding deadLetterQueueBinding(Queue deadLetterQueue, TopicExchange deadLetterExchange){ return BindingBuilder.bind(deadLetterQueue).to(deadLetterExchange).with(\"dle.*\"); } } @Component public class DedaLetterListener { // 监听业务队列 @RabbitListener(queues = \"businessQueue\") public void businessQueue(String msg, Channel channel, Message message) throws IOException { if (\"error\".equals(msg)) { System.out.println(\"业务消费者出现问题:\" + msg); try { throw new RuntimeException(); }catch (Exception e){ // 无法消费消息，nack channel.basicNack(message.getMessageProperties().getDeliveryTag(),false,false); } } else { System.out.println(\"正常消费消息:\" + msg); // 正常消费了消息，手动ack channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); } } // 监听死信队列 @RabbitListener(queues = \"dle-queue\") public void deadLetterQueue(String msg, Channel channel, Message message) throws IOException { System.out.println(\"死信队列消费消息:\" + msg); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); } } 参数说明 // deliveryTag:该消息的index // multiple：是否批量.true:将一次性ack所有小于deliveryTag的消息。 public void basicAck(long deliveryTag, boolean multiple) //deliveryTag:该消息的index //multiple：是否批量.true:将一次性拒绝所有小于deliveryTag的消息。 //requeue：是否重新入队列 public void basicNack(long deliveryTag, boolean multiple, boolean requeue) 死信交换机和死信队列和普通的没有区别 当消息成为死信后，如果该队列绑定了死信交换机，则消息会被死信交换机重新路由到死信队列 消息成为死信的三种情况： 队列消息长度到达限制； 消费者拒接消费消息，并且不重回队列； 原队列存在消息过期设置，消息到达超时时间未被消费； 6.延迟队列-重点延迟队列，即消息进入队列后不会立即被消费，只有到达指定时间后，才会被消费。 提出需求： 下单后，30分钟未支付，取消订单，回滚库存。 新用户注册成功7天后，发送短信问候。 实现方式： 定时器（不优雅！） 延迟队列 注意：在RabbitMQ中并未提供延迟队列功能。 但是可以使用：TTL+死信队列 组合实现延迟队列的效果。 gitee地址https://gitee.com/macongxuexi/RabbitMQSenior.git","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://macongmc.github.io/categories/RabbitMQ/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://macongmc.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"RabbitMQ","slug":"RabbitMQ","date":"2022-08-25T05:56:10.000Z","updated":"2022-08-25T05:56:10.000Z","comments":true,"path":"posts/b543ced0.html","link":"","permalink":"https://macongmc.github.io/posts/b543ced0.html","excerpt":"","text":"一.消息中间件MQ全称为Message Queue，消息队列是应用程序和应用程序之间的通信方法。 1.MQ的优劣势优势： 应用解耦 异步调用 消峰添谷 缺点： 系统可用性降低 系统复杂度提高 一致性问题 解决：消息重复 消息丢失 消息顺序 消息一致性（失败） 2.MQ的应用场合① 生产者不需要从消费者处获得反馈。引入消息队列之前的直接调用，其接口的返回值应该为空，这才让明 明下层的动作还没做，上层却当成动作做完了继续往后走，即所谓异步成为了可能。 ② 容许短暂的不一致性。 ③ 确实是用了有效果。即解耦、提速、削峰这些方面的收益，超过加入MQ，管理MQ这些成本。 3.MQ产品 4.特点1.使用简单，功能强大 2.跨语言 3.社区活跃，文档完善 4.高并发性能好 5.spring boot 默认集成 5.工作模式RabbitMQ提供了6种模式：简单模式，work模式，Publish/Subscribe发布与订阅模式，Routing路由模式，Topics主题模式，RPC远程调用模式（远程调用，不太算MQ；暂不作介绍）； 官网对应模式介绍：https://www.rabbitmq.com/getstarted.html 二.RabbitMQ工作原理1.重点： http 三次握手 四次挥手 一个长连接 一个消费者监听“一个”“队列” Broker：消息队列服务进程，此进程包括两个部分：Exchange和Queue。 Exchange：消息队列交换机，按一定的规则将消息路由转发到某个队列，对消息进行过虑。 Queue：消息队列，存储消息的队列，消息到达队列并转发给指定的消费方。 Producer：消息生产者，即生产方客户端，生产方客户端将消息发送到MQ。 Consumer：消息消费者，即消费方客户端，接收MQ转发的消息。 消息发布接收流程： —–发送消息—– 1、生产者和Broker建立TCP连接。 2、生产者和Broker建立通道。 3、生产者通过通道消息发送给Broker，由Exchange将消息进行转发。 4、Exchange将消息转发到指定的Queue（队列） —-接收消息—– 1、消费者和Broker建立TCP连接 2、消费者和Broker建立通道 3、消费者监听指定的Queue（队列） 4、当有消息到达Queue时Broker默认将消息推送给消费者。 5、消费者接收到消息。 2.RabbitMQ运转流程在入门案例中： 生产者发送消息 生产者创建连接（Connection），开启一个信道（Channel），连接到RabbitMQ Broker； 声明队列并设置属性；如是否排它，是否持久化，是否自动删除； 将路由键（空字符串）与队列绑定起来； 发送消息至RabbitMQ Broker； 关闭信道； 关闭连接； 消费者接收消息 消费者创建连接（Connection），开启一个信道（Channel），连接到RabbitMQ Broker 向Broker 请求消费相应队列中的消息，设置相应的回调函数； 等待Broker回应闭关投递响应队列中的消息，消费者接收消息； 确认（ack，自动确认）接收到的消息； RabbitMQ从队列中删除相应已经被确认的消息； 关闭信道； 关闭连接； 3.生产者流转过程说明 客户端与代理服务器Broker建立连接。会调用newConnection() 方法,这个方法会进一步封装Protocol Header 0-9-1 的报文头发送给Broker ，以此通知Broker 本次交互采用的是AMQPO-9-1 协议，紧接着Broker 返回Connection.Start 来建立连接，在连接的过程中涉及Connection.Start/.Start-OK 、Connection.Tune/.Tune-Ok ，Connection.Open/ .Open-Ok 这6 个命令的交互。 客户端调用connection.createChannel方法。此方法开启信道，其包装的channel.open命令发送给Broker,等待channel.basicPublish方法，对应的AMQP命令为Basic.Publish,这个命令包含了content Header 和content Body()。content Header 包含了消息体的属性，例如:投递模式，优先级等，content Body 包含了消息体本身。 客户端发送完消息需要关闭资源时，涉及到Channel.Close和Channl.Close-Ok 与Connetion.Close和Connection.Close-Ok的命令交互。 4.消费者流转过程说明 消费者客户端与代理服务器Broker建立连接。会调用newConnection() 方法,这个方法会进一步封装Protocol Header 0-9-1 的报文头发送给Broker ，以此通知Broker 本次交互采用的是AMQPO-9-1 协议，紧接着Broker 返回Connection.Start 来建立连接，在连接的过程中涉及Connection.Start/.Start-OK 、Connection.Tune/.Tune-Ok ，Connection.Open/ .Open-Ok 这6 个命令的交互。 消费者客户端调用connection.createChannel方法。和生产者客户端一样，协议涉及Channel . Open/Open-Ok命令。 在真正消费之前，消费者客户端需要向Broker 发送Basic.Consume 命令(即调用channel.basicConsume 方法〉将Channel 置为接收模式，之后Broker 回执Basic . Consume - Ok 以告诉消费者客户端准备好消费消息。 Broker 向消费者客户端推送(Push) 消息，即Basic.Deliver 命令，这个命令和Basic.Publish 命令一样会携带Content Header 和Content Body。 消费者接收到消息并正确消费之后，向Broker 发送确认，即Basic.Ack 命令。 客户端发送完消息需要关闭资源时，涉及到Channel.Close和Channl.Close-Ok 与Connetion.Close和Connection.Close-Ok的命令交互。 三.入门1.启动在sbin目录下，管理员身份运行cmd rabbitmq-plugins.bat enable rabbitmq_management http://localhost:15672/ username:guest password:guest 2.简单模式 依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 编写生产者 package com.ydlclass.rabbitmq.simple; import com.rabbitmq.client.AMQP; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConnectionFactory; import java.io.IOException; import java.util.concurrent.TimeoutException; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ public class Producer { public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory=new ConnectionFactory(); //连接的ip connectionFactory.setHost(\"localhost\"); //连接的端口 connectionFactory.setPort(5672); //设置虚拟主机 connectionFactory.setVirtualHost(\"/\"); //设置用户名 connectionFactory.setUsername(\"guest\"); //设置密码 connectionFactory.setPassword(\"guest\"); //2创建长连接 Connection connection = connectionFactory.newConnection(); //3创建channel Channel channel = connection.createChannel(); //声明队列 //String queue, 队列名 // boolean durable, 持久化 // boolean exclusive, 排他的 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.queueDeclare(\"ydlqueue\",true,false,false,null); //4发消息 // String exchange, 交换机 // String routingKey, 路由键 // AMQP.BasicProperties props, 属性 // byte[] body 消息 string byte[] char[]如何相互转换的？ String msg=\"hello rabbitmq!\"; channel.basicPublish(\"\",\"ydlqueue\",null,msg.getBytes()); //5关闭连接 资源关闭的顺序，先关后出来的资源，最后关，第一个资源 channel.close(); connection.close(); } } 编写消费者 package com.ydlclass.rabbitmq.simple; import com.ydlclass.rabbitmq.util.ConnectionUtil; import com.rabbitmq.client.*; import java.io.IOException; public class Consumer { static final String QUEUE_NAME = \"simple_queue\"; public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory = new ConnectionFactory(); //主机地址;默认为 localhost connectionFactory.setHost(\"localhost\"); //连接端口;默认为 5672 connectionFactory.setPort(5672); //虚拟主机名称;默认为 / connectionFactory.setVirtualHost(\"/\"); //连接用户名；默认为guest connectionFactory.setUsername(\"itlils\"); //连接密码；默认为guest connectionFactory.setPassword(\"itlils\"); //2创建连接 Connection connection = connectionFactory.newConnection(); //3创建频道 Channel channel = connection.createChannel(); //6声明（创建）队列 /** * 参数1：队列名称 * 参数2：是否定义持久化队列 * 参数3：是否独占本次连接 * 参数4：是否在不使用的时候自动删除队列 * 参数5：队列其它参数 */ channel.queueDeclare(QUEUE_NAME, true, false, false, null); //5创建消费者；并设置消息处理 DefaultConsumer consumer = new DefaultConsumer(channel){ @Override /** * consumerTag 消息者标签，在channel.basicConsume时候可以指定 * envelope 消息包的内容，可从中获取消息id，消息routingkey，交换机，消息和重传标志(收到消息失败后是否需要重新发送) * properties 属性信息 * body 消息 */ public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { //消费者标签 System.out.println(\"消费者标签为：\" + consumerTag); //路由key System.out.println(\"路由key为：\" + envelope.getRoutingKey()); //交换机 System.out.println(\"交换机为：\" + envelope.getExchange()); //消息id System.out.println(\"消息id为：\" + envelope.getDeliveryTag()); //收到的消息 System.out.println(\"接收到的消息为：\" + new String(body, \"utf-8\")); } }; //4监听消息 /** * 参数1：队列名称 * 参数2：是否自动确认，设置为true为表示消息接收到自动向mq回复接收到了，mq接收到回复会删除消息，设置为false则需要手动确认 * 参数3：消息接收到后回调 */ channel.basicConsume(QUEUE_NAME, true, consumer); //不关闭资源，应该一直监听消息 //channel.close(); //connection.close(); } } 3.工作队列模式 Work Queues与入门程序的简单模式相比，多了一个或一些消费端，多个消费端共同消费同一个队列中的消息。 应用场景：对于 任务过重或任务较多情况使用工作队列可以提高任务处理的速度。 生产者，多运行几次，观察连个消费者 设置，消费者能启多份： 4. 订阅发布模式类型（微博） 前面2个案例中，只有3个角色： P：生产者，也就是要发送消息的程序 C：消费者：消息的接受者，会一直等待消息到来。 queue：消息队列，图中红色部分 而在订阅模型中，多了一个exchange角色，而且过程略有变化： P：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机） C：消费者，消息的接受者，会一直等待消息到来。 Queue：消息队列，接收消息、缓存消息。 Exchange：交换机，图中的X。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有常见以下3种类型： Fanout：广播，将消息交给所有绑定到交换机的队列 Direct：定向，把消息交给符合指定routing key 的队列 Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列 Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！ 生产者 package com.ydlclass.rabbitmq.simple; import com.rabbitmq.client.BuiltinExchangeType; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConnectionFactory; /** * creste by ydlclass. */ public class Producer_pubsub { //交换机名称 static final String FANOUT_EXCHAGE = \"fanout_exchange\"; //队列名称 static final String FANOUT_QUEUE_1 = \"fanout_queue_1\"; //队列名称 static final String FANOUT_QUEUE_2 = \"fanout_queue_2\"; public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory = new ConnectionFactory(); //主机地址;默认为 localhost connectionFactory.setHost(\"localhost\"); //连接端口;默认为 5672 connectionFactory.setPort(5672); //虚拟主机名称;默认为 / connectionFactory.setVirtualHost(\"/\"); //连接用户名；默认为guest connectionFactory.setUsername(\"itlils\"); //连接密码；默认为guest connectionFactory.setPassword(\"itlils\"); //2创建连接 Connection connection = connectionFactory.newConnection(); //3创建频道 Channel channel = connection.createChannel(); /** * 声明交换机 * 参数1：交换机名称 * 参数2：交换机类型，fanout、topic、direct、headers * 参数3：是否定义持久化 * 参数4：是否在不使用的时候自动删除 */ channel.exchangeDeclare(FANOUT_EXCHAGE, BuiltinExchangeType.FANOUT,true,true,null); // 声明（创建）队列 /** * 参数1：队列名称 * 参数2：是否定义持久化队列 * 参数3：是否独占本次连接 * 参数4：是否在不使用的时候自动删除队列 * 参数5：队列其它参数 */ channel.queueDeclare(FANOUT_QUEUE_1, true, false, false, null); channel.queueDeclare(FANOUT_QUEUE_2, true, false, false, null); //队列绑定交换机 channel.queueBind(FANOUT_QUEUE_1, FANOUT_EXCHAGE, \"\"); channel.queueBind(FANOUT_QUEUE_2, FANOUT_EXCHAGE, \"\"); for (int i = 1; i &lt;= 10; i++) { // 发送信息 String message = \"你好；小兔子！发布订阅模式--\" + i; /** * 参数1：交换机名称，如果没有指定则使用默认Default Exchage * 参数2：路由key,简单模式可以传递队列名称 * 参数3：消息其它属性 * 参数4：消息内容 */ channel.basicPublish(FANOUT_EXCHAGE, \"\", null, message.getBytes()); System.out.println(\"已发送消息：\" + message); } // 关闭资源 channel.close(); connection.close(); } } 消费者1 package com.ydlclass.rabbitmq.publish; import com.rabbitmq.client.*; import java.io.IOException; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ public class Consumer1 { //交换机名称 static final String FANOUT_EXCHAGE = \"fanout_exchange\"; //队列名称 static final String FANOUT_QUEUE_1 = \"fanout_queue_1\"; //队列名称 static final String FANOUT_QUEUE_2 = \"fanout_queue_2\"; public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory=new ConnectionFactory(); //连接的ip connectionFactory.setHost(\"localhost\"); //连接的端口 connectionFactory.setPort(5672); //设置虚拟主机 connectionFactory.setVirtualHost(\"/\"); //设置用户名 connectionFactory.setUsername(\"itlils\"); //设置密码 connectionFactory.setPassword(\"itlils\"); //2创建长连接 Connection connection = connectionFactory.newConnection(); //3创建channel Channel channel = connection.createChannel(); //声明队列 //String queue, 队列名 // boolean durable, 持久化 // boolean exclusive, 排他的 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.queueDeclare(FANOUT_QUEUE_1,true,false,false,null); channel.queueDeclare(FANOUT_QUEUE_2,true,false,false,null); // 声明交换机 // String exchange, 交换机名称 // BuiltinExchangeType type, 交换机类型 // boolean durable, 持久化 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.exchangeDeclare(FANOUT_EXCHAGE, BuiltinExchangeType.FANOUT,true,false,null); //队列绑定交换机 // String queue, 队列名称 // String exchange, 交换机名称 // String routingKey 路由键 channel.queueBind(FANOUT_QUEUE_1,FANOUT_EXCHAGE,\"\"); channel.queueBind(FANOUT_QUEUE_2,FANOUT_EXCHAGE,\"\"); //4监听某个队列 // String queue, 监听的队列名 // boolean autoAck, 是否自动应答 // Consumer callback 回调函数，收到消息，我要干啥 com.rabbitmq.client.Consumer consumer=new DefaultConsumer(channel){ // 回调函数，收到消息，我要干啥 // String consumerTag, 消费者标签 // Envelope envelope, 信封 保存很多信息 // AMQP.BasicProperties properties, 属性 // byte[] body 消息字节数组 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { //业务逻辑 //现在的业务逻辑就是打印 // System.out.println(\"consumerTag:\"+consumerTag); // System.out.println(\"Exchange:\"+envelope.getExchange()); // System.out.println(\"RoutingKey:\"+envelope.getRoutingKey()); // System.out.println(\"DeliveryTag:\"+envelope.getDeliveryTag()); //消息id System.out.println(new String(body)); } }; channel.basicConsume(FANOUT_QUEUE_1,true,consumer); //5 千万别关闭连接，要不然queue有了消息 推不过来了 // channel.close(); // connection.close(); } } 消费者2 package com.ydlclass.rabbitmq.publish; import com.rabbitmq.client.*; import java.io.IOException; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ public class Consumer2 { //交换机名称 static final String FANOUT_EXCHAGE = \"fanout_exchange\"; //队列名称 static final String FANOUT_QUEUE_1 = \"fanout_queue_1\"; //队列名称 static final String FANOUT_QUEUE_2 = \"fanout_queue_2\"; public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory=new ConnectionFactory(); //连接的ip connectionFactory.setHost(\"localhost\"); //连接的端口 connectionFactory.setPort(5672); //设置虚拟主机 connectionFactory.setVirtualHost(\"/\"); //设置用户名 connectionFactory.setUsername(\"itlils\"); //设置密码 connectionFactory.setPassword(\"itlils\"); //2创建长连接 Connection connection = connectionFactory.newConnection(); //3创建channel Channel channel = connection.createChannel(); //声明队列 //String queue, 队列名 // boolean durable, 持久化 // boolean exclusive, 排他的 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.queueDeclare(FANOUT_QUEUE_1,true,false,false,null); channel.queueDeclare(FANOUT_QUEUE_2,true,false,false,null); // 声明交换机 // String exchange, 交换机名称 // BuiltinExchangeType type, 交换机类型 // boolean durable, 持久化 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.exchangeDeclare(FANOUT_EXCHAGE, BuiltinExchangeType.FANOUT,true,false,null); //队列绑定交换机 // String queue, 队列名称 // String exchange, 交换机名称 // String routingKey 路由键 channel.queueBind(FANOUT_QUEUE_1,FANOUT_EXCHAGE,\"\"); channel.queueBind(FANOUT_QUEUE_2,FANOUT_EXCHAGE,\"\"); //4监听某个队列 // String queue, 监听的队列名 // boolean autoAck, 是否自动应答 // Consumer callback 回调函数，收到消息，我要干啥 Consumer consumer=new DefaultConsumer(channel){ // 回调函数，收到消息，我要干啥 // String consumerTag, 消费者标签 // Envelope envelope, 信封 保存很多信息 // AMQP.BasicProperties properties, 属性 // byte[] body 消息字节数组 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { //业务逻辑 //现在的业务逻辑就是打印 // System.out.println(\"consumerTag:\"+consumerTag); // System.out.println(\"Exchange:\"+envelope.getExchange()); // System.out.println(\"RoutingKey:\"+envelope.getRoutingKey()); // System.out.println(\"DeliveryTag:\"+envelope.getDeliveryTag()); //消息id System.out.println(new String(body)); } }; channel.basicConsume(FANOUT_QUEUE_2,true,consumer); //5 千万别关闭连接，要不然queue有了消息 推不过来了 // channel.close(); // connection.close(); } } 1、工作队列模式不用定义交换机，而发布/订阅模式需要定义交换机。 2、发布/订阅模式的生产方是面向交换机发送消息，工作队列模式的生产方是面向队列发送消息(底层使用默认交换机)。 3、发布/订阅模式需要设置队列和交换机的绑定，工作队列模式不需要设置，实际上工作队列模式会将队列绑 定到默认的交换机 。 5.Routing路由模式（分布式日志收集系统）路由模式特点： 队列与交换机的绑定，不能是任意绑定了，而是要指定一个RoutingKey（路由key） 消息的发送方在 向 Exchange发送消息时，也必须指定消息的 RoutingKey。 Exchange不再把消息交给每一个绑定的队列，而是根据消息的Routing Key进行判断，只有队列的Routingkey与消息的 Routing key完全一致，才会接收到消息 图解： P：生产者，向Exchange发送消息，发送消息时，会指定一个routing key。 X：Exchange（交换机），接收生产者的消息，然后把消息递交给 与routing key完全匹配的队列 C1：消费者，其所在队列指定了需要routing key 为 error 的消息 C2：消费者，其所在队列指定了需要routing key 为 info、error、warning 的消息 生产者 package com.ydlclass.rabbitmq.routing; import com.rabbitmq.client.BuiltinExchangeType; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConnectionFactory; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ public class Producer { //交换机名称 static final String DIRECT_EXCHAGE = \"direct_exchange\"; //队列名称 static final String DIRECT_QUEUE_1 = \"direct_queue_1\"; //队列名称 static final String DIRECT_QUEUE_2 = \"direct_queue_2\"; public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory=new ConnectionFactory(); //连接的ip connectionFactory.setHost(\"localhost\"); //连接的端口 connectionFactory.setPort(5672); //设置虚拟主机 connectionFactory.setVirtualHost(\"/\"); //设置用户名 connectionFactory.setUsername(\"itlils\"); //设置密码 connectionFactory.setPassword(\"itlils\"); //2创建长连接 Connection connection = connectionFactory.newConnection(); //3创建channel Channel channel = connection.createChannel(); //声明队列 //String queue, 队列名 // boolean durable, 持久化 // boolean exclusive, 排他的 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.queueDeclare(DIRECT_QUEUE_1,true,false,false,null); channel.queueDeclare(DIRECT_QUEUE_2,true,false,false,null); // 声明交换机 // String exchange, 交换机名称 // BuiltinExchangeType type, 交换机类型 // boolean durable, 持久化 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.exchangeDeclare(DIRECT_EXCHAGE, BuiltinExchangeType.DIRECT,true,false,null); //队列绑定交换机 // String queue, 队列名称 // String exchange, 交换机名称 // String routingKey 路由键 channel.queueBind(DIRECT_QUEUE_1,DIRECT_EXCHAGE,\"error\"); channel.queueBind(DIRECT_QUEUE_2,DIRECT_EXCHAGE,\"info\"); channel.queueBind(DIRECT_QUEUE_2,DIRECT_EXCHAGE,\"error\"); channel.queueBind(DIRECT_QUEUE_2,DIRECT_EXCHAGE,\"warning\"); //4发消息 // String exchange, 交换机 // String routingKey, 路由键 // AMQP.BasicProperties props, 属性 // byte[] body 消息 string byte[] char[]如何相互转换的？ String msg=\"hello rabbitmq!routing error\"; channel.basicPublish(DIRECT_EXCHAGE,\"error\",null,msg.getBytes()); String msg1=\"hello rabbitmq!routing info\"; channel.basicPublish(DIRECT_EXCHAGE,\"info\",null,msg1.getBytes()); String msg2=\"hello rabbitmq!routing warning\"; channel.basicPublish(DIRECT_EXCHAGE,\"warning\",null,msg2.getBytes()); //5关闭连接 资源关闭的顺序，先关后出来的资源，最后关，第一个资源 channel.close(); connection.close(); } } 消费者1 package com.ydlclass.rabbitmq.routing; import com.rabbitmq.client.*; import java.io.IOException; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ public class Consumer1 { //交换机名称 static final String DIRECT_EXCHAGE = \"direct_exchange\"; //队列名称 static final String DIRECT_QUEUE_1 = \"direct_queue_1\"; //队列名称 static final String DIRECT_QUEUE_2 = \"direct_queue_2\"; public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory=new ConnectionFactory(); //连接的ip connectionFactory.setHost(\"localhost\"); //连接的端口 connectionFactory.setPort(5672); //设置虚拟主机 connectionFactory.setVirtualHost(\"/\"); //设置用户名 connectionFactory.setUsername(\"itlils\"); //设置密码 connectionFactory.setPassword(\"itlils\"); //2创建长连接 Connection connection = connectionFactory.newConnection(); //3创建channel Channel channel = connection.createChannel(); //声明队列 //String queue, 队列名 // boolean durable, 持久化 // boolean exclusive, 排他的 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.queueDeclare(DIRECT_QUEUE_1,true,false,false,null); channel.queueDeclare(DIRECT_QUEUE_2,true,false,false,null); // 声明交换机 // String exchange, 交换机名称 // BuiltinExchangeType type, 交换机类型 // boolean durable, 持久化 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.exchangeDeclare(DIRECT_EXCHAGE, BuiltinExchangeType.DIRECT,true,false,null); //队列绑定交换机 // String queue, 队列名称 // String exchange, 交换机名称 // String routingKey 路由键 channel.queueBind(DIRECT_QUEUE_1,DIRECT_EXCHAGE,\"error\"); channel.queueBind(DIRECT_QUEUE_2,DIRECT_EXCHAGE,\"info\"); channel.queueBind(DIRECT_QUEUE_2,DIRECT_EXCHAGE,\"error\"); channel.queueBind(DIRECT_QUEUE_2,DIRECT_EXCHAGE,\"warning\"); //4监听某个队列 // String queue, 监听的队列名 // boolean autoAck, 是否自动应答 // Consumer callback 回调函数，收到消息，我要干啥 com.rabbitmq.client.Consumer consumer=new DefaultConsumer(channel){ // 回调函数，收到消息，我要干啥 // String consumerTag, 消费者标签 // Envelope envelope, 信封 保存很多信息 // AMQP.BasicProperties properties, 属性 // byte[] body 消息字节数组 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { //业务逻辑 //现在的业务逻辑就是打印 // System.out.println(\"consumerTag:\"+consumerTag); // System.out.println(\"Exchange:\"+envelope.getExchange()); // System.out.println(\"RoutingKey:\"+envelope.getRoutingKey()); // System.out.println(\"DeliveryTag:\"+envelope.getDeliveryTag()); //消息id System.out.println(new String(body)); } }; channel.basicConsume(DIRECT_QUEUE_1,true,consumer); //5 千万别关闭连接，要不然queue有了消息 推不过来了 // channel.close(); // connection.close(); } } 消费者2 package com.ydlclass.rabbitmq.routing; import com.rabbitmq.client.*; import java.io.IOException; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ public class Consumer2 { //交换机名称 static final String DIRECT_EXCHAGE = \"direct_exchange\"; //队列名称 static final String DIRECT_QUEUE_1 = \"direct_queue_1\"; //队列名称 static final String DIRECT_QUEUE_2 = \"direct_queue_2\"; public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory=new ConnectionFactory(); //连接的ip connectionFactory.setHost(\"localhost\"); //连接的端口 connectionFactory.setPort(5672); //设置虚拟主机 connectionFactory.setVirtualHost(\"/\"); //设置用户名 connectionFactory.setUsername(\"itlils\"); //设置密码 connectionFactory.setPassword(\"itlils\"); //2创建长连接 Connection connection = connectionFactory.newConnection(); //3创建channel Channel channel = connection.createChannel(); //声明队列 //String queue, 队列名 // boolean durable, 持久化 // boolean exclusive, 排他的 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.queueDeclare(DIRECT_QUEUE_1,true,false,false,null); channel.queueDeclare(DIRECT_QUEUE_2,true,false,false,null); // 声明交换机 // String exchange, 交换机名称 // BuiltinExchangeType type, 交换机类型 // boolean durable, 持久化 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.exchangeDeclare(DIRECT_EXCHAGE, BuiltinExchangeType.DIRECT,true,false,null); //队列绑定交换机 // String queue, 队列名称 // String exchange, 交换机名称 // String routingKey 路由键 channel.queueBind(DIRECT_QUEUE_1,DIRECT_EXCHAGE,\"error\"); channel.queueBind(DIRECT_QUEUE_2,DIRECT_EXCHAGE,\"info\"); channel.queueBind(DIRECT_QUEUE_2,DIRECT_EXCHAGE,\"error\"); channel.queueBind(DIRECT_QUEUE_2,DIRECT_EXCHAGE,\"warning\"); //4监听某个队列 // String queue, 监听的队列名 // boolean autoAck, 是否自动应答 // Consumer callback 回调函数，收到消息，我要干啥 Consumer consumer=new DefaultConsumer(channel){ // 回调函数，收到消息，我要干啥 // String consumerTag, 消费者标签 // Envelope envelope, 信封 保存很多信息 // AMQP.BasicProperties properties, 属性 // byte[] body 消息字节数组 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { //业务逻辑 //现在的业务逻辑就是打印 // System.out.println(\"consumerTag:\"+consumerTag); // System.out.println(\"Exchange:\"+envelope.getExchange()); // System.out.println(\"RoutingKey:\"+envelope.getRoutingKey()); // System.out.println(\"DeliveryTag:\"+envelope.getDeliveryTag()); //消息id System.out.println(new String(body)); } }; channel.basicConsume(DIRECT_QUEUE_2,true,consumer); //5 千万别关闭连接，要不然queue有了消息 推不过来了 // channel.close(); // connection.close(); } } Routing模式要求队列在绑定交换机时要指定routing key，消息会转发到符合routing key的队列。 6.Topics通配符模式通配符规则： #：匹配一个或多个词 *：匹配不多不少恰好1个词 Topic类型与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！ Routingkey` 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： `item.insert 图解： 红色Queue：绑定的是usa.# ，因此凡是以 usa.开头的routing key 都会被匹配到 黄色Queue：绑定的是#.news ，因此凡是以 .news结尾的 routing key 都会被匹配 生产者 package com.ydlclass.rabbitmq.topic; import com.rabbitmq.client.BuiltinExchangeType; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Connection; import com.rabbitmq.client.ConnectionFactory; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ public class Producer { //交换机名称 static final String TOPIC_EXCHAGE = \"topic_exchange\"; //队列名称 static final String TOPIC_QUEUE_1 = \"topic_queue_1\"; //队列名称 static final String TOPIC_QUEUE_2 = \"topic_queue_2\"; public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory=new ConnectionFactory(); //连接的ip connectionFactory.setHost(\"localhost\"); //连接的端口 connectionFactory.setPort(5672); //设置虚拟主机 connectionFactory.setVirtualHost(\"/\"); //设置用户名 connectionFactory.setUsername(\"itlils\"); //设置密码 connectionFactory.setPassword(\"itlils\"); //2创建长连接 Connection connection = connectionFactory.newConnection(); //3创建channel Channel channel = connection.createChannel(); //声明队列 //String queue, 队列名 // boolean durable, 持久化 // boolean exclusive, 排他的 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.queueDeclare(TOPIC_QUEUE_1,true,false,false,null); channel.queueDeclare(TOPIC_QUEUE_2,true,false,false,null); // 声明交换机 // String exchange, 交换机名称 // BuiltinExchangeType type, 交换机类型 // boolean durable, 持久化 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.exchangeDeclare(TOPIC_EXCHAGE, BuiltinExchangeType.TOPIC,true,false,null); //队列绑定交换机 // String queue, 队列名称 // String exchange, 交换机名称 // String routingKey 路由键 channel.queueBind(TOPIC_QUEUE_1,TOPIC_EXCHAGE,\"ydlclass.taiyuan.*.*\"); //我是太原校区校长的队列 channel.queueBind(TOPIC_QUEUE_2,TOPIC_EXCHAGE,\"ydlclass.*.caiwubu.*\");//我是总部财务主管的队列 //4发消息 // String exchange, 交换机 // String routingKey, 路由键 // AMQP.BasicProperties props, 属性 // byte[] body 消息 string byte[] char[]如何相互转换的？ String msg1=\"hello rabbitmq!topic 本月工资大家涨两千！\"; channel.basicPublish(TOPIC_EXCHAGE,\"ydlclass.taiyuan.caiwubu.info\",null,msg1.getBytes()); String msg2=\"hello rabbitmq!topic 李老师携款潜逃！\"; channel.basicPublish(TOPIC_EXCHAGE,\"ydlclass.taiyuan.renshi.error\",null,msg2.getBytes()); String msg3=\"hello rabbitmq!topic 因为李老师逃了，全国所有校区降薪两千。不行就毕业！\"; channel.basicPublish(TOPIC_EXCHAGE,\"ydlclass.beijing.caiwubu.error\",null,msg3.getBytes()); //5关闭连接 资源关闭的顺序，先关后出来的资源，最后关，第一个资源 channel.close(); connection.close(); } } 消费者1 package com.ydlclass.rabbitmq.topic; import com.rabbitmq.client.*; import java.io.IOException; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ public class Consumer1 { //交换机名称 static final String TOPIC_EXCHAGE = \"topic_exchange\"; //队列名称 static final String TOPIC_QUEUE_1 = \"topic_queue_1\"; //队列名称 static final String TOPIC_QUEUE_2 = \"topic_queue_2\"; public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory=new ConnectionFactory(); //连接的ip connectionFactory.setHost(\"localhost\"); //连接的端口 connectionFactory.setPort(5672); //设置虚拟主机 connectionFactory.setVirtualHost(\"/\"); //设置用户名 connectionFactory.setUsername(\"itlils\"); //设置密码 connectionFactory.setPassword(\"itlils\"); //2创建长连接 Connection connection = connectionFactory.newConnection(); //3创建channel Channel channel = connection.createChannel(); //声明队列 //String queue, 队列名 // boolean durable, 持久化 // boolean exclusive, 排他的 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.queueDeclare(TOPIC_QUEUE_1,true,false,false,null); channel.queueDeclare(TOPIC_QUEUE_2,true,false,false,null); // 声明交换机 // String exchange, 交换机名称 // BuiltinExchangeType type, 交换机类型 // boolean durable, 持久化 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.exchangeDeclare(TOPIC_EXCHAGE, BuiltinExchangeType.TOPIC,true,false,null); //队列绑定交换机 // String queue, 队列名称 // String exchange, 交换机名称 // String routingKey 路由键 channel.queueBind(TOPIC_QUEUE_1,TOPIC_EXCHAGE,\"ydlclass.taiyuan.*.*\"); //我是太原校区校长的队列 channel.queueBind(TOPIC_QUEUE_2,TOPIC_EXCHAGE,\"ydlclass.*.caiwubu.*\");//我是总部财务主管的队列 //4监听某个队列 // String queue, 监听的队列名 // boolean autoAck, 是否自动应答 // Consumer callback 回调函数，收到消息，我要干啥 Consumer consumer=new DefaultConsumer(channel){ // 回调函数，收到消息，我要干啥 // String consumerTag, 消费者标签 // Envelope envelope, 信封 保存很多信息 // AMQP.BasicProperties properties, 属性 // byte[] body 消息字节数组 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { //业务逻辑 //现在的业务逻辑就是打印 // System.out.println(\"consumerTag:\"+consumerTag); // System.out.println(\"Exchange:\"+envelope.getExchange()); // System.out.println(\"RoutingKey:\"+envelope.getRoutingKey()); // System.out.println(\"DeliveryTag:\"+envelope.getDeliveryTag()); //消息id System.out.println(new String(body)); } }; channel.basicConsume(TOPIC_QUEUE_1,true,consumer); //5 千万别关闭连接，要不然queue有了消息 推不过来了 // channel.close(); // connection.close(); } } 消费者2 package com.ydlclass.rabbitmq.topic; import com.rabbitmq.client.*; import java.io.IOException; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ public class Consumer2 { //交换机名称 static final String TOPIC_EXCHAGE = \"topic_exchange\"; //队列名称 static final String TOPIC_QUEUE_1 = \"topic_queue_1\"; //队列名称 static final String TOPIC_QUEUE_2 = \"topic_queue_2\"; public static void main(String[] args) throws Exception { //1创建连接工厂 ConnectionFactory connectionFactory=new ConnectionFactory(); //连接的ip connectionFactory.setHost(\"localhost\"); //连接的端口 connectionFactory.setPort(5672); //设置虚拟主机 connectionFactory.setVirtualHost(\"/\"); //设置用户名 connectionFactory.setUsername(\"itlils\"); //设置密码 connectionFactory.setPassword(\"itlils\"); //2创建长连接 Connection connection = connectionFactory.newConnection(); //3创建channel Channel channel = connection.createChannel(); //声明队列 //String queue, 队列名 // boolean durable, 持久化 // boolean exclusive, 排他的 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.queueDeclare(TOPIC_QUEUE_1,true,false,false,null); channel.queueDeclare(TOPIC_QUEUE_2,true,false,false,null); // 声明交换机 // String exchange, 交换机名称 // BuiltinExchangeType type, 交换机类型 // boolean durable, 持久化 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 channel.exchangeDeclare(TOPIC_EXCHAGE, BuiltinExchangeType.TOPIC,true,false,null); //队列绑定交换机 // String queue, 队列名称 // String exchange, 交换机名称 // String routingKey 路由键 channel.queueBind(TOPIC_QUEUE_1,TOPIC_EXCHAGE,\"ydlclass.taiyuan.*.*\"); //我是太原校区校长的队列 channel.queueBind(TOPIC_QUEUE_2,TOPIC_EXCHAGE,\"ydlclass.*.caiwubu.*\");//我是总部财务主管的队列 //4监听某个队列 // String queue, 监听的队列名 // boolean autoAck, 是否自动应答 // Consumer callback 回调函数，收到消息，我要干啥 Consumer consumer=new DefaultConsumer(channel){ // 回调函数，收到消息，我要干啥 // String consumerTag, 消费者标签 // Envelope envelope, 信封 保存很多信息 // AMQP.BasicProperties properties, 属性 // byte[] body 消息字节数组 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { //业务逻辑 //现在的业务逻辑就是打印 // System.out.println(\"consumerTag:\"+consumerTag); // System.out.println(\"Exchange:\"+envelope.getExchange()); // System.out.println(\"RoutingKey:\"+envelope.getRoutingKey()); // System.out.println(\"DeliveryTag:\"+envelope.getDeliveryTag()); //消息id System.out.println(new String(body)); } }; channel.basicConsume(TOPIC_QUEUE_2,true,consumer); //5 千万别关闭连接，要不然queue有了消息 推不过来了 // channel.close(); // connection.close(); } } Topic主题模式可以实现 Publish/Subscribe发布与订阅模式 和 Routing路由模式 的功能；只是Topic在配置routing key 的时候可以使用通配符，显得更加灵活。 7.模式总结（1）简单模式 HelloWorld一个生产者、一个消费者，不需要设置交换机（使用默认的交换机）。 （2）工作队列模式 Work Queue**一个生产者、多个消费者（竞争关系），不需要设置交换机（使用默认的交换机）。 （3）发布订阅模式 Publish/subscribe**需要设置类型为fanout的交换机，并且交换机和队列进行绑定，当发送消息到交换机后，交换机会将消息发送到绑定的队列。 （4）路由模式 Routing**需要设置类型为direct的交换机，交换机和队列进行绑定，并且指定routing key，当发送消息到交换机后，交换机会根据routing key将消息发送到对应的队列。 （5）通配符模式 Topic**需要设置类型为topic的交换机，交换机和队列进行绑定，并且指定通配符方式的routing key，当发送消息到交换机后，交换机会根据routing key将消息发送到对应的队列。 四.Spring Boot 集成RabbitMQ生产者工程： application.yml文件配置RabbitMQ相关信息； 在生产者工程中编写配置类，用于创建交换机和队列，并进行绑定 注入RabbitTemplate对象，通过RabbitTemplate对象发送消息到交换机 消费者工程： application.yml文件配置RabbitMQ相关信息 创建消息处理类，用于接收队列中的消息并进行处理 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; spring: rabbitmq: host: localhost port: 5672 virtual-host: / username: guest password: guest 绑定交换机和队列 创建RabbitMQ队列与交换机绑定的配置类com.ydlclass.rabbitmq.config.RabbitMQConfig package com.ydlclass.rabbitmq.config; import org.springframework.amqp.core.*; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ @Configuration public class RabbitConfig { @Bean(\"boot_hello_queue\") public Queue queue(){ //String queue, 队列名 // boolean durable, 持久化 // boolean exclusive, 排他的 // boolean autoDelete, 自动删除 // Map&lt;String, Object&gt; arguments 属性 return new Queue(\"boot_hello_queue\",true,false,false,null); } //发布订阅模式 //交换机名称 public static final String FANOUT_EXCHAGE = \"boot_fanout_exchange\"; //队列名称 public static final String FANOUT_QUEUE_1 = \"boot_fanout_queue_1\"; //队列名称 public static final String FANOUT_QUEUE_2 = \"boot_fanout_queue_2\"; @Bean(FANOUT_QUEUE_1) public Queue FANOUT_QUEUE_1(){ return new Queue(FANOUT_QUEUE_1,true,false,false,null); } @Bean(FANOUT_QUEUE_2) public Queue FANOUT_QUEUE_2(){ return new Queue(FANOUT_QUEUE_2,true,false,false,null); } @Bean(FANOUT_EXCHAGE) public Exchange FANOUT_EXCHAGE(){ return ExchangeBuilder.fanoutExchange(FANOUT_EXCHAGE).durable(true).build(); } @Bean public Binding FANOUT_QUEUE_1_FANOUT_EXCHAGE(@Qualifier(FANOUT_QUEUE_1) Queue queue, @Qualifier(FANOUT_EXCHAGE) Exchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(\"\").noargs(); } @Bean public Binding FANOUT_QUEUE_2_FANOUT_EXCHAGE(@Qualifier(FANOUT_QUEUE_2) Queue queue, @Qualifier(FANOUT_EXCHAGE) Exchange exchange){ return BindingBuilder.bind(queue).to(exchange).with(\"\").noargs(); } //作业 //routing模式 //topic模式 } package com.ydlclass.rabbitmq; import com.ydlclass.rabbitmq.config.RabbitConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ @RunWith(SpringRunner.class) @SpringBootTest(classes = ProducerApp.class) public class ProducerTest { @Autowired RabbitTemplate rabbitTemplate; @Test public void helloTest(){ String msg=\"hello rabbitmq!\"; rabbitTemplate.convertAndSend(\"\",\"boot_hello_queue\",msg); } @Test public void publishTest(){ String msg=\"hello rabbitmq!publishTest\"; rabbitTemplate.convertAndSend(RabbitConfig.FANOUT_EXCHAGE,\"\",msg); } //作业 routing //topic } package com.ydlclass.rabbitmq.listener; import com.ydlclass.rabbitmq.config.RabbitConfig; import org.springframework.amqp.core.Message; import org.springframework.amqp.core.MessageProperties; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; /** * @Created by IT李老师 * 公主号 “元动力课堂” * 个人微 itlils */ @Component public class MyListener { @RabbitListener(queues = RabbitConfig.FANOUT_QUEUE_1) public void receiveMsg(Message message){ //业务逻辑 byte[] body = message.getBody(); System.out.println(new String(body)); MessageProperties messageProperties = message.getMessageProperties(); //参数 System.out.println(messageProperties.getMessageId()); System.out.println(messageProperties.getDeliveryTag()); System.out.println(messageProperties.getReceivedRoutingKey()); System.out.println(messageProperties.getConsumerTag()); } } 注解 @RabbitListener(bindings =@QueueBinding( // email.fanout.queue 是队列名字，这个名字你可以自定随便定义。 value = @Queue(value = \"email.topic.queue\",autoDelete = \"false\",durable = \"true\"), // order.fanout 交换机的名字 必须和生产者保持一致 exchange = @Exchange(value = \"topic_order_exchange\", // 这里是确定的rabbitmq模式是：fanout 是以广播模式 、 发布订阅模式 type = ExchangeTypes.TOPIC),key = \"*.email.#\" )) 五.gitee地址https://gitee.com/macongxuexi/RabbitMQDemo.git","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://macongmc.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"消息队列/RabbitMQ","permalink":"https://macongmc.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://macongmc.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"author":"马聪"},{"title":"Redis","slug":"Redis","date":"2022-08-17T09:51:43.000Z","updated":"2022-08-17T09:51:43.000Z","comments":true,"path":"posts/bae4ff13.html","link":"","permalink":"https://macongmc.github.io/posts/bae4ff13.html","excerpt":"","text":"一.单节点Redis存在问题 1.数据丢失问题 实现Redis数据持久化 2.并发能力问题 负载均衡集群 主从集群 读写分离 3.存储能力问题 搭建分片集群，插槽机制实现动态扩容。 4.故障恢复问题 哨兵机制 二.Redis持久化1.RDB持久化备份机制，也叫快照 主进程 单线程 redis-cli save 数据写入磁盘 快结束执行 缺点：单线程使用不能执行别得操作。 推荐 用额外得线程执行，主进行不受影响 后台异步 bgsave 运行过程中执行 后台备份 停机时会主动一次RDB 当突然宕机导致数据丢失，再Redis.conf 的配置文件中 修改触发机制 #900秒内，如果至少有一个key被修改执行bgsave save \"\" #禁用RDB save 900 1 save 300 10 save 60 1000 2.RDB原理RDB bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入RDB文件。 3.AOFAOF：Redis处理的每一个写命令都会记录再AOF文件中，可以看做是命令日志文件。 AOF频率： 主进程 执行 bgrewriteaof 压缩体积 后台异步执行 触发重写机制 两者之间的优缺点 redis和AOF结合使用 AOF 优点： 数据更完整，秒级数据丢失(取决于设置fsync策略)。 兼容性较高，由于是基于redis通讯协议而形成的命令追加方式，无论何种版本的redis都兼容，再者aof文件是明文的，可阅读性较好。 缺点： 数据文件体积较大,即使有重写机制，但是在相同的数据集情况下，AOF文件通常比RDB文件大。 相对RDB方式，AOF速度慢于RDB，并且在数据量大时候，恢复速度AOF速度也是慢于RDB。 由于频繁地将命令同步到文件中，AOF持久化对性能的影响相对RDB较大，但是对于我们来说是可以接受的。 4.混合使用优点： 混合持久化结合了RDB持久化 和 AOF 持久化的优点, 由于绝大部分都是RDB格式，加载速度快，同时结合AOF，增量的数据以AOF方式保存了，数据更少的丢失。 缺点： 兼容性差，一旦开启了混合持久化，同时由于前部分是RDB格式，阅读性较差 混合模式开关设置： aof-use-rdb-preamble y 混合模式兼顾了RDB数据恢复快以及AOF数据完整性的优点。 bgrewirteof的触发机制是怎样的呢？ auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb 新启动空闲实例，开启混合持久化功能，写入数据，此时AOF文件内容是操作指令； 执行AOF重写功能，fork()的子进程会把共享内存中所有的数据以RDB形式写到AOF临时文件中，然后继续把重写缓冲区中的增量数据以操作指令类型到AOF临时文件中，最后用AOF临时文件替换原AOF文件，AOF重写完成； 继续写入数据，此时写入的新数据依然是操作指令类型； 执行AOF重写，重复步骤2操作….. ； Redis重启，此时会加载AOF文件(前面部分是二进制数据，后面部分是指令数据的AOF文件)置内存；","categories":[{"name":"Redis","slug":"Redis","permalink":"https://macongmc.github.io/categories/Redis/"},{"name":"分布式缓存","slug":"Redis/分布式缓存","permalink":"https://macongmc.github.io/categories/Redis/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"API","slug":"API","permalink":"https://macongmc.github.io/tags/API/"}],"author":"马聪"},{"title":"jenkins(三）","slug":"jenkins-三）","date":"2022-08-12T14:10:48.000Z","updated":"2022-08-12T14:10:48.000Z","comments":true,"path":"posts/a5cd10b.html","link":"","permalink":"https://macongmc.github.io/posts/a5cd10b.html","excerpt":"","text":"一.gitliab自动构建项目选择构建触发器 点击触发远程构建 在gitlab中头像设置 Access Tokens 最后找到令牌写入。 在浏览器中输入 JENKINS_URL/job/first/build?token=TOKEN_NAME 可以直接构建。 通过配置地址来让gitLab进行构建。 注意：跨浏览器会要求登录。 解决在Jenkins安装Build Authorization Token Root Plugin 用于免登录jenkins 使用如下地址配置 JENKINS_URL/buildByToken/build?job=NAME&amp;token=SECRET. 使用gitlab 在项目中的设置选择集成 填写相应的url 和令牌 选择触发方式。 去掉ssl 把网络勾上。 添加成功后测试 二.几种构建触发器详情 Build whenever a SNAPSHOT dependency is built 依赖快照 触发远程构建 gitLab 其他工程构建后触发 父子项目，先子项目，后父项目 定时构建 表达式 gitHub git 托管 轮询 定时，查看是否发生变化 也是时间表达式 三.配置邮箱1.首先注册一个网易邮箱 设置开启 POP3 HENOQKOTQLHEJITL 2.用QQ收邮件3.配置 触发器。 后面设置测试。 4.项目配置邮件选择构建后操作 选择设置发送时机和人。 Project Recipient List 收件人邮件 多个用空格隔开 添加 Project Recipient List发送 四.配置钉钉机器人(199条消息) Jenkins配置钉钉机器人_三千花灯的博客-CSDN博客_jenkins钉钉机器人","categories":[{"name":"持续集成","slug":"持续集成","permalink":"https://macongmc.github.io/categories/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://macongmc.github.io/tags/Jenkins/"}],"author":"马聪"},{"title":"jenkins(二）","slug":"jenkins-二）","date":"2022-08-12T03:33:12.000Z","updated":"2022-08-12T03:33:12.000Z","comments":true,"path":"posts/47427259.html","link":"","permalink":"https://macongmc.github.io/posts/47427259.html","excerpt":"","text":"一.启动jenkins1.基本配置切换到jdk11运行 alternatives --config java 启动命令 nohup java -jar jenkins.war --httpPort=8383 &gt;my.file 2&gt;&amp;1 &amp; 切换回1.8 alternatives --config java 浏览器访问 http://localhost:8383 cat 位置查看密码 选择安装推荐的插件 设置账户密码 成功登录 在系统管理里 插件管理 高级设置国内站点 升级站点 https://updates.jenkins.io/update-center.json 2.安装插件安装maven构建插件和远程连接插件。 Maven Integration plugin Publish Over SSH 二启动配置系统管理 全局工具配置 把mavn,git，jdk进行路径配置。 三.配置主机连接 系统管理的系统配置里 找到Publish over SSH 进行配置，22端口，root,主机号，以及密码。最后测试连接。 三.基本使用1.新建任务 创建一个maven项目 2.General项目描述 JDK选择对应项目版本 3.源码管理选择git 输入git仓库地址 添加凭证 及登录的账号密码 4.构建触发器可以选择定时构建 5.构建环境Add timestamps to the Console Output 6.Pre Steps 选择Send files or execute commands over SSH 选择之前设置的主机号，如果没有设置，在系统全局配置的最后。 Source files: 要传入远程服务器的文件 默认根目录为 /root/.jenkins/workspace Remove prefix：移除外部文件 Remote directory:传入文件的目录，默认root下创建 例如：xxoo 会在远程服务器的/root/xxoo Exec command:执行命令 一般设置脚本 用来结束进程，删除文件。 执行脚本文件 mkdir go.sh chmod u+x go.sh sh /root/sh/go.sh start #!/bin/bash PID=$(ps -ef | grep demo | grep -v grep | awk '{ print $2 }') if [ -z \"$PID\" ] then echo Application is stopped else echo kill $PID kill -9 $PID rm -rf /root/xxoo fi source /etc/profile Exec command:可以使用./go.sh ./go.sh 必须创建在~目录下 可以传参 例如 ./go.sh demo appname =$1 #获取参数 echo \"arg:$1\" pid =`ps-ef |grep $1 | grep 'java-jar' | awk '{printf $2}'` echo $pid #如果pid为空，提示一下，否则kill if [ -z $pid ]; #空值判断 then echo \"$appname not started\" eles kill -9 $pid #删除历史 rm -rf xxoo echo \"$appname stoping.....\" pid =`ps -ef | grep -w $pid | grep java ` if [ -z $pid ]; then echo \"$appname pid:$pid is stop\" else echo \"$appname stop failed\" fi 7.Build Root POM:填写gitlab中pom地址 Goals and options:填写maven打包命令 clean package -Dmaven.test.skip=true -Pdev 8.Post Steps 选择Send files or execute commands over SSH 选择之前设置的主机号，如果没有设置，在系统全局配置的最后。 Source files: 要传入远程服务器的文件 默认根目录为 /root/.jenkins/workspace 例如 **/fn-safeedu*.jar Remove prefix：移除外部文件 例如 safe-edu-server/fn-safeedu/target/ Remote directory:传入文件的目录，默认root下创建 例如：xxoo 会在远程服务器的/root/xxoo xxoo Exec command:执行命令 执行启动命名 nohup java -jar /root/xxoo/fn-safeedu*.jar &gt;my.log.log 2&gt;&amp;1 &amp; 9.构建设置 用于失败发送邮件","categories":[{"name":"持续集成","slug":"持续集成","permalink":"https://macongmc.github.io/categories/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://macongmc.github.io/tags/Jenkins/"}],"author":"马聪"},{"title":"jenkisn(一）","slug":"jenkisn-一）","date":"2022-08-12T03:11:41.000Z","updated":"2022-08-12T03:11:41.000Z","comments":true,"path":"posts/cd651f5d.html","link":"","permalink":"https://macongmc.github.io/posts/cd651f5d.html","excerpt":"","text":"一.环境需求jenkins最新版目前需要JDK11。 环境需求：jdk,mavn,git. jdk采取linux多环境安装。 二.安装JDK1.下载JDK8和JDK11linux安装多版本 百度网盘https://pan.baidu.com/s/1UybyZL9fg4aWBZQLAbzHrA 提取码：7777 解压两个JDK tar zxvf jdk-8u181-linux-x64.tar.gz 设置环境变量 vim /etc/profile 配置 export JAVA_HOME=/usr/local/jdk/jdk1.8.0_181 export CLASSPATH=$:CLASSPATH:$JAVA_HOME/lib/ export PATH=$PATH:$JAVA_HOME/bin source /etc/profile 1.8设置为默认JDK 2.多版本配置查看JDK是否存在 alternatives --config java 根据数字动态切换JDK 添加两个版本的JDK alternatives --install /usr/bin/java java /usr/local/java/jdk1.8.0_152/bin/java 序号 三.安装maven下载地址：https://maven.apache.org/download.cgi 解压 tar zxvf apache-maven-3.8.6-bin.tar.gz 修改仓库 vi /usr/local/maven/apache-maven-3.6.1/conf/settings.xml 配置阿里云镜像 &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt; &lt;/mirror&gt; 配置环境变量 export MAVEN_HOME=/usr/local/maven/apache-maven-3.6.1 export PATH=$PATH:$MAVEN_HOME/bin 赋权限 chmod 777 /usr/local/maven/apache-maven-3.6.1/bin/mvn 刷新运行 source /etc/profile mvn-v 四.安装gityum -y install git git version 五.安装jenkinx下载地址：Jenkins download and deployment 采用：war包下载 运行： nohup java -jar jenkins.war --httpPort=8383 &gt;my.file 2&gt;&amp;1 &amp; 如有空指针 yum -y install fontconfig","categories":[{"name":"持续集成","slug":"持续集成","permalink":"https://macongmc.github.io/categories/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://macongmc.github.io/tags/Jenkins/"}],"author":"马聪"},{"title":"Linux手册","slug":"多版本JDK","date":"2022-08-12T02:54:09.000Z","updated":"2022-08-12T02:54:09.000Z","comments":true,"path":"posts/4e543b07.html","link":"","permalink":"https://macongmc.github.io/posts/4e543b07.html","excerpt":"","text":"一.多版本JDK1.下载多个版本JDK依赖 下载jdk1.8 下载jdk11 alternatives --install /usr/bin/java java /usr/local/java/jdk1.8.0_152/bin/java 序号 alternatives --config java 选择版本 二.防火墙设置防火墙允许http服务 sudo firewall-cmd --add-service=http --permanent 设置防火墙打开8080端口 sudo firewall-cmd --add-port=8080/tcp --permanent 命令重启防火墙 sudo firewall-cmd --reload 看防火墙开启还是关闭 systemctl status firewalld.service 可以查看端口开放情况 sudo firewall-cmd --list-all 三.shell脚本赋权限 chmod u+x 文件名称 基本脚本 #!/bin/bash PID=$(ps -ef | grep fn-safeedu | grep -v grep | awk '{ print $2 }') if [ -z \"$PID\" ] then echo Application is stopped else echo kill $PID kill -9 $PID rm -rf /root/xxoo fi source /etc/profile 四.后端运行javanohup java -jar /root/xxoo/fn-safeedu*.jar &gt;my.log.log 2&gt;&amp;1 &amp;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://macongmc.github.io/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://macongmc.github.io/tags/linux/"},{"name":"多版本jdk","slug":"多版本jdk","permalink":"https://macongmc.github.io/tags/%E5%A4%9A%E7%89%88%E6%9C%ACjdk/"}],"author":"马聪"},{"title":"分布式任务调度-xxl-job","slug":"分布式任务调度-xxl-job","date":"2022-08-10T02:16:19.000Z","updated":"2022-08-10T02:16:19.000Z","comments":true,"path":"posts/cfbe074.html","link":"","permalink":"https://macongmc.github.io/posts/cfbe074.html","excerpt":"","text":"一.分布式任务调度-xxl-job1.文档地址文档地址源码地址 2.环境 Maven3+ Jdk1.8+ Mysql5.7+ 3.初始化数据库- xxl_job_lock：任务调度锁表； - xxl_job_group：执行器信息表，维护任务执行器信息； - xxl_job_info：调度扩展信息表： 用于保存XXL-JOB调度任务的扩展信息，如任务分组、任务名、机器地址、执行器、执行入参和报警邮件等等； - xxl_job_log：调度日志表： 用于保存XXL-JOB任务调度的历史信息，如调度结果、执行结果、调度入参、调度机器和执行器等等； - xxl_job_logglue：任务GLUE日志：用于保存GLUE更新历史，用于支持GLUE的版本回溯功能； - xxl_job_registry：执行器注册表，维护在线的执行器和调度中心机器地址信息； - xxl_job_user：系统用户表； 调度中心支持集群部署，集群情况下各节点务必连接同一个mysql实例; 如果mysql做主从,调度中心集群节点务必强制走主库; 配置文件 ### web server.port=8888 server.servlet.context-path=/xxl-job-admin ### actuator management.server.servlet.context-path=/actuator management.health.mail.enabled=false ### resources spring.mvc.servlet.load-on-startup=0 spring.mvc.static-path-pattern=/static/** spring.resources.static-locations=classpath:/static/ ### freemarker spring.freemarker.templateLoaderPath=classpath:/templates/ spring.freemarker.suffix=.ftl spring.freemarker.charset=UTF-8 spring.freemarker.request-context-attribute=request spring.freemarker.settings.number_format=0.########## ### mybatis mybatis.mapper-locations=classpath:/mybatis-mapper/*Mapper.xml #mybatis.type-aliases-package=com.xxl.job.admin.core.model ### xxl-job, datasource spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?Unicode=true&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=UTF-8 spring.datasource.username=root spring.datasource.password=root spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver ### datasource-pool spring.datasource.type=com.zaxxer.hikari.HikariDataSource spring.datasource.hikari.minimum-idle=10 spring.datasource.hikari.maximum-pool-size=30 spring.datasource.hikari.auto-commit=true spring.datasource.hikari.idle-timeout=30000 spring.datasource.hikari.pool-name=HikariCP spring.datasource.hikari.max-lifetime=900000 spring.datasource.hikari.connection-timeout=10000 spring.datasource.hikari.connection-test-query=SELECT 1 ### xxl-job, email spring.mail.host=smtp.qq.com spring.mail.port=25 spring.mail.username=xxx@qq.com spring.mail.password=xxx spring.mail.properties.mail.smtp.auth=true spring.mail.properties.mail.smtp.starttls.enable=true spring.mail.properties.mail.smtp.starttls.required=true spring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory ### xxl-job, access token xxl.job.accessToken= ### xxl-job, i18n (default is zh_CN, and you can choose \"zh_CN\", \"zh_TC\" and \"en\") xxl.job.i18n=zh_CN ## xxl-job, triggerpool max size xxl.job.triggerpool.fast.max=200 xxl.job.triggerpool.slow.max=100 ### xxl-job, log retention days xxl.job.logretentiondays=30 启动调度中心，默认登录账号 “admin/123456”, 登录后运行界面如下图所示。 二.入门案例1.dockerdocker pull xuxueli/xxl-job-admin:2.3.0 docker run -e PARAMS=\"--spring.datasource.url=jdbc:mysql://192.168.200.130:3306/xxl_job?Unicode=true&amp;characterEncoding=UTF-8 \\ --spring.datasource.username=root \\ --spring.datasource.password=root\" \\ -p 8888:8080 -v /tmp:/data/applogs \\ --name xxl-job-admin --restart=always -d xuxueli/xxl-job-admin:2.3.0 2.依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--xxl-job--&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuxueli&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; server: port: 8881 xxl: job: admin: addresses: http://192.168.200.130:8888/xxl-job-admin executor: appname: xxl-job-executor-sample port: 9999 import com.xxl.job.core.executor.impl.XxlJobSpringExecutor; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * xxl-job config * * @author xuxueli 2017-04-28 */ @Configuration public class XxlJobConfig { private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class); @Value(\"${xxl.job.admin.addresses}\") private String adminAddresses; @Value(\"${xxl.job.executor.appname}\") private String appname; @Value(\"${xxl.job.executor.port}\") private int port; @Bean public XxlJobSpringExecutor xxlJobExecutor() { logger.info(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init.\"); XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor(); xxlJobSpringExecutor.setAdminAddresses(adminAddresses); xxlJobSpringExecutor.setAppname(appname); xxlJobSpringExecutor.setPort(port); return xxlJobSpringExecutor; } } import com.xxl.job.core.handler.annotation.XxlJob; import org.springframework.stereotype.Component; @Component public class HelloJob { @XxlJob(\"demoJobHandler\") public void helloJob(){ System.out.println(\"简单任务执行了。。。。\"); } } 执行器启动","categories":[{"name":"xxl-job","slug":"xxl-job","permalink":"https://macongmc.github.io/categories/xxl-job/"}],"tags":[{"name":"api","slug":"api","permalink":"https://macongmc.github.io/tags/api/"}],"author":"马聪"},{"title":"计算代码行数","slug":"计算代码行数","date":"2022-08-10T00:41:24.000Z","updated":"2022-08-10T00:41:24.000Z","comments":true,"path":"posts/a7ab6980.html","link":"","permalink":"https://macongmc.github.io/posts/a7ab6980.html","excerpt":"","text":"package com; import java.io.File; import java.nio.file.Files; import java.nio.file.Paths; import java.util.Objects; import java.util.function.Consumer; import java.util.function.Function; import java.util.stream.Stream; /** * Desc: 统计项目代码行数 * Created by Java指南者 on 2020-06-25 14:49 */ public class ProjectCodeCount { public static &lt;T&gt; Consumer&lt;T&gt; cof(UncheckedConsumer&lt;T&gt; mapper) { Objects.requireNonNull(mapper); return t -&gt; { try { mapper.accept(t); } catch (Exception ex) { throw new RuntimeException(ex); } }; } public static &lt;T&gt; Consumer&lt;T&gt; ncof(UncheckedConsumer&lt;T&gt; mapper) { Objects.requireNonNull(mapper); return t -&gt; { try { mapper.accept(t); } catch (Exception ex) { ex.printStackTrace(); } }; } public static &lt;T, R&gt; Function&lt;T, R&gt; of(UncheckedFunction&lt;T, R&gt; mapper) { Objects.requireNonNull(mapper); return t -&gt; { try { return mapper.apply(t); } catch (Exception ex) { throw new RuntimeException(ex); } }; } public static &lt;T, R&gt; Function&lt;T, R&gt; eof(UncheckedFunction&lt;T, R&gt; mapper, Exception cex) { Objects.requireNonNull(mapper); return t -&gt; { try { return mapper.apply(t); } catch (Exception ex) { if (cex != null &amp;&amp; cex.getClass() == ex.getClass()) { throw new RuntimeException(cex); } else { throw new RuntimeException(ex); } } }; } public static &lt;T, R&gt; Function&lt;T, R&gt; of(UncheckedFunction&lt;T, R&gt; mapper, R defaultR) { Objects.requireNonNull(mapper); return t -&gt; { try { return mapper.apply(t); } catch (Exception ex) { ex.printStackTrace(System.err); return defaultR; } }; } @FunctionalInterface public static interface UncheckedFunction&lt;T, R&gt; { R apply(T t) throws Exception; } @FunctionalInterface public static interface UncheckedConsumer&lt;T&gt; { void accept(T t) throws Exception; } /** * 查看项目文件夹下的代码行数 * * @param args * @throws Exception */ public static void main(String[] args) throws Exception { String path = \"C:\\\\Users\\\\16231\\\\Desktop\\\\test\\\\safe-edu-servers\\\\safe-edu-server\"; File f = new File(path); File[] files = f.listFiles(); if (files == null || files.length &lt; 1) { return; } int allCount = 0; for (File fi : files) { String[] split = fi.toString().split(\"/\"); if (fi.isDirectory() &amp;&amp; !split[split.length - 1].startsWith(\".\")) { long count = Files.walk(Paths.get(fi.toString())) // 递归获得项目目录下的所有文件 .filter(file -&gt; !Files.isDirectory(file)) // 筛选出文件 .filter(file -&gt; file.toString().endsWith(\".java\")) // 筛选出 java 文件 .flatMap(ProjectCodeCount.of(file -&gt; Files.lines(file), Stream.empty())) // 将会抛出受检异常的 Lambda 包装为 抛出非受检异常的 Lambda .filter(line -&gt; !line.trim().isEmpty()) // 过滤掉空行 .filter(line -&gt; !line.trim().startsWith(\"//\")) //过滤掉 //之类的注释 .filter(line -&gt; !(line.trim().startsWith(\"/*\") &amp;&amp; line.trim().endsWith(\"*/\"))) //过滤掉/* */之类的注释 .filter(line -&gt; !(line.trim().startsWith(\"/*\") &amp;&amp; !line.trim().endsWith(\"*/\"))) //过滤掉以 /* 开头的注释（去除空格后的开头） .filter(line -&gt; !(!line.trim().startsWith(\"/*\") &amp;&amp; line.trim().endsWith(\"*/\"))) //过滤掉已 */ 结尾的注释 .filter(line -&gt; !line.trim().startsWith(\"*\")) //过滤掉 javadoc 中的文字注释 .filter(line -&gt; !line.trim().startsWith(\"@Override\")) //过滤掉方法上含 @Override 的 .count(); System.out.println(split[split.length - 1] + \" : \" + count); allCount += count; } } System.out.println(\"总的代码行数：\" + allCount); } }","categories":[{"name":"工具篇","slug":"工具篇","permalink":"https://macongmc.github.io/categories/%E5%B7%A5%E5%85%B7%E7%AF%87/"}],"tags":[{"name":"计算","slug":"计算","permalink":"https://macongmc.github.io/tags/%E8%AE%A1%E7%AE%97/"}],"author":"马聪"},{"title":"Seata","slug":"Seata","date":"2022-08-07T14:15:44.000Z","updated":"2022-08-07T14:15:44.000Z","comments":true,"path":"posts/8d9a091c.html","link":"","permalink":"https://macongmc.github.io/posts/8d9a091c.html","excerpt":"","text":"一.分布式事务理论1.CAP理论一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项. 2.BASE理论BASE理论是对CAP的一种解决思路，包含三个思想： Basically Available （基本可用）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。 Soft State（软状态）：在一定时间内，允许出现中间状态，比如临时的不一致状态。 Eventually Consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。 3.解决思路分布式事务最大的问题是各个子事务的一致性问题，因此可以借鉴CAP定理和BASE理论，有两种解决思路： AP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现最终一致。 CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致。但事务等待过程中，处于弱可用状态。 二.seata架构Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。 Seata事务管理中有三个重要的角色： TC (Transaction Coordinator) - 事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚。 TM (Transaction Manager) - 事务管理器：定义全局事务的范围、开始全局事务、提交或回滚全局事务。 RM (Resource Manager) - 资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 Seata基于上述架构提供了四种不同的分布式事务解决方案： XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入 TCC模式：最终一致的分阶段事务模式，有业务侵入 AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式 SAGA模式：长事务模式，有业务侵入 无论哪种方案，都离不开TC，也就是事务的协调者。 Seata 官方文档 1.部署首先，在order-service中引入依赖： &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--版本较低，1.3.0，因此排除--&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;!--seata starter 采用1.4.2版本--&gt; &lt;version&gt;${seata.version}&lt;/version&gt; &lt;/dependency&gt; 2.配置TC地址在order-service中的application.yml中，配置TC服务信息，通过注册中心nacos，结合服务名称获取TC地址： seata: registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址 type: nacos # 注册中心类型 nacos nacos: server-addr: 127.0.0.1:8848 # nacos地址 namespace: \"\" # namespace，默认为空 group: DEFAULT_GROUP # 分组，默认是DEFAULT_GROUP application: seata-tc-server # seata服务名称 username: nacos password: nacos tx-service-group: seata-demo # 事务组名称 service: vgroup-mapping: # 事务组与cluster的映射关系 seata-demo: SH 微服务如何根据这些配置寻找TC的地址呢？ 我们知道注册到Nacos中的微服务，确定一个具体实例需要四个信息： namespace：命名空间 group：分组 application：服务名 cluster：集群名 以上四个信息，在刚才的yaml文件中都能找到： namespace为空，就是默认的public 结合起来，TC服务的信息就是：public@DEFAULT_GROUP@seata-tc-server@SH，这样就能确定TC服务集群了。然后就可以去Nacos拉取对应的实例信息了。 3.其它服务其它两个微服务也都参考order-service的步骤来做，完全一样。 三.XA模式XA 规范 是 X/Open 组织定义的分布式事务处理（DTP，Distributed Transaction Processing）标准，XA 规范 描述了全局的TM与局部的RM之间的接口，几乎所有主流的数据库都对 XA 规范 提供了支持。 正常情况： 异常情况： 一阶段： 事务协调者通知每个事物参与者执行本地事务 本地事务执行完成后报告事务执行状态给事务协调者，此时事务不提交，继续持有数据库锁 二阶段： 事务协调者基于一阶段的报告来判断下一步操作 如果一阶段都成功，则通知所有事务参与者，提交事务 如果一阶段任意一个参与者失败，则通知所有事务参与者回滚事务 1.Seata的XA模型Seata对原始的XA模式做了简单的封装和改造，以适应自己的事务模型，基本架构如图： RM一阶段的工作： ​ ① 注册分支事务到TC ​ ② 执行分支业务sql但不提交 ​ ③ 报告执行状态到TC TC二阶段的工作： TC检测各分支事务执行状态 a.如果都成功，通知所有RM提交事务 b.如果有失败，通知所有RM回滚事务 RM二阶段的工作： 接收TC指令，提交或回滚事务 2.优缺点XA模式的优点是什么？ 事务的强一致性，满足ACID原则。 常用数据库都支持，实现简单，并且没有代码侵入 XA模式的缺点是什么？ 因为一阶段需要锁定数据库资源，等待二阶段结束才释放，性能较差 依赖关系型数据库实现事务 3.实现XA模式Seata的starter已经完成了XA模式的自动装配，实现非常简单，步骤如下： 1）修改application.yml文件（每个参与事务的微服务），开启XA模式： seata: data-source-proxy-mode: XA 2）给发起全局事务的入口方法添加@GlobalTransactional注解: 本例中是OrderServiceImpl中的create方法. 3）重启服务并测试 重启order-service，再次测试，发现无论怎样，三个微服务都能成功回滚。 四.AT模式AT模式同样是分阶段提交的事务模型，不过缺弥补了XA模型中资源锁定周期过长的缺陷。 4.2.1.Seata的AT模型基本流程图： 阶段一RM的工作： 注册分支事务 记录undo-log（数据快照） 执行业务sql并提交 报告事务状态 阶段二提交时RM的工作： 删除undo-log即可 阶段二回滚时RM的工作： 根据undo-log恢复数据到更新前 4.2.2.流程梳理我们用一个真实的业务来梳理下AT模式的原理。 比如，现在又一个数据库表，记录用户余额： id money 1 100 其中一个分支业务要执行的SQL为： update tb_account set money = money - 10 where id = 1 AT模式下，当前分支事务执行流程如下： 一阶段： 1）TM发起并注册全局事务到TC 2）TM调用分支事务 3）分支事务准备执行业务SQL 4）RM拦截业务SQL，根据where条件查询原始数据，形成快照。 { \"id\": 1, \"money\": 100 } 5）RM执行业务SQL，提交本地事务，释放数据库锁。此时 money = 90 6）RM报告本地事务状态给TC 二阶段： 1）TM通知TC事务结束 2）TC检查分支事务状态 ​ a）如果都成功，则立即删除快照 ​ b）如果有分支事务失败，需要回滚。读取快照数据（{\"id\": 1, \"money\": 100}），将快照恢复到数据库。此时数据库再次恢复为100 流程图： 4.2.3.AT与XA的区别简述AT模式与XA模式最大的区别是什么？ XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。 XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。 XA模式强一致；AT模式最终一致 4.2.4.脏写问题在多线程并发访问AT模式的分布式事务时，有可能出现脏写问题，如图： 解决思路就是引入了全局锁的概念。在释放DB锁之前，先拿到全局锁。避免同一时刻有另外一个事务来操作当前数据。 4.2.5.优缺点AT模式的优点： 一阶段完成直接提交事务，释放数据库资源，性能比较好 利用全局锁实现读写隔离 没有代码侵入，框架自动完成回滚和提交 AT模式的缺点： 两阶段之间属于软状态，属于最终一致 框架的快照功能会影响性能，但比XA模式要好很多 4.2.6.实现AT模式AT模式中的快照生成、回滚等动作都是由框架自动完成，没有任何代码侵入，因此实现非常简单。 只不过，AT模式需要一个表来记录全局锁、另一张表来记录数据快照undo_log。 1）导入数据库表，记录全局锁 导入课前资料提供的Sql文件：seata-at.sql，其中lock_table导入到TC服务关联的数据库，undo_log表导入到微服务关联的数据库： 2）修改application.yml文件，将事务模式修改为AT模式即可： seata: data-source-proxy-mode: AT # 默认就是AT 3）重启服务并测试 4.3.TCC模式TCC模式与AT模式非常相似，每阶段都是独立事务，不同的是TCC通过人工编码来实现数据恢复。需要实现三个方法： Try：资源的检测和预留； Confirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功。 Cancel：预留资源释放，可以理解为try的反向操作。 4.3.1.流程分析举例，一个扣减用户余额的业务。假设账户A原来余额是100，需要余额扣减30元。 阶段一（ Try ）：检查余额是否充足，如果充足则冻结金额增加30元，可用余额扣除30 初识余额： 余额充足，可以冻结： 此时，总金额 = 冻结金额 + 可用金额，数量依然是100不变。事务直接提交无需等待其它事务。 **阶段二（Confirm)**：假如要提交（Confirm），则冻结金额扣减30 确认可以提交，不过之前可用金额已经扣减过了，这里只要清除冻结金额就好了： 此时，总金额 = 冻结金额 + 可用金额 = 0 + 70 = 70元 **阶段二(Canncel)**：如果要回滚（Cancel），则冻结金额扣减30，可用余额增加30 需要回滚，那么就要释放冻结金额，恢复可用金额： 4.3.2.Seata的TCC模型Seata中的TCC模型依然延续之前的事务架构，如图： 4.3.3.优缺点TCC模式的每个阶段是做什么的？ Try：资源检查和预留 Confirm：业务执行和提交 Cancel：预留资源的释放 TCC的优点是什么？ 一阶段完成直接提交事务，释放数据库资源，性能好 相比AT模型，无需生成快照，无需使用全局锁，性能最强 不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库 TCC的缺点是什么？ 有代码侵入，需要人为编写try、Confirm和Cancel接口，太麻烦 软状态，事务是最终一致 需要考虑Confirm和Cancel的失败情况，做好幂等处理 4.3.4.事务悬挂和空回滚1）空回滚当某分支事务的try阶段阻塞时，可能导致全局事务超时而触发二阶段的cancel操作。在未执行try操作时先执行了cancel操作，这时cancel不能做回滚，就是空回滚。 如图： 执行cancel操作时，应当判断try是否已经执行，如果尚未执行，则应该空回滚。 2）业务悬挂对于已经空回滚的业务，之前被阻塞的try操作恢复，继续执行try，就永远不可能confirm或cancel ，事务一直处于中间状态，这就是业务悬挂。 执行try操作时，应当判断cancel是否已经执行过了，如果已经执行，应当阻止空回滚后的try操作，避免悬挂 4.3.5.实现TCC模式解决空回滚和业务悬挂问题，必须要记录当前事务状态，是在try、还是cancel？ 1）思路分析这里我们定义一张表： CREATE TABLE `account_freeze_tbl` ( `xid` varchar(128) NOT NULL, `user_id` varchar(255) DEFAULT NULL COMMENT '用户id', `freeze_money` int(11) unsigned DEFAULT '0' COMMENT '冻结金额', `state` int(1) DEFAULT NULL COMMENT '事务状态，0:try，1:confirm，2:cancel', PRIMARY KEY (`xid`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT; 其中： xid：是全局事务id freeze_money：用来记录用户冻结金额 state：用来记录事务状态 那此时，我们的业务开怎么做呢？ Try业务： 记录冻结金额和事务状态到account_freeze表 扣减account表可用金额 Confirm业务 根据xid删除account_freeze表的冻结记录 Cancel业务 修改account_freeze表，冻结金额为0，state为2 修改account表，恢复可用金额 如何判断是否空回滚？ cancel业务中，根据xid查询account_freeze，如果为null则说明try还没做，需要空回滚 如何避免业务悬挂？ try业务中，根据xid查询account_freeze ，如果已经存在则证明Cancel已经执行，拒绝执行try业务 接下来，我们改造account-service，利用TCC实现余额扣减功能。 2）声明TCC接口TCC的Try、Confirm、Cancel方法都需要在接口中基于注解来声明， 我们在account-service项目中的cn.itcast.account.service包中新建一个接口，声明TCC三个接口： package cn.itcast.account.service; import io.seata.rm.tcc.api.BusinessActionContext; import io.seata.rm.tcc.api.BusinessActionContextParameter; import io.seata.rm.tcc.api.LocalTCC; import io.seata.rm.tcc.api.TwoPhaseBusinessAction; @LocalTCC public interface AccountTCCService { @TwoPhaseBusinessAction(name = \"deduct\", commitMethod = \"confirm\", rollbackMethod = \"cancel\") void deduct(@BusinessActionContextParameter(paramName = \"userId\") String userId, @BusinessActionContextParameter(paramName = \"money\")int money); boolean confirm(BusinessActionContext ctx); boolean cancel(BusinessActionContext ctx); } 3）编写实现类在account-service服务中的cn.itcast.account.service.impl包下新建一个类，实现TCC业务： package cn.itcast.account.service.impl; import cn.itcast.account.entity.AccountFreeze; import cn.itcast.account.mapper.AccountFreezeMapper; import cn.itcast.account.mapper.AccountMapper; import cn.itcast.account.service.AccountTCCService; import io.seata.core.context.RootContext; import io.seata.rm.tcc.api.BusinessActionContext; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; @Service @Slf4j public class AccountTCCServiceImpl implements AccountTCCService { @Autowired private AccountMapper accountMapper; @Autowired private AccountFreezeMapper freezeMapper; @Override @Transactional public void deduct(String userId, int money) { // 0.获取事务id String xid = RootContext.getXID(); // 1.扣减可用余额 accountMapper.deduct(userId, money); // 2.记录冻结金额，事务状态 AccountFreeze freeze = new AccountFreeze(); freeze.setUserId(userId); freeze.setFreezeMoney(money); freeze.setState(AccountFreeze.State.TRY); freeze.setXid(xid); freezeMapper.insert(freeze); } @Override public boolean confirm(BusinessActionContext ctx) { // 1.获取事务id String xid = ctx.getXid(); // 2.根据id删除冻结记录 int count = freezeMapper.deleteById(xid); return count == 1; } @Override public boolean cancel(BusinessActionContext ctx) { // 0.查询冻结记录 String xid = ctx.getXid(); AccountFreeze freeze = freezeMapper.selectById(xid); // 1.恢复可用余额 accountMapper.refund(freeze.getUserId(), freeze.getFreezeMoney()); // 2.将冻结金额清零，状态改为CANCEL freeze.setFreezeMoney(0); freeze.setState(AccountFreeze.State.CANCEL); int count = freezeMapper.updateById(freeze); return count == 1; } } 4.4.SAGA模式Saga 模式是 Seata 即将开源的长事务解决方案，将由蚂蚁金服主要贡献。 其理论基础是Hector &amp; Kenneth 在1987年发表的论文Sagas。 Seata官网对于Saga的指南：https://seata.io/zh-cn/docs/user/saga.html 4.4.1.原理在 Saga 模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。 分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。 Saga也分为两个阶段： 一阶段：直接提交本地事务 二阶段：成功则什么都不做；失败则通过编写补偿业务来回滚 4.4.2.优缺点优点： 事务参与者可以基于事件驱动实现异步调用，吞吐高 一阶段直接提交事务，无锁，性能好 不用编写TCC中的三个阶段，实现简单 缺点： 软状态持续时间不确定，时效性差 没有锁，没有事务隔离，会有脏写 4.5.四种模式对比我们从以下几个方面来对比四种实现： 一致性：能否保证事务的一致性？强一致还是最终一致？ 隔离性：事务之间的隔离性如何？ 代码侵入：是否需要对业务代码改造？ 性能：有无性能损耗？ 场景：常见的业务场景 如图：","categories":[{"name":"分布式事务","slug":"分布式事务","permalink":"https://macongmc.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://macongmc.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"springcloud alibaba","slug":"springcloud-alibaba","permalink":"https://macongmc.github.io/tags/springcloud-alibaba/"}],"author":"马聪"},{"title":"Elasticsearch","slug":"Elasticsearch","date":"2022-08-04T13:36:58.000Z","updated":"2022-08-04T13:36:58.000Z","comments":true,"path":"posts/d32d37e5.html","link":"","permalink":"https://macongmc.github.io/posts/d32d37e5.html","excerpt":"","text":"一.搭建ElasticSearch环境拉去镜像 docker pull elasticsearch:7.4.0 创建容器 docker run -id --name elasticsearch -d --restart=always -p 9200:9200 -p 9300:9300 -v /usr/share/elasticsearch/plugins:/usr/share/elasticsearch/plugins -e \"discovery.type=single-node\" elasticsearch:7.4.0 配置分词器把资料中的elasticsearch-analysis-ik-7.4.0.zip上传到服务器上,放到对应目录（plugins）解压 #切换目录 cd /usr/share/elasticsearch/plugins #新建目录 mkdir analysis-ik cd analysis-ik #root根目录中拷贝文件 mv elasticsearch-analysis-ik-7.4.0.zip /usr/share/elasticsearch/plugins/analysis-ik #解压文件 cd /usr/share/elasticsearch/plugins/analysis-ik unzip elasticsearch-analysis-ik-7.4.0.zip 二.批量导入数据库1.依赖&lt;!--elasticsearch--&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;7.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-client&lt;/artifactId&gt; &lt;version&gt;7.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;7.4.0&lt;/version&gt; &lt;/dependency&gt; 2.配置类import lombok.Getter; import lombok.Setter; import org.apache.http.HttpHost; import org.elasticsearch.client.RestClient; import org.elasticsearch.client.RestHighLevelClient; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Getter @Setter @Configuration @ConfigurationProperties(prefix = \"elasticsearch\") public class ElasticSearchConfig { private String host; private int port; @Bean public RestHighLevelClient client(){ return new RestHighLevelClient(RestClient.builder( new HttpHost( host, port, \"http\" ) )); } } 3.配置文件server: port: 9999 spring: application: name: es-article datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://82.157.254.101:3306/leadnews_article?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC username: password: # 设置Mapper接口所对应的XML文件位置，如果你在Mapper接口中有自定义方法，需要进行该配置 mybatis-plus: mapper-locations: classpath*:mapper/*.xml # 设置别名包扫描路径，通过该属性可以给包中的类注册别名 type-aliases-package: com.heima.model.article.pojos #自定义elasticsearch连接配置 elasticsearch: host: 82.157.254.101 port: 9200 4.代码@SpringBootTest @RunWith(SpringRunner.class) public class ApArticleTest { @Autowired private ApArticleMapper apArticleMapper; @Autowired private RestHighLevelClient restHighLevelClient; /** * 注意：数据量的导入，如果数据量过大，需要分页导入 * @throws Exception */ /** * 注意：数据量的导入，如果数据量过大，需要分页导入 * @throws Exception */ @Test public void init() throws Exception { //1.查询所有符合条件的文章数据 List&lt;SearchArticleVo&gt; searchArticleVos = apArticleMapper.loadArticleList(); //2.批量导入到es索引库 BulkRequest bulkRequest = new BulkRequest(\"app_info_article\"); for (SearchArticleVo searchArticleVo : searchArticleVos) { IndexRequest indexRequest = new IndexRequest().id(searchArticleVo.getId().toString()) .source(JSON.toJSONString(searchArticleVo), XContentType.JSON); //批量添加数据 bulkRequest.add(indexRequest); } restHighLevelClient.bulk(bulkRequest, RequestOptions.DEFAULT); } 中文文档 javaApi springDate esElasticSearch集成SpringData史上最全查询教程 - 掘金 (juejin.cn) 【Elasticsearch】7. Spring Boot整合ES - 掘金 (juejin.cn)","categories":[{"name":"API","slug":"API","permalink":"https://macongmc.github.io/categories/API/"}],"tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"https://macongmc.github.io/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"}],"author":"马聪"},{"title":"kafka","slug":"kafka","date":"2022-08-03T01:00:24.000Z","updated":"2022-08-03T01:00:24.000Z","comments":true,"path":"posts/5bbc7517.html","link":"","permalink":"https://macongmc.github.io/posts/5bbc7517.html","excerpt":"","text":"一.kafka概述消息中间件对比 特性 ActiveMQ RabbitMQ RocketMQ Kafka 开发语言 java erlang java scala 单机吞吐量 万级 万级 10万级 100万级 时效性 ms us ms ms级以内 可用性 高（主从） 高（主从） 非常高（分布式） 非常高（分布式） 功能特性 成熟的产品、较全的文档、各种协议支持好 并发能力强、性能好、延迟低 MQ功能比较完善，扩展性佳 只支持主要的MQ功能，主要应用于大数据领域 消息中间件对比-选择建议 消息中间件 建议 Kafka 追求高吞吐量，适合产生大量数据的互联网服务的数据收集业务 RocketMQ 可靠性要求很高的金融互联网领域,稳定性高，经历了多次阿里双11考验 RabbitMQ 性能较好，社区活跃度高，数据量没有那么大，优先选择功能比较完备的RabbitMQ kafka介绍 Kafka 是一个分布式流媒体平台,类似于消息队列或企业消息传递系统。kafka官网：http://kafka.apache.org/ 中文文档 kafka介绍-名词解释 producer：发布消息的对象称之为主题生产者（Kafka topic producer） topic：Kafka将消息分门别类，每一类的消息称之为一个主题（Topic） consumer：订阅消息并处理发布的消息的对象称之为主题消费者（consumers） broker：已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理（Broker）。 消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息。 二.安装和配置Kafka对于zookeeper是强依赖，保存kafka相关的节点数据，所以安装Kafka之前必须先安装zookeeper Docker安装zookeeper 下载镜像： docker pull zookeeper 创建容器 docker run -d --restart=always --log-driver json-file --log-opt max-size=100m --log-opt max-file=2 --name zookeeper -p 2181:2181 -v /etc/localtime:/etc/localtime zookeeper Docker安装kafka 下载镜像： docker pull wurstmeister/kafka 创建容器: 云主机 docker run -d --restart=always --log-driver json-file --log-opt max-size=100m --log-opt max-file=2 --name kafka -p 9092:9092 -e KAFKA_BROKER_ID=0 -e KAFKA_ZOOKEEPER_CONNECT=172.21.10.10:2181/kafka -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://172.21.10.10:9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -v /etc/localtime:/etc/localtime wurstmeister/kafka 虚拟机 docker run -d --name kafka \\ --env KAFKA_ADVERTISED_HOST_NAME=192.168.200.130 \\ --env KAFKA_ZOOKEEPER_CONNECT=192.168.200.130:2181 \\ --env KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.200.130:9092 \\ --env KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\ --env KAFKA_HEAP_OPTS=\"-Xmx256M -Xms256M\" \\ --net=host wurstmeister/kafka:2.12-2.3.1 三.kafka入门 生产者发送消息，多个消费者只能有一个消费者接收到消息 生产者发送消息，多个消费者都可以接收到消息 （1）创建kafka-demo项目，导入依赖 &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;/dependency&gt; （2）生产者发送消息 package com.heima.kafka.sample; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.ProducerConfig; import org.apache.kafka.clients.producer.ProducerRecord; import java.util.Properties; /** * 生产者 */ public class ProducerQuickStart { public static void main(String[] args) { //1.kafka的配置信息 Properties properties = new Properties(); //kafka的连接地址 properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,\"192.168.200.130:9092\"); //发送失败，失败的重试次数 properties.put(ProducerConfig.RETRIES_CONFIG,5); //消息key的序列化器 properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\"org.apache.kafka.common.serialization.StringSerializer\"); //消息value的序列化器 properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\"org.apache.kafka.common.serialization.StringSerializer\"); //2.生产者对象 KafkaProducer&lt;String,String&gt; producer = new KafkaProducer&lt;String, String&gt;(properties); //封装发送的消息 ProducerRecord&lt;String,String&gt; record = new ProducerRecord&lt;String, String&gt;(\"itheima-topic\",\"100001\",\"hello kafka\"); //3.发送消息 producer.send(record); //4.关闭消息通道，必须关闭，否则消息发送不成功 producer.close(); } } （3）消费者接收消息 package com.heima.kafka.sample; import org.apache.kafka.clients.consumer.ConsumerConfig; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; import java.time.Duration; import java.util.Collections; import java.util.Properties; /** * 消费者 */ public class ConsumerQuickStart { public static void main(String[] args) { //1.添加kafka的配置信息 Properties properties = new Properties(); //kafka的连接地址 properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"192.168.200.130:9092\"); //消费者组 properties.put(ConsumerConfig.GROUP_ID_CONFIG, \"group2\"); //消息的反序列化器 properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\"); properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\"); //2.消费者对象 KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(properties); //3.订阅主题 consumer.subscribe(Collections.singletonList(\"itheima-topic\")); //当前线程一直处于监听状态 while (true) { //4.获取消息 ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) { System.out.println(consumerRecord.key()); System.out.println(consumerRecord.value()); } } } } 总结 生产者发送消息，多个消费者订阅同一个主题，只能有一个消费者收到消息（一对一） 生产者发送消息，多个消费者订阅同一个主题，所有消费者都能收到消息（一对多） 四.kafka高可用设计1.集群 Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成 这样如果集群中某一台机器宕机，其他机器上的 Broker 也依然能够对外提供服务。这其实就是 Kafka 提供高可用的手段之一 2.备份机制(Replication） Kafka 中消息的备份又叫做 副本（Replica） Kafka 定义了两类副本： 领导者副本（Leader Replica） 追随者副本（Follower Replica） 同步方式 ISR（in-sync replica）需要同步复制保存的follower 如果leader失效后，需要选出新的leader，选举的原则如下： 第一：选举时优先从ISR中选定，因为这个列表中follower的数据是与leader同步的 第二：如果ISR列表中的follower都不行了，就只能从其他follower中选取 极端情况，就是所有副本都失效了，这时有两种方案 第一：等待ISR中的一个活过来，选为Leader，数据可靠，但活过来的时间不确定 第二：选择第一个活过来的Replication，不一定是ISR中的，选为leader，以最快速度恢复可用性，但数据不一定完整 五.kafka生产者详解1.发送类型 同步发送 使用send()方法发送，它会返回一个Future对象，调用get()方法进行等待，就可以知道消息是否发送成功 RecordMetadata recordMetadata = producer.send(kvProducerRecord).get(); System.out.println(recordMetadata.offset()); 异步发送 调用send()方法，并指定一个回调函数，服务器在返回响应时调用函数 //异步消息发送 producer.send(kvProducerRecord, new Callback() { @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) { if(e != null){ System.out.println(\"记录异常信息到日志表中\"); } System.out.println(recordMetadata.offset()); } }); 2.参数详解ack 代码的配置方式： //ack配置 消息确认机制 prop.put(ProducerConfig.ACKS_CONFIG,\"all\"); 参数的选择说明 确认机制 说明 acks=0 生产者在成功写入消息之前不会等待任何来自服务器的响应,消息有丢失的风险，但是速度最快 acks=1（默认值） 只要集群首领节点收到消息，生产者就会收到一个来自服务器的成功响应 acks=all 只有当所有参与赋值的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应 retries 生产者从服务器收到的错误有可能是临时性错误，在这种情况下，retries参数的值决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试返回错误，默认情况下，生产者会在每次重试之间等待100ms 代码中配置方式： //重试次数 prop.put(ProducerConfig.RETRIES_CONFIG,10); 消息压缩 默认情况下， 消息发送时不会被压缩。 代码中配置方式： //数据压缩 prop.put(ProducerConfig.COMPRESSION_TYPE_CONFIG,\"lz4\"); 压缩算法 说明 snappy 占用较少的 CPU， 却能提供较好的性能和相当可观的压缩比， 如果看重性能和网络带宽，建议采用 lz4 占用较少的 CPU， 压缩和解压缩速度较快，压缩比也很客观 gzip 占用较多的 CPU，但会提供更高的压缩比，网络带宽有限，可以使用这种算法 使用压缩可以降低网络传输开销和存储开销，而这往往是向 Kafka 发送消息的瓶颈所在。 六.kafka消费者详解1.消费者组消费者组（Consumer Group） ：指的就是由一个或多个消费者组成的群体 一个发布在Topic上消息被分发给此消费者组中的一个消费者 所有的消费者都在一个组中，那么这就变成了queue模型 所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型 2.消息有序性应用场景： ​ 即时消息中的单对单聊天和群聊，保证发送方消息发送顺序与接收 方的顺序一致 ​ 充值转账两个渠道在同一个时间进行余额变更，短信通知必须要有顺序 topic分区中消息只能由消费者组中的唯一一个消费者处理，所以消息肯定是按照先后顺序进行处理的。但是它也仅仅是保证Topic的一个分区顺序处理，不能保证跨分区的消息先后处理顺序。 所以，如果你想要顺序的处理Topic的所有消息，那就只提供一个分区。 3.提交和偏移量kafka不会像其他JMS队列那样需要得到消费者的确认，消费者可以使用kafka来追踪消息在分区的位置（偏移量） 消费者会往一个叫做_consumer_offset的特殊主题发送消息，消息里包含了每个分区的偏移量。如果消费者发生崩溃或有新的消费者加入群组，就会触发再均衡 如果消费者2挂掉以后，会发生再均衡，消费者2负责的分区会被其他消费者进行消费 再均衡后不可避免会出现一些问题 问题一： 如果提交偏移量小于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会被重复处理。 问题二： 如果提交的偏移量大于客户端的最后一个消息的偏移量，那么处于两个偏移量之间的消息将会丢失。 如果想要解决这些问题，还要知道目前kafka提交偏移量的方式： 提交偏移量的方式有两种，分别是自动提交偏移量和手动提交 自动提交偏移量 当enable.auto.commit被设置为true，提交方式就是让消费者自动提交偏移量，每隔5秒消费者会自动把从poll()方法接收的最大偏移量提交上去 手动提交 ，当enable.auto.commit被设置为false可以有以下三种提交方式 提交当前偏移量（同步提交） 异步提交 同步和异步组合提交 1.提交当前偏移量（同步提交） 把enable.auto.commit设置为false,让应用程序决定何时提交偏移量。使用commitSync()提交偏移量，commitSync()将会提交poll返回的最新的偏移量，所以在处理完所有记录后要确保调用了commitSync()方法。否则还是会有消息丢失的风险。 只要没有发生不可恢复的错误，commitSync()方法会一直尝试直至提交成功，如果提交失败也可以记录到错误日志里。 while (true){ ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord&lt;String, String&gt; record : records) { System.out.println(record.value()); System.out.println(record.key()); try { consumer.commitSync();//同步提交当前最新的偏移量 }catch (CommitFailedException e){ System.out.println(\"记录提交失败的异常：\"+e); } } } 2.异步提交 手动提交有一个缺点，那就是当发起提交调用时应用会阻塞。当然我们可以减少手动提交的频率，但这个会增加消息重复的概率（和自动提交一样）。另外一个解决办法是，使用异步提交的API。 while (true){ ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord&lt;String, String&gt; record : records) { System.out.println(record.value()); System.out.println(record.key()); } consumer.commitAsync(new OffsetCommitCallback() { @Override public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; map, Exception e) { if(e!=null){ System.out.println(\"记录错误的提交偏移量：\"+ map+\",异常信息\"+e); } } }); } 3.同步和异步组合提交 异步提交也有个缺点，那就是如果服务器返回提交失败，异步提交不会进行重试。相比较起来，同步提交会进行重试直到成功或者最后抛出异常给应用。异步提交没有实现重试是因为，如果同时存在多个异步提交，进行重试可能会导致位移覆盖。 举个例子，假如我们发起了一个异步提交commitA，此时的提交位移为2000，随后又发起了一个异步提交commitB且位移为3000；commitA提交失败但commitB提交成功，此时commitA进行重试并成功的话，会将实际上将已经提交的位移从3000回滚到2000，导致消息重复消费。 try { while (true){ ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord&lt;String, String&gt; record : records) { System.out.println(record.value()); System.out.println(record.key()); } consumer.commitAsync(); } }catch (Exception e){+ e.printStackTrace(); System.out.println(\"记录错误信息：\"+e); }finally { try { consumer.commitSync(); }finally { consumer.close(); } } 4.再均衡监听器 ConsumerRebalanceListener onPartitionsRevoked：在分区均衡开始【前】和消费者停止读取消息【后】被调用； onPartitionsAssigned：分区再均衡【后】和消费者开始读取消息【前】被调用 ； import org.apache.kafka.clients.consumer.ConsumerRebalanceListener; import org.apache.kafka.clients.consumer.KafkaConsumer; import org.apache.kafka.clients.consumer.OffsetAndMetadata; import org.apache.kafka.common.TopicPartition; import java.util.Collection; import java.util.Map; import java.util.concurrent.ConcurrentHashMap; public class HandlerRebalance implements ConsumerRebalanceListener { private final Map&lt;TopicPartition, OffsetAndMetadata&gt; currOffsets; private final KafkaConsumer&lt;String,String&gt; consumer; //private final Transaction tr事务类的实例 public HandlerRebalance(Map&lt;TopicPartition, OffsetAndMetadata&gt; currOffsets, KafkaConsumer&lt;String, String&gt; consumer) { this.currOffsets = currOffsets; this.consumer = consumer; } /*模拟一个保存分区偏移量的数据库表*/ public final static ConcurrentHashMap&lt;TopicPartition,Long&gt; partitionOffsetMap = new ConcurrentHashMap(); //分区再均衡之前 public void onPartitionsRevoked( Collection&lt;TopicPartition&gt; partitions) { final String id = Thread.currentThread().getId()+\"\"; System.out.println(id+\"-onPartitionsRevoked参数值为：\"+partitions); System.out.println(id+\"-服务器准备分区再均衡，提交偏移量。当前偏移量为：\" +currOffsets); //开始事务 //偏移量写入数据库 System.out.println(\"分区偏移量表中：\"+partitionOffsetMap); for(TopicPartition topicPartition:partitions){ partitionOffsetMap.put(topicPartition, currOffsets.get(topicPartition).offset()); } consumer.commitSync(currOffsets); //提交业务数和偏移量入库 tr.commit } //分区再均衡完成以后 public void onPartitionsAssigned( Collection&lt;TopicPartition&gt; partitions) { final String id = \"\" + Thread.currentThread().getId(); System.out.println(id+\"-再均衡完成，onPartitionsAssigned参数值为：\"+partitions); System.out.println(\"分区偏移量表中：\"+partitionOffsetMap); for(TopicPartition topicPartition:partitions){ System.out.println(id+\"-topicPartition\"+topicPartition); //模拟从数据库中取得上次的偏移量 Long offset = partitionOffsetMap.get(topicPartition); if(offset==null) continue; //从特定偏移量处开始记录 (从指定分区中的指定偏移量开始消费) //这样就可以确保分区再均衡中的数据不错乱 consumer.seek(topicPartition,partitionOffsetMap.get(topicPartition)); } } } ## 七.springboot集成kafka 1.导入spring-kafka依赖信息 ```xml &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- kafkfa --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2.在resources下创建文件application.yml server: port: 9991 spring: application: name: kafka-demo kafka: bootstrap-servers: 192.168.200.130:9092 producer: retries: 10 key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: org.apache.kafka.common.serialization.StringSerializer consumer: group-id: ${spring.application.name}-test key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: org.apache.kafka.common.serialization.StringDeserializer 3.消息生产者 package com.heima.kafka.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.kafka.core.KafkaTemplate; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class HelloController { @Autowired private KafkaTemplate&lt;String,String&gt; kafkaTemplate; @GetMapping(\"/hello\") public String hello(){ kafkaTemplate.send(\"itcast-topic\",\"黑马程序员\"); return \"ok\"; } } 4.消息消费者 package com.heima.kafka.listener; import org.springframework.kafka.annotation.KafkaListener; import org.springframework.stereotype.Component; import org.springframework.util.StringUtils; @Component public class HelloListener { @KafkaListener(topics = \"itcast-topic\") public void onMessage(String message){ if(!StringUtils.isEmpty(message)){ System.out.println(message); } } } 传递消息为对象 目前springboot整合后的kafka，因为序列化器是StringSerializer，这个时候如果需要传递对象可以有两种方式 方式一：可以自定义序列化器，对象类型众多，这种方式通用性不强，本章节不介绍 方式二：可以把要传递的对象进行转json字符串，接收消息后再转为对象即可，本项目采用这种方式 发送消息 @GetMapping(\"/hello\") public String hello(){ User user = new User(); user.setUsername(\"xiaowang\"); user.setAge(18); kafkaTemplate.send(\"user-topic\", JSON.toJSONString(user)); return \"ok\"; } 接收消息 package com.heima.kafka.listener; import com.alibaba.fastjson.JSON; import com.heima.kafka.pojo.User; import org.springframework.kafka.annotation.KafkaListener; import org.springframework.stereotype.Component; import org.springframework.util.StringUtils; @Component public class HelloListener { @KafkaListener(topics = \"user-topic\") public void onMessage(String message){ if(!StringUtils.isEmpty(message)){ User user = JSON.parseObject(message, User.class); System.out.println(user); } } } 生产者配置 NAME DESCRIPTION TYPE DEFAULT VALID VALUES IMPORTANCE bootstrap.servers host/port列表，用于初始化建立和Kafka集群的连接。列表格式为host1:port1,host2:port2,….，无需添加所有的集群地址，kafka会根据提供的地址发现其他的地址（你可以多提供几个，以防提供的服务器关闭） list high key.serializer 实现 org.apache.kafka.common.serialization.Serializer 接口的 key 的 Serializer 类。 class high value.serializer 实现 org.apache.kafka.common.serialization.Serializer 接口的value 的 Serializer 类。 class high acks 生产者需要leader确认请求完成之前接收的应答数。此配置控制了发送消息的耐用性，支持以下配置： string 1 [all, -1, 0, 1] high acks=0 如果设置为0，那么生产者将不等待任何消息确认。消息将立刻添加到socket缓冲区并考虑发送。在这种情况下不能保障消息被服务器接收到。并且重试机制不会生效（因为客户端不知道故障了没有）。每个消息返回的offset始终设置为-1。 acks=1，这意味着leader写入消息到本地日志就立即响应，而不等待所有follower应答。在这种情况下，如果响应消息之后但follower还未复制之前leader立即故障，那么消息将会丢失。 acks=all 这意味着leader将等待所有副本同步后应答消息。此配置保障消息不会丢失（只要至少有一个同步的副本或者）。这是最强壮的可用性保障。等价于acks=-1。 buffer.memory 生产者用来缓存等待发送到服务器的消息的内存总字节数。如果消息发送比可传递到服务器的快，生产者将阻塞max.block.ms之后，抛出异常。 long 33554432 [0,…] high 此设置应该大致的对应生产者将要使用的总内存，但不是硬约束，因为生产者所使用的所有内存都用于缓冲。一些额外的内存将用于压缩（如果启动压缩），以及用于保持发送中的请求。 compression.type 数据压缩的类型。默认为空（就是不压缩）。有效的值有 none，gzip，snappy, 或 lz4。压缩全部的数据批，因此批的效果也将影响压缩的比率（更多的批次意味着更好的压缩）。 string none high retries 设置一个比零大的值，客户端如果发送失败则会重新发送。注意，这个重试功能和客户端在接到错误之后重新发送没什么不同。如果max.in.flight.requests.per.connection没有设置为1，有可能改变消息发送的顺序，因为如果2个批次发送到一个分区中，并第一个失败了并重试，但是第二个成功了，那么第二个批次将超过第一个。 int 0 [0,…,2147483647] high ssl.key.password 密钥仓库文件中的私钥的密码。 password null high ssl.keystore.location 密钥仓库文件的位置。可用于客户端的双向认证。 string null high ssl.keystore.password 密钥仓库文件的仓库密码。只有配置了ssl.keystore.location时才需要。 password null high ssl.truststore.location 信任仓库的位置 string null high ssl.truststore.password 信任仓库文件的密码 password null high batch.size 当多个消息要发送到相同分区的时，生产者尝试将消息批量打包在一起，以减少请求交互。这样有助于客户端和服务端的性能提升。该配置的默认批次大小（以字节为单位）： int 16384 [0,…] medium 不会打包大于此配置大小的消息。 发送到broker的请求将包含多个批次，每个分区一个，用于发送数据。 较小的批次大小有可能降低吞吐量（批次大小为0则完全禁用批处理）。一个非常大的批次大小可能更浪费内存。因为我们会预先分配这个资源。 client.id 当发出请求时传递给服务器的id字符串。这样做的目的是允许服务器请求记录记录这个【逻辑应用名】，这样能够追踪请求的源，而不仅仅只是ip/prot。 string “” medium connections.max.idle.ms 多少毫秒之后关闭闲置的连接。 long 540000 medium linger.ms 生产者组将发送的消息组合成单个批量请求。正常情况下，只有消息到达的速度比发送速度快的情况下才会出现。但是，在某些情况下，即使在适度的负载下，客户端也可能希望减少请求数量。此设置通过添加少量人为延迟来实现。- 也就是说，不是立即发出一个消息，生产者将等待一个给定的延迟，以便和其他的消息可以组合成一个批次。这类似于Nagle在TCP中的算法。此设置给出批量延迟的上限：一旦我们达到分区的batch.size值的记录，将立即发送，不管这个设置如何，但是，如果比这个小，我们将在指定的“linger”时间内等待更多的消息加入。此设置默认为0（即无延迟）。假设，设置 linger.ms=5，将达到减少发送的请求数量的效果，但对于在没有负载情况，将增加5ms的延迟。 long 0 [0,…] medium max.block.ms 该配置控制 KafkaProducer.send() 和 KafkaProducer.partitionsFor() 将阻塞多长时间。此外这些方法被阻止，也可能是因为缓冲区已满或元数据不可用。在用户提供的序列化程序或分区器中的锁定不会计入此超时。 long 60000 [0,…] medium max.request.size 请求的最大大小（以字节为单位）。此设置将限制生产者的单个请求中发送的消息批次数，以避免发送过大的请求。这也是最大消息批量大小的上限。请注意，服务器拥有自己的批量大小，可能与此不同。 int 1048576 [0,…] medium partitioner.class 实现Partitioner接口的的Partitioner类。 class org.apache.kafka.clients.producer.internals.DefaultPartitioner medium receive.buffer.bytes 读取数据时使用的TCP接收缓冲区(SO_RCVBUF)的大小。如果值为-1，则将使用OS默认值。 int 32768 [-1,…] medium request.timeout.ms 该配置控制客户端等待请求响应的最长时间。如果在超时之前未收到响应，客户端将在必要时重新发送请求，如果重试耗尽，则该请求将失败。 这应该大于replica.lag.time.max.ms，以减少由于不必要的生产者重试引起的消息重复的可能性。 int 30000 [0,…] medium sasl.jaas.config JAAS配置文件使用的格式的SASL连接的JAAS登录上下文参数。这里描述JAAS配置文件格式。该值的格式为：’（=）*;’ password null medium sasl.kerberos.service.name Kafka运行的Kerberos主体名称。可以在Kafka的JAAS配置或Kafka的配置中定义。 string null medium sasl.mechanism SASL机制用于客户端连接。这是安全提供者可用与任何机制。GSSAPI是默认机制。 string GSSAPI medium security.protocol 用于与broker通讯的协议。 有效值为：PLAINTEXT，SSL，SASL_PLAINTEXT，SASL_SSL。 string PLAINTEXT medium send.buffer.bytes 发送数据时，用于TCP发送缓存（SO_SNDBUF）的大小。如果值为 -1，将默认使用系统的。 int 131072 [-1,…] medium ssl.enabled.protocols 启用SSL连接的协议列表。 list TLSv1.2,TLSv1.1,TLSv1 medium ssl.keystore.type 密钥存储文件的文件格式。对于客户端是可选的。 string JKS medium ssl.protocol 最近的JVM中允许的值是TLS，TLSv1.1和TLSv1.2。 较旧的JVM可能支持SSL，SSLv2和SSLv3，但由于已知的安全漏洞，不建议使用SSL。 string TLS medium ssl.provider 用于SSL连接的安全提供程序的名称。默认值是JVM的默认安全提供程序。 string null medium ssl.truststore.type 信任仓库文件的文件格式。 string JKS medium enable.idempotence 当设置为‘true’，生产者将确保每个消息正好一次复制写入到stream。如果‘false’，由于broker故障，生产者重试。即，可以在流中写入重试的消息。此设置默认是‘false’。请注意，启用幂等式需要将max.in.flight.requests.per.connection设置为1，重试次数不能为零。另外acks必须设置为“全部”。如果这些值保持默认值，我们将覆盖默认值。 如果这些值设置为与幂等生成器不兼容的值，则将抛出一个ConfigException异常。如果这些值设置为与幂等生成器不兼容的值，则将抛出一个ConfigException异常。 boolean FALSE low interceptor.classes 实现ProducerInterceptor接口，你可以在生产者发布到Kafka群集之前拦截（也可变更）生产者收到的消息。默认情况下没有拦截器。 list null low max.in.flight.requests.per.connection 阻塞之前，客户端单个连接上发送的未应答请求的最大数量。注意，如果此设置设置大于1且发送失败，则会由于重试（如果启用了重试）会导致消息重新排序的风险。 int 5 [1,…] low metadata.max.age.ms 在一段时间段之后（以毫秒为单位），强制更新元数据，即使我们没有看到任何分区leader的变化，也会主动去发现新的broker或分区。 long 300000 [0,…] low metric.reporters 用作metrics reporters（指标记录员）的类的列表。实现MetricReporter接口，将受到新增加的度量标准创建类插入的通知。 JmxReporter始终包含在注册JMX统计信息中。 list “” low metrics.num.samples 维护用于计算度量的样例数量。 int 2 [1,…] low metrics.recording.level 指标的最高记录级别。 string INFO [INFO, DEBUG] low metrics.sample.window.ms 度量样例计算上 long 30000 [0,…] low reconnect.backoff.max.ms 重新连接到重复无法连接的代理程序时等待的最大时间（毫秒）。 如果提供，每个主机的回退将会连续增加，直到达到最大值。 计算后退增加后，增加20％的随机抖动以避免连接风暴。 long 1000 [0,…] low reconnect.backoff.ms 尝试重新连接到给定主机之前等待的基本时间量。这避免了在循环中高频率的重复连接到主机。这种回退适应于客户端对broker的所有连接尝试。 long 50 [0,…] low retry.backoff.ms 尝试重试指定topic分区的失败请求之前等待的时间。这样可以避免在某些故障情况下高频次的重复发送请求。 long 100 [0,…] low sasl.kerberos.kinit.cmd Kerberos kinit 命令路径。 string /usr/bin/kinit low sasl.kerberos.min.time.before.relogin Login线程刷新尝试之间的休眠时间。 long 60000 low sasl.kerberos.ticket.renew.jitter 添加更新时间的随机抖动百分比。 double 0.05 low sasl.kerberos.ticket.renew.window.factor 登录线程将睡眠，直到从上次刷新ticket到期时间的指定窗口因子为止，此时将尝试续订ticket。 double 0.8 low ssl.cipher.suites 密码套件列表。这是使用TLS或SSL网络协议来协商用于网络连接的安全设置的认证，加密，MAC和密钥交换算法的命名组合。默认情况下，支持所有可用的密码套件。 list null low ssl.endpoint.identification.algorithm 使用服务器证书验证服务器主机名的端点识别算法。 string null low ssl.keymanager.algorithm 用于SSL连接的密钥管理因子算法。默认值是为Java虚拟机配置的密钥管理器工厂算法。 string SunX509 low ssl.secure.random.implementation 用于SSL加密操作的SecureRandom PRNG实现。 string null low ssl.trustmanager.algorithm 用于SSL连接的信任管理因子算法。默认值是JAVA虚拟机配置的信任管理工厂算法。 string PKIX low transaction.timeout.ms 生产者在主动中止正在进行的交易之前，交易协调器等待事务状态更新的最大时间（以ms为单位）。如果此值大于broker中的max.transaction.timeout.ms设置，则请求将失败，并报“InvalidTransactionTimeout”错误。 int 60000 low transactional.id 用于事务传递的TransactionalId。这样可以跨多个生产者会话的可靠性语义，因为它允许客户端保证在开始任何新事务之前使用相同的TransactionalId的事务已经完成。如果没有提供TransactionalId，则生产者被限制为幂等传递。请注意，如果配置了TransactionalId，则必须启用enable.idempotence。 默认值为空，这意味着无法使用事务。 string null non-empty string low 消费者配置 NAME DESCRIPTION TYPE DEFAULT VALID VALUES IMPORTANCE bootstrap.servers host/port,用于和kafka集群建立初始化连接。因为这些服务器地址仅用于初始化连接，并通过现有配置的来发现全部的kafka集群成员（集群随时会变化），所以此列表不需要包含完整的集群地址（但尽量多配置几个，以防止配置的服务器宕机）。 list high key.deserializer key的解析序列化接口实现类（Deserializer）。 class high value.deserializer value的解析序列化接口实现类（Deserializer） class high fetch.min.bytes 服务器哦拉取请求返回的最小数据量，如果数据不足，请求将等待数据积累。默认设置为1字节，表示只要单个字节的数据可用或者读取等待请求超时，就会应答读取请求。将此值设置的越大将导致服务器等待数据累积的越长，这可能以一些额外延迟为代价提高服务器吞吐量。 int 1 [0,…] high group.id 此消费者所属消费者组的唯一标识。如果消费者用于订阅或offset管理策略的组管理功能，则此属性是必须的。 string “” high heartbeat.interval.ms 当使用Kafka的分组管理功能时，心跳到消费者协调器之间的预计时间。心跳用于确保消费者的会话保持活动状态，并当有新消费者加入或离开组时方便重新平衡。该值必须必比session.timeout.ms小，通常不高于1/3。它可以调整的更低，以控制正常重新平衡的预期时间。 int 3000 high max.partition.fetch.bytes 服务器将返回每个分区的最大数据量。如果拉取的第一个非空分区中第一个消息大于此限制，则仍然会返回消息，以确保消费者可以正常的工作。broker接受的最大消息大小通过message.max.bytes（broker config）或max.message.bytes (topic config)定义。参阅fetch.max.bytes以限制消费者请求大小。 int 1048576 [0,…] high session.timeout.ms 用于发现消费者故障的超时时间。消费者周期性的发送心跳到broker，表示其还活着。如果会话超时期满之前没有收到心跳，那么broker将从分组中移除消费者，并启动重新平衡。请注意，该值必须在broker配置的group.min.session.timeout.ms和group.max.session.timeout.ms允许的范围内。 int 10000 high ssl.key.password 密钥存储文件中的私钥的密码。 客户端可选 password null high ssl.keystore.location 密钥存储文件的位置， 这对于客户端是可选的，并且可以用于客户端的双向认证。 string null high ssl.keystore.password 密钥仓库文件的仓库密码。客户端可选，只有ssl.keystore.location配置了才需要。 password null high ssl.truststore.location 信任仓库文件的位置 string null high ssl.truststore.password 信任仓库文件的密码 password null high auto.offset.reset 当Kafka中没有初始offset或如果当前的offset不存在时（例如，该数据被删除了），该怎么办。 string latest [latest, earliest, none] medium 最早：自动将偏移重置为最早的偏移 最新：自动将偏移重置为最新偏移 none：如果消费者组找到之前的offset，则向消费者抛出异常 其他：抛出异常给消费者。 connections.max.idle.ms 指定在多少毫秒之后关闭闲置的连接 long 540000 medium enable.auto.commit 如果为true，消费者的offset将在后台周期性的提交 boolean TRUE medium exclude.internal.topics 内部topic的记录（如偏移量）是否应向消费者公开。如果设置为true，则从内部topic接受记录的唯一方法是订阅它。 boolean TRUE medium fetch.max.bytes 服务器为拉取请求返回的最大数据值。这不是绝对的最大值，如果在第一次非空分区拉取的第一条消息大于该值，该消息将仍然返回，以确保消费者继续工作。接收的最大消息大小通过message.max.bytes (broker config) 或 max.message.bytes (topic config)定义。注意，消费者是并行执行多个提取的。 int 52428800 [0,…] medium max.poll.interval.ms 使用消费者组管理时poll()调用之间的最大延迟。消费者在获取更多记录之前可以空闲的时间量的上限。如果此超时时间期满之前poll()没有调用，则消费者被视为失败，并且分组将重新平衡，以便将分区重新分配给别的成员。 int 300000 [1,…] medium max.poll.records 在单次调用poll()中返回的最大记录数。 int 500 [1,…] medium partition.assignment.strategy 当使用组管理时，客户端将使用分区分配策略的类名来分配消费者实例之间的分区所有权 list class org.apache.kafka medium .clients.consumer .RangeAssignor receive.buffer.bytes 读取数据时使用的TCP接收缓冲区（SO_RCVBUF）的大小。 如果值为-1，则将使用OS默认值。 int 65536 [-1,…] medium request.timeout.ms 配置控制客户端等待请求响应的最长时间。 如果在超时之前未收到响应，客户端将在必要时重新发送请求，如果重试耗尽则客户端将重新发送请求。 int 305000 [0,…] medium sasl.jaas.config JAAS配置文件中SASL连接登录上下文参数。 这里描述JAAS配置文件格式。 该值的格式为： ‘(=)*;’ password null medium sasl.kerberos.service.name Kafka运行Kerberos principal名。可以在Kafka的JAAS配置文件或在Kafka的配置文件中定义。 string null medium sasl.mechanism 用于客户端连接的SASL机制。安全提供者可用的机制。GSSAPI是默认机制。 string GSSAPI medium security.protocol 用于与broker通讯的协议。 有效值为：PLAINTEXT，SSL，SASL_PLAINTEXT，SASL_SSL。 string PLAINTEXT medium send.buffer.bytes 发送数据时要使用的TCP发送缓冲区（SO_SNDBUF）的大小。 如果值为-1，则将使用OS默认值。 int 131072 [-1,…] medium ssl.enabled.protocols 启用SSL连接的协议列表。 list TLSv1.2,TLSv1.1,TLSv1 medium ssl.keystore.type key仓库文件的文件格式，客户端可选。 string JKS medium ssl.protocol 用于生成SSLContext的SSL协议。 默认设置是TLS，这对大多数情况都是适用的。 最新的JVM中的允许值为TLS，TLSv1.1和TLSv1.2。 较旧的JVM可能支持SSL，SSLv2和SSLv3，但由于已知的安全漏洞，不建议使用SSL。 string TLS medium ssl.provider 用于SSL连接的安全提供程序的名称。 默认值是JVM的默认安全提供程序。 string null medium ssl.truststore.type 信任存储文件的文件格式。 string JKS medium auto.commit.interval.ms 如果enable.auto.commit设置为true，则消费者偏移量自动提交给Kafka的频率（以毫秒为单位）。 int 5000 [0,…] low check.crcs 自动检查CRC32记录的消耗。 这样可以确保消息发生时不会在线或磁盘损坏。 此检查增加了一些开销，因此在寻求极致性能的情况下可能会被禁用。 boolean TRUE low client.id 在发出请求时传递给服务器的id字符串。 这样做的目的是通过允许将逻辑应用程序名称包含在服务器端请求日志记录中，来跟踪ip/port的请求源。 string “” low fetch.max.wait.ms 如果没有足够的数据满足fetch.min.bytes，服务器将在接收到提取请求之前阻止的最大时间。 int 500 [0,…] low interceptor.classes 用作拦截器的类的列表。 你可实现ConsumerInterceptor接口以允许拦截（也可能变化）消费者接收的记录。 默认情况下，没有拦截器。 list null low metadata.max.age.ms 在一定时间段之后（以毫秒为单位的），强制更新元数据，即使没有任何分区领导变化，任何新的broker或分区。 long 300000 [0,…] low metric.reporters 用作度量记录员类的列表。实现MetricReporter接口以允许插入通知新的度量创建的类。JmxReporter始终包含在注册JMX统计信息中。 list “” low metrics.num.samples 保持的样本数以计算度量。 int 2 [1,…] low metrics.recording.level 最高的记录级别。 string INFO [INFO, DEBUG] low metrics.sample.window.ms The window of time a metrics sample is computed over. long 30000 [0,…] low reconnect.backoff.ms 尝试重新连接指定主机之前等待的时间，避免频繁的连接主机，这种机制适用于消费者向broker发送的所有请求。 long 50 [0,…] low retry.backoff.ms 尝试重新发送失败的请求到指定topic分区之前的等待时间。避免在某些故障情况下，频繁的重复发送。 long 100 [0,…] low sasl.kerberos.kinit.cmd Kerberos kinit命令路径。 string /usr/bin/kinit low sasl.kerberos.min.time.before.relogin 尝试/恢复之间的登录线程的休眠时间。 long 60000 low sasl.kerberos.ticket.renew.jitter 添加到更新时间的随机抖动百分比。 double 0.05 low sasl.kerberos.ticket.renew.window.factor 登录线程将休眠，直到从上次刷新到ticket的指定的时间窗口因子到期，此时将尝试续订ticket。 double 0.8 low ssl.cipher.suites 密码套件列表，用于TLS或SSL网络协议的安全设置，认证，加密，MAC和密钥交换算法的明明组合。默认情况下，支持所有可用的密码套件。 list null low ssl.endpoint.identification.algorithm 使用服务器证书验证服务器主机名的端点识别算法。 string null low ssl.keymanager.algorithm 密钥管理器工厂用于SSL连接的算法。 默认值是为Java虚拟机配置的密钥管理器工厂算法。 string SunX509 low ssl.secure.random.implementation 用于SSL加密操作的SecureRandom PRNG实现。 string null low ssl.trustmanager.algorithm 信任管理器工厂用于SSL连接的算法。 默认值是为Java虚拟机配置的信任管理器工厂算法。 string PKIX low","categories":[{"name":"API","slug":"API","permalink":"https://macongmc.github.io/categories/API/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://macongmc.github.io/tags/kafka/"},{"name":"消息队列","slug":"消息队列","permalink":"https://macongmc.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"author":"马聪"},{"title":"延迟任务Redis","slug":"延迟任务Redis","date":"2022-08-02T05:46:03.000Z","updated":"2022-08-02T05:46:03.000Z","comments":true,"path":"posts/6308532f.html","link":"","permalink":"https://macongmc.github.io/posts/6308532f.html","excerpt":"","text":"一.Redis实现思路 1.安装redisdocker pull redis docker run -d --name redis --restart=always -p 6379:6379 redis --requirepass \"root\" 2.redis依赖dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- redis依赖commons-pool 这个依赖一定要添加 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; 3.redis配置spring: redis: host: 192.168.200.130 password: root port: 6379 4.工具类package com.heima.common.redis; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cache.annotation.CachingConfigurerSupport; import org.springframework.dao.DataAccessException; import org.springframework.data.redis.connection.*; import org.springframework.data.redis.core.*; import org.springframework.data.redis.core.ZSetOperations.TypedTuple; import org.springframework.data.redis.core.types.Expiration; import org.springframework.lang.Nullable; import org.springframework.stereotype.Component; import java.io.IOException; import java.util.*; import java.util.concurrent.TimeUnit; @Component public class CacheService extends CachingConfigurerSupport { @Autowired private StringRedisTemplate stringRedisTemplate; public StringRedisTemplate getstringRedisTemplate() { return this.stringRedisTemplate; } /** -------------------key相关操作--------------------- */ /** * 删除key * * @param key */ public void delete(String key) { stringRedisTemplate.delete(key); } /** * 批量删除key * * @param keys */ public void delete(Collection&lt;String&gt; keys) { stringRedisTemplate.delete(keys); } /** * 序列化key * * @param key * @return */ public byte[] dump(String key) { return stringRedisTemplate.dump(key); } /** * 是否存在key * * @param key * @return */ public Boolean exists(String key) { return stringRedisTemplate.hasKey(key); } /** * 设置过期时间 * * @param key * @param timeout * @param unit * @return */ public Boolean expire(String key, long timeout, TimeUnit unit) { return stringRedisTemplate.expire(key, timeout, unit); } /** * 设置过期时间 * * @param key * @param date * @return */ public Boolean expireAt(String key, Date date) { return stringRedisTemplate.expireAt(key, date); } /** * 查找匹配的key * * @param pattern * @return */ public Set&lt;String&gt; keys(String pattern) { return stringRedisTemplate.keys(pattern); } /** * 将当前数据库的 key 移动到给定的数据库 db 当中 * * @param key * @param dbIndex * @return */ public Boolean move(String key, int dbIndex) { return stringRedisTemplate.move(key, dbIndex); } /** * 移除 key 的过期时间，key 将持久保持 * * @param key * @return */ public Boolean persist(String key) { return stringRedisTemplate.persist(key); } /** * 返回 key 的剩余的过期时间 * * @param key * @param unit * @return */ public Long getExpire(String key, TimeUnit unit) { return stringRedisTemplate.getExpire(key, unit); } /** * 返回 key 的剩余的过期时间 * * @param key * @return */ public Long getExpire(String key) { return stringRedisTemplate.getExpire(key); } /** * 从当前数据库中随机返回一个 key * * @return */ public String randomKey() { return stringRedisTemplate.randomKey(); } /** * 修改 key 的名称 * * @param oldKey * @param newKey */ public void rename(String oldKey, String newKey) { stringRedisTemplate.rename(oldKey, newKey); } /** * 仅当 newkey 不存在时，将 oldKey 改名为 newkey * * @param oldKey * @param newKey * @return */ public Boolean renameIfAbsent(String oldKey, String newKey) { return stringRedisTemplate.renameIfAbsent(oldKey, newKey); } /** * 返回 key 所储存的值的类型 * * @param key * @return */ public DataType type(String key) { return stringRedisTemplate.type(key); } /** -------------------string相关操作--------------------- */ /** * 设置指定 key 的值 * @param key * @param value */ public void set(String key, String value) { stringRedisTemplate.opsForValue().set(key, value); } /** * 获取指定 key 的值 * @param key * @return */ public String get(String key) { return stringRedisTemplate.opsForValue().get(key); } /** * 返回 key 中字符串值的子字符 * @param key * @param start * @param end * @return */ public String getRange(String key, long start, long end) { return stringRedisTemplate.opsForValue().get(key, start, end); } /** * 将给定 key 的值设为 value ，并返回 key 的旧值(old value) * * @param key * @param value * @return */ public String getAndSet(String key, String value) { return stringRedisTemplate.opsForValue().getAndSet(key, value); } /** * 对 key 所储存的字符串值，获取指定偏移量上的位(bit) * * @param key * @param offset * @return */ public Boolean getBit(String key, long offset) { return stringRedisTemplate.opsForValue().getBit(key, offset); } /** * 批量获取 * * @param keys * @return */ public List&lt;String&gt; multiGet(Collection&lt;String&gt; keys) { return stringRedisTemplate.opsForValue().multiGet(keys); } /** * 设置ASCII码, 字符串'a'的ASCII码是97, 转为二进制是'01100001', 此方法是将二进制第offset位值变为value * * @param key * @param * @param value * 值,true为1, false为0 * @return */ public boolean setBit(String key, long offset, boolean value) { return stringRedisTemplate.opsForValue().setBit(key, offset, value); } /** * 将值 value 关联到 key ，并将 key 的过期时间设为 timeout * * @param key * @param value * @param timeout * 过期时间 * @param unit * 时间单位, 天:TimeUnit.DAYS 小时:TimeUnit.HOURS 分钟:TimeUnit.MINUTES * 秒:TimeUnit.SECONDS 毫秒:TimeUnit.MILLISECONDS */ public void setEx(String key, String value, long timeout, TimeUnit unit) { stringRedisTemplate.opsForValue().set(key, value, timeout, unit); } /** * 只有在 key 不存在时设置 key 的值 * * @param key * @param value * @return 之前已经存在返回false,不存在返回true */ public boolean setIfAbsent(String key, String value) { return stringRedisTemplate.opsForValue().setIfAbsent(key, value); } /** * 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始 * * @param key * @param value * @param offset * 从指定位置开始覆写 */ public void setRange(String key, String value, long offset) { stringRedisTemplate.opsForValue().set(key, value, offset); } /** * 获取字符串的长度 * * @param key * @return */ public Long size(String key) { return stringRedisTemplate.opsForValue().size(key); } /** * 批量添加 * * @param maps */ public void multiSet(Map&lt;String, String&gt; maps) { stringRedisTemplate.opsForValue().multiSet(maps); } /** * 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在 * * @param maps * @return 之前已经存在返回false,不存在返回true */ public boolean multiSetIfAbsent(Map&lt;String, String&gt; maps) { return stringRedisTemplate.opsForValue().multiSetIfAbsent(maps); } /** * 增加(自增长), 负数则为自减 * * @param key * @param * @return */ public Long incrBy(String key, long increment) { return stringRedisTemplate.opsForValue().increment(key, increment); } /** * * @param key * @param * @return */ public Double incrByFloat(String key, double increment) { return stringRedisTemplate.opsForValue().increment(key, increment); } /** * 追加到末尾 * * @param key * @param value * @return */ public Integer append(String key, String value) { return stringRedisTemplate.opsForValue().append(key, value); } /** -------------------hash相关操作------------------------- */ /** * 获取存储在哈希表中指定字段的值 * * @param key * @param field * @return */ public Object hGet(String key, String field) { return stringRedisTemplate.opsForHash().get(key, field); } /** * 获取所有给定字段的值 * * @param key * @return */ public Map&lt;Object, Object&gt; hGetAll(String key) { return stringRedisTemplate.opsForHash().entries(key); } /** * 获取所有给定字段的值 * * @param key * @param fields * @return */ public List&lt;Object&gt; hMultiGet(String key, Collection&lt;Object&gt; fields) { return stringRedisTemplate.opsForHash().multiGet(key, fields); } public void hPut(String key, String hashKey, String value) { stringRedisTemplate.opsForHash().put(key, hashKey, value); } public void hPutAll(String key, Map&lt;String, String&gt; maps) { stringRedisTemplate.opsForHash().putAll(key, maps); } /** * 仅当hashKey不存在时才设置 * * @param key * @param hashKey * @param value * @return */ public Boolean hPutIfAbsent(String key, String hashKey, String value) { return stringRedisTemplate.opsForHash().putIfAbsent(key, hashKey, value); } /** * 删除一个或多个哈希表字段 * * @param key * @param fields * @return */ public Long hDelete(String key, Object... fields) { return stringRedisTemplate.opsForHash().delete(key, fields); } /** * 查看哈希表 key 中，指定的字段是否存在 * * @param key * @param field * @return */ public boolean hExists(String key, String field) { return stringRedisTemplate.opsForHash().hasKey(key, field); } /** * 为哈希表 key 中的指定字段的整数值加上增量 increment * * @param key * @param field * @param increment * @return */ public Long hIncrBy(String key, Object field, long increment) { return stringRedisTemplate.opsForHash().increment(key, field, increment); } /** * 为哈希表 key 中的指定字段的整数值加上增量 increment * * @param key * @param field * @param delta * @return */ public Double hIncrByFloat(String key, Object field, double delta) { return stringRedisTemplate.opsForHash().increment(key, field, delta); } /** * 获取所有哈希表中的字段 * * @param key * @return */ public Set&lt;Object&gt; hKeys(String key) { return stringRedisTemplate.opsForHash().keys(key); } /** * 获取哈希表中字段的数量 * * @param key * @return */ public Long hSize(String key) { return stringRedisTemplate.opsForHash().size(key); } /** * 获取哈希表中所有值 * * @param key * @return */ public List&lt;Object&gt; hValues(String key) { return stringRedisTemplate.opsForHash().values(key); } /** * 迭代哈希表中的键值对 * * @param key * @param options * @return */ public Cursor&lt;Map.Entry&lt;Object, Object&gt;&gt; hScan(String key, ScanOptions options) { return stringRedisTemplate.opsForHash().scan(key, options); } /** ------------------------list相关操作---------------------------- */ /** * 通过索引获取列表中的元素 * * @param key * @param index * @return */ public String lIndex(String key, long index) { return stringRedisTemplate.opsForList().index(key, index); } /** * 获取列表指定范围内的元素 * * @param key * @param start * 开始位置, 0是开始位置 * @param end * 结束位置, -1返回所有 * @return */ public List&lt;String&gt; lRange(String key, long start, long end) { return stringRedisTemplate.opsForList().range(key, start, end); } /** * 存储在list头部 * * @param key * @param value * @return */ public Long lLeftPush(String key, String value) { return stringRedisTemplate.opsForList().leftPush(key, value); } /** * * @param key * @param value * @return */ public Long lLeftPushAll(String key, String... value) { return stringRedisTemplate.opsForList().leftPushAll(key, value); } /** * * @param key * @param value * @return */ public Long lLeftPushAll(String key, Collection&lt;String&gt; value) { return stringRedisTemplate.opsForList().leftPushAll(key, value); } /** * 当list存在的时候才加入 * * @param key * @param value * @return */ public Long lLeftPushIfPresent(String key, String value) { return stringRedisTemplate.opsForList().leftPushIfPresent(key, value); } /** * 如果pivot存在,再pivot前面添加 * * @param key * @param pivot * @param value * @return */ public Long lLeftPush(String key, String pivot, String value) { return stringRedisTemplate.opsForList().leftPush(key, pivot, value); } /** * * @param key * @param value * @return */ public Long lRightPush(String key, String value) { return stringRedisTemplate.opsForList().rightPush(key, value); } /** * * @param key * @param value * @return */ public Long lRightPushAll(String key, String... value) { return stringRedisTemplate.opsForList().rightPushAll(key, value); } /** * * @param key * @param value * @return */ public Long lRightPushAll(String key, Collection&lt;String&gt; value) { return stringRedisTemplate.opsForList().rightPushAll(key, value); } /** * 为已存在的列表添加值 * * @param key * @param value * @return */ public Long lRightPushIfPresent(String key, String value) { return stringRedisTemplate.opsForList().rightPushIfPresent(key, value); } /** * 在pivot元素的右边添加值 * * @param key * @param pivot * @param value * @return */ public Long lRightPush(String key, String pivot, String value) { return stringRedisTemplate.opsForList().rightPush(key, pivot, value); } /** * 通过索引设置列表元素的值 * * @param key * @param index * 位置 * @param value */ public void lSet(String key, long index, String value) { stringRedisTemplate.opsForList().set(key, index, value); } /** * 移出并获取列表的第一个元素 * * @param key * @return 删除的元素 */ public String lLeftPop(String key) { return stringRedisTemplate.opsForList().leftPop(key); } /** * 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 * * @param key * @param timeout * 等待时间 * @param unit * 时间单位 * @return */ public String lBLeftPop(String key, long timeout, TimeUnit unit) { return stringRedisTemplate.opsForList().leftPop(key, timeout, unit); } /** * 移除并获取列表最后一个元素 * * @param key * @return 删除的元素 */ public String lRightPop(String key) { return stringRedisTemplate.opsForList().rightPop(key); } /** * 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 * * @param key * @param timeout * 等待时间 * @param unit * 时间单位 * @return */ public String lBRightPop(String key, long timeout, TimeUnit unit) { return stringRedisTemplate.opsForList().rightPop(key, timeout, unit); } /** * 移除列表的最后一个元素，并将该元素添加到另一个列表并返回 * * @param sourceKey * @param destinationKey * @return */ public String lRightPopAndLeftPush(String sourceKey, String destinationKey) { return stringRedisTemplate.opsForList().rightPopAndLeftPush(sourceKey, destinationKey); } /** * 从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 * * @param sourceKey * @param destinationKey * @param timeout * @param unit * @return */ public String lBRightPopAndLeftPush(String sourceKey, String destinationKey, long timeout, TimeUnit unit) { return stringRedisTemplate.opsForList().rightPopAndLeftPush(sourceKey, destinationKey, timeout, unit); } /** * 删除集合中值等于value得元素 * * @param key * @param index * index=0, 删除所有值等于value的元素; index&gt;0, 从头部开始删除第一个值等于value的元素; * index&lt;0, 从尾部开始删除第一个值等于value的元素; * @param value * @return */ public Long lRemove(String key, long index, String value) { return stringRedisTemplate.opsForList().remove(key, index, value); } /** * 裁剪list * * @param key * @param start * @param end */ public void lTrim(String key, long start, long end) { stringRedisTemplate.opsForList().trim(key, start, end); } /** * 获取列表长度 * * @param key * @return */ public Long lLen(String key) { return stringRedisTemplate.opsForList().size(key); } /** --------------------set相关操作-------------------------- */ /** * set添加元素 * * @param key * @param values * @return */ public Long sAdd(String key, String... values) { return stringRedisTemplate.opsForSet().add(key, values); } /** * set移除元素 * * @param key * @param values * @return */ public Long sRemove(String key, Object... values) { return stringRedisTemplate.opsForSet().remove(key, values); } /** * 移除并返回集合的一个随机元素 * * @param key * @return */ public String sPop(String key) { return stringRedisTemplate.opsForSet().pop(key); } /** * 将元素value从一个集合移到另一个集合 * * @param key * @param value * @param destKey * @return */ public Boolean sMove(String key, String value, String destKey) { return stringRedisTemplate.opsForSet().move(key, value, destKey); } /** * 获取集合的大小 * * @param key * @return */ public Long sSize(String key) { return stringRedisTemplate.opsForSet().size(key); } /** * 判断集合是否包含value * * @param key * @param value * @return */ public Boolean sIsMember(String key, Object value) { return stringRedisTemplate.opsForSet().isMember(key, value); } /** * 获取两个集合的交集 * * @param key * @param otherKey * @return */ public Set&lt;String&gt; sIntersect(String key, String otherKey) { return stringRedisTemplate.opsForSet().intersect(key, otherKey); } /** * 获取key集合与多个集合的交集 * * @param key * @param otherKeys * @return */ public Set&lt;String&gt; sIntersect(String key, Collection&lt;String&gt; otherKeys) { return stringRedisTemplate.opsForSet().intersect(key, otherKeys); } /** * key集合与otherKey集合的交集存储到destKey集合中 * * @param key * @param otherKey * @param destKey * @return */ public Long sIntersectAndStore(String key, String otherKey, String destKey) { return stringRedisTemplate.opsForSet().intersectAndStore(key, otherKey, destKey); } /** * key集合与多个集合的交集存储到destKey集合中 * * @param key * @param otherKeys * @param destKey * @return */ public Long sIntersectAndStore(String key, Collection&lt;String&gt; otherKeys, String destKey) { return stringRedisTemplate.opsForSet().intersectAndStore(key, otherKeys, destKey); } /** * 获取两个集合的并集 * * @param key * @param otherKeys * @return */ public Set&lt;String&gt; sUnion(String key, String otherKeys) { return stringRedisTemplate.opsForSet().union(key, otherKeys); } /** * 获取key集合与多个集合的并集 * * @param key * @param otherKeys * @return */ public Set&lt;String&gt; sUnion(String key, Collection&lt;String&gt; otherKeys) { return stringRedisTemplate.opsForSet().union(key, otherKeys); } /** * key集合与otherKey集合的并集存储到destKey中 * * @param key * @param otherKey * @param destKey * @return */ public Long sUnionAndStore(String key, String otherKey, String destKey) { return stringRedisTemplate.opsForSet().unionAndStore(key, otherKey, destKey); } /** * key集合与多个集合的并集存储到destKey中 * * @param key * @param otherKeys * @param destKey * @return */ public Long sUnionAndStore(String key, Collection&lt;String&gt; otherKeys, String destKey) { return stringRedisTemplate.opsForSet().unionAndStore(key, otherKeys, destKey); } /** * 获取两个集合的差集 * * @param key * @param otherKey * @return */ public Set&lt;String&gt; sDifference(String key, String otherKey) { return stringRedisTemplate.opsForSet().difference(key, otherKey); } /** * 获取key集合与多个集合的差集 * * @param key * @param otherKeys * @return */ public Set&lt;String&gt; sDifference(String key, Collection&lt;String&gt; otherKeys) { return stringRedisTemplate.opsForSet().difference(key, otherKeys); } /** * key集合与otherKey集合的差集存储到destKey中 * * @param key * @param otherKey * @param destKey * @return */ public Long sDifference(String key, String otherKey, String destKey) { return stringRedisTemplate.opsForSet().differenceAndStore(key, otherKey, destKey); } /** * key集合与多个集合的差集存储到destKey中 * * @param key * @param otherKeys * @param destKey * @return */ public Long sDifference(String key, Collection&lt;String&gt; otherKeys, String destKey) { return stringRedisTemplate.opsForSet().differenceAndStore(key, otherKeys, destKey); } /** * 获取集合所有元素 * * @param key * @param * @param * @return */ public Set&lt;String&gt; setMembers(String key) { return stringRedisTemplate.opsForSet().members(key); } /** * 随机获取集合中的一个元素 * * @param key * @return */ public String sRandomMember(String key) { return stringRedisTemplate.opsForSet().randomMember(key); } /** * 随机获取集合中count个元素 * * @param key * @param count * @return */ public List&lt;String&gt; sRandomMembers(String key, long count) { return stringRedisTemplate.opsForSet().randomMembers(key, count); } /** * 随机获取集合中count个元素并且去除重复的 * * @param key * @param count * @return */ public Set&lt;String&gt; sDistinctRandomMembers(String key, long count) { return stringRedisTemplate.opsForSet().distinctRandomMembers(key, count); } /** * * @param key * @param options * @return */ public Cursor&lt;String&gt; sScan(String key, ScanOptions options) { return stringRedisTemplate.opsForSet().scan(key, options); } /**------------------zSet相关操作--------------------------------*/ /** * 添加元素,有序集合是按照元素的score值由小到大排列 * * @param key * @param value * @param score * @return */ public Boolean zAdd(String key, String value, double score) { return stringRedisTemplate.opsForZSet().add(key, value, score); } /** * * @param key * @param values * @return */ public Long zAdd(String key, Set&lt;TypedTuple&lt;String&gt;&gt; values) { return stringRedisTemplate.opsForZSet().add(key, values); } /** * * @param key * @param values * @return */ public Long zRemove(String key, Object... values) { return stringRedisTemplate.opsForZSet().remove(key, values); } public Long zRemove(String key, Collection&lt;String&gt; values) { if(values!=null&amp;&amp;!values.isEmpty()){ Object[] objs = values.toArray(new Object[values.size()]); return stringRedisTemplate.opsForZSet().remove(key, objs); } return 0L; } /** * 增加元素的score值，并返回增加后的值 * * @param key * @param value * @param delta * @return */ public Double zIncrementScore(String key, String value, double delta) { return stringRedisTemplate.opsForZSet().incrementScore(key, value, delta); } /** * 返回元素在集合的排名,有序集合是按照元素的score值由小到大排列 * * @param key * @param value * @return 0表示第一位 */ public Long zRank(String key, Object value) { return stringRedisTemplate.opsForZSet().rank(key, value); } /** * 返回元素在集合的排名,按元素的score值由大到小排列 * * @param key * @param value * @return */ public Long zReverseRank(String key, Object value) { return stringRedisTemplate.opsForZSet().reverseRank(key, value); } /** * 获取集合的元素, 从小到大排序 * * @param key * @param start * 开始位置 * @param end * 结束位置, -1查询所有 * @return */ public Set&lt;String&gt; zRange(String key, long start, long end) { return stringRedisTemplate.opsForZSet().range(key, start, end); } /** * 获取zset集合的所有元素, 从小到大排序 * */ public Set&lt;String&gt; zRangeAll(String key) { return zRange(key,0,-1); } /** * 获取集合元素, 并且把score值也获取 * * @param key * @param start * @param end * @return */ public Set&lt;TypedTuple&lt;String&gt;&gt; zRangeWithScores(String key, long start, long end) { return stringRedisTemplate.opsForZSet().rangeWithScores(key, start, end); } /** * 根据Score值查询集合元素 * * @param key * @param min * 最小值 * @param max * 最大值 * @return */ public Set&lt;String&gt; zRangeByScore(String key, double min, double max) { return stringRedisTemplate.opsForZSet().rangeByScore(key, min, max); } /** * 根据Score值查询集合元素, 从小到大排序 * * @param key * @param min * 最小值 * @param max * 最大值 * @return */ public Set&lt;TypedTuple&lt;String&gt;&gt; zRangeByScoreWithScores(String key, double min, double max) { return stringRedisTemplate.opsForZSet().rangeByScoreWithScores(key, min, max); } /** * * @param key * @param min * @param max * @param start * @param end * @return */ public Set&lt;TypedTuple&lt;String&gt;&gt; zRangeByScoreWithScores(String key, double min, double max, long start, long end) { return stringRedisTemplate.opsForZSet().rangeByScoreWithScores(key, min, max, start, end); } /** * 获取集合的元素, 从大到小排序 * * @param key * @param start * @param end * @return */ public Set&lt;String&gt; zReverseRange(String key, long start, long end) { return stringRedisTemplate.opsForZSet().reverseRange(key, start, end); } public Set&lt;String&gt; zReverseRangeByScore(String key, long min, long max) { return stringRedisTemplate.opsForZSet().reverseRangeByScore(key, min, max); } /** * 获取集合的元素, 从大到小排序, 并返回score值 * * @param key * @param start * @param end * @return */ public Set&lt;TypedTuple&lt;String&gt;&gt; zReverseRangeWithScores(String key, long start, long end) { return stringRedisTemplate.opsForZSet().reverseRangeWithScores(key, start, end); } /** * 根据Score值查询集合元素, 从大到小排序 * * @param key * @param min * @param max * @return */ public Set&lt;String&gt; zReverseRangeByScore(String key, double min, double max) { return stringRedisTemplate.opsForZSet().reverseRangeByScore(key, min, max); } /** * 根据Score值查询集合元素, 从大到小排序 * * @param key * @param min * @param max * @return */ public Set&lt;TypedTuple&lt;String&gt;&gt; zReverseRangeByScoreWithScores( String key, double min, double max) { return stringRedisTemplate.opsForZSet().reverseRangeByScoreWithScores(key, min, max); } /** * * @param key * @param min * @param max * @param start * @param end * @return */ public Set&lt;String&gt; zReverseRangeByScore(String key, double min, double max, long start, long end) { return stringRedisTemplate.opsForZSet().reverseRangeByScore(key, min, max, start, end); } /** * 根据score值获取集合元素数量 * * @param key * @param min * @param max * @return */ public Long zCount(String key, double min, double max) { return stringRedisTemplate.opsForZSet().count(key, min, max); } /** * 获取集合大小 * * @param key * @return */ public Long zSize(String key) { return stringRedisTemplate.opsForZSet().size(key); } /** * 获取集合大小 * * @param key * @return */ public Long zZCard(String key) { return stringRedisTemplate.opsForZSet().zCard(key); } /** * 获取集合中value元素的score值 * * @param key * @param value * @return */ public Double zScore(String key, Object value) { return stringRedisTemplate.opsForZSet().score(key, value); } /** * 移除指定索引位置的成员 * * @param key * @param start * @param end * @return */ public Long zRemoveRange(String key, long start, long end) { return stringRedisTemplate.opsForZSet().removeRange(key, start, end); } /** * 根据指定的score值的范围来移除成员 * * @param key * @param min * @param max * @return */ public Long zRemoveRangeByScore(String key, double min, double max) { return stringRedisTemplate.opsForZSet().removeRangeByScore(key, min, max); } /** * 获取key和otherKey的并集并存储在destKey中 * * @param key * @param otherKey * @param destKey * @return */ public Long zUnionAndStore(String key, String otherKey, String destKey) { return stringRedisTemplate.opsForZSet().unionAndStore(key, otherKey, destKey); } /** * * @param key * @param otherKeys * @param destKey * @return */ public Long zUnionAndStore(String key, Collection&lt;String&gt; otherKeys, String destKey) { return stringRedisTemplate.opsForZSet() .unionAndStore(key, otherKeys, destKey); } /** * 交集 * * @param key * @param otherKey * @param destKey * @return */ public Long zIntersectAndStore(String key, String otherKey, String destKey) { return stringRedisTemplate.opsForZSet().intersectAndStore(key, otherKey, destKey); } /** * 交集 * * @param key * @param otherKeys * @param destKey * @return */ public Long zIntersectAndStore(String key, Collection&lt;String&gt; otherKeys, String destKey) { return stringRedisTemplate.opsForZSet().intersectAndStore(key, otherKeys, destKey); } /** * * @param key * @param options * @return */ public Cursor&lt;TypedTuple&lt;String&gt;&gt; zScan(String key, ScanOptions options) { return stringRedisTemplate.opsForZSet().scan(key, options); } /** * 扫描主键，建议使用 * @param patten * @return */ public Set&lt;String&gt; scan(String patten){ Set&lt;String&gt; keys = stringRedisTemplate.execute((RedisCallback&lt;Set&lt;String&gt;&gt;) connection -&gt; { Set&lt;String&gt; result = new HashSet&lt;&gt;(); try (Cursor&lt;byte[]&gt; cursor = connection.scan(new ScanOptions.ScanOptionsBuilder() .match(patten).count(10000).build())) { while (cursor.hasNext()) { result.add(new String(cursor.next())); } } catch (IOException e) { e.printStackTrace(); } return result; }); return keys; } /** * 管道技术，提高性能 * @param type * @param values * @return */ public List&lt;Object&gt; lRightPushPipeline(String type,Collection&lt;String&gt; values){ List&lt;Object&gt; results = stringRedisTemplate.executePipelined(new RedisCallback&lt;Object&gt;() { public Object doInRedis(RedisConnection connection) throws DataAccessException { StringRedisConnection stringRedisConn = (StringRedisConnection)connection; //集合转换数组 String[] strings = values.toArray(new String[values.size()]); //直接批量发送 stringRedisConn.rPush(type, strings); return null; } }); return results; } public List&lt;Object&gt; refreshWithPipeline(String future_key,String topic_key,Collection&lt;String&gt; values){ List&lt;Object&gt; objects = stringRedisTemplate.executePipelined(new RedisCallback&lt;Object&gt;() { @Nullable @Override public Object doInRedis(RedisConnection redisConnection) throws DataAccessException { StringRedisConnection stringRedisConnection = (StringRedisConnection)redisConnection; String[] strings = values.toArray(new String[values.size()]); stringRedisConnection.rPush(topic_key,strings); stringRedisConnection.zRem(future_key,strings); return null; } }); return objects; } /** * 加锁 * * @param name * @param expire * @return */ public String tryLock(String name, long expire) { name = name + \"_lock\"; String token = UUID.randomUUID().toString(); RedisConnectionFactory factory = stringRedisTemplate.getConnectionFactory(); RedisConnection conn = factory.getConnection(); try { //参考redis命令： //set key value [EX seconds] [PX milliseconds] [NX|XX] Boolean result = conn.set( name.getBytes(), token.getBytes(), Expiration.from(expire, TimeUnit.MILLISECONDS), RedisStringCommands.SetOption.SET_IF_ABSENT //NX ); if (result != null &amp;&amp; result) return token; } finally { RedisConnectionUtils.releaseConnection(conn, factory,false); } return null; } } 二.接口封装1.接口package com.heima.schedule.service; import com.heima.model.schedule.dtos.Task; /** * 对外访问接口 */ public interface TaskService { /** * 添加任务 * @param task 任务对象 * @return 任务id */ public long addTask(Task task) ; /** * 取消任务 * @param taskId 任务id * @return 取消结果 */ public boolean cancelTask(long taskId); /** * 按照类型和优先级来拉取任务 * @param type * @param priority * @return */ public Task poll(int type,int priority); } 2.实现类package com.heima.schedule.service.impl; import com.alibaba.fastjson.JSON; import com.baomidou.mybatisplus.core.toolkit.Wrappers; import com.heima.common.constants.ScheduleConstants; import com.heima.common.redis.CacheService; import com.heima.model.schedule.dtos.Task; import com.heima.model.schedule.pojos.Taskinfo; import com.heima.model.schedule.pojos.TaskinfoLogs; import com.heima.schedule.mapper.TaskinfoLogsMapper; import com.heima.schedule.mapper.TaskinfoMapper; import com.heima.schedule.service.TaskService; import lombok.extern.slf4j.Slf4j; import org.apache.commons.lang3.StringUtils; import org.springframework.beans.BeanUtils; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.scheduling.annotation.Scheduled; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; import javax.annotation.PostConstruct; import java.util.Calendar; import java.util.Date; import java.util.List; import java.util.Set; @Service @Transactional @Slf4j public class TaskServiceImpl implements TaskService { /** * 添加延迟任务 * * @param task * @return */ @Override public long addTask(Task task) { //1.添加任务到数据库中 boolean success = addTaskToDb(task); if (success) { //2.添加任务到redis addTaskToCache(task); } return task.getTaskId(); } @Autowired private CacheService cacheService; /** * 把任务添加到redis中 * * @param task */ private void addTaskToCache(Task task) { String key = task.getTaskType() + \"_\" + task.getPriority(); //获取5分钟之后的时间 毫秒值 Calendar calendar = Calendar.getInstance(); calendar.add(Calendar.MINUTE, 5); long nextScheduleTime = calendar.getTimeInMillis(); //2.1 如果任务的执行时间小于等于当前时间，存入list if (task.getExecuteTime() &lt;= System.currentTimeMillis()) { cacheService.lLeftPush(ScheduleConstants.TOPIC + key, JSON.toJSONString(task)); } else if (task.getExecuteTime() &lt;= nextScheduleTime) { //2.2 如果任务的执行时间大于当前时间 &amp;&amp; 小于等于预设时间（未来5分钟） 存入zset中 cacheService.zAdd(ScheduleConstants.FUTURE + key, JSON.toJSONString(task), task.getExecuteTime()); } } @Autowired private TaskinfoMapper taskinfoMapper; @Autowired private TaskinfoLogsMapper taskinfoLogsMapper; /** * 添加任务到数据库中 * * @param task * @return */ private boolean addTaskToDb(Task task) { boolean flag = false; try { //保存任务表 Taskinfo taskinfo = new Taskinfo(); BeanUtils.copyProperties(task, taskinfo); taskinfo.setExecuteTime(new Date(task.getExecuteTime())); taskinfoMapper.insert(taskinfo); //设置taskID task.setTaskId(taskinfo.getTaskId()); //保存任务日志数据 TaskinfoLogs taskinfoLogs = new TaskinfoLogs(); BeanUtils.copyProperties(taskinfo, taskinfoLogs); taskinfoLogs.setVersion(1); taskinfoLogs.setStatus(ScheduleConstants.SCHEDULED); taskinfoLogsMapper.insert(taskinfoLogs); flag = true; } catch (Exception e) { e.printStackTrace(); } return flag; } /** * 取消任务 * @param taskId * @return */ @Override public boolean cancelTask(long taskId) { boolean flag = false; //删除任务，更新日志 Task task = updateDb(taskId,ScheduleConstants.EXECUTED); //删除redis的数据 if(task != null){ removeTaskFromCache(task); flag = true; } return false; } /** * 删除redis中的任务数据 * @param task */ private void removeTaskFromCache(Task task) { String key = task.getTaskType()+\"_\"+task.getPriority(); if(task.getExecuteTime()&lt;=System.currentTimeMillis()){ cacheService.lRemove(ScheduleConstants.TOPIC+key,0,JSON.toJSONString(task)); }else { cacheService.zRemove(ScheduleConstants.FUTURE+key, JSON.toJSONString(task)); } } /** * 删除任务，更新任务日志状态 * @param taskId * @param status * @return */ private Task updateDb(long taskId, int status) { Task task = null; try { //删除任务 taskinfoMapper.deleteById(taskId); TaskinfoLogs taskinfoLogs = taskinfoLogsMapper.selectById(taskId); taskinfoLogs.setStatus(status); taskinfoLogsMapper.updateById(taskinfoLogs); task = new Task(); BeanUtils.copyProperties(taskinfoLogs,task); task.setExecuteTime(taskinfoLogs.getExecuteTime().getTime()); }catch (Exception e){ log.error(\"task cancel exception taskid={}\",taskId); } return task; } /** * 按照类型和优先级拉取任务 * @return */ @Override public Task poll(int type,int priority) { Task task = null; try { String key = type+\"_\"+priority; String task_json = cacheService.lRightPop(ScheduleConstants.TOPIC + key); if(StringUtils.isNotBlank(task_json)){ task = JSON.parseObject(task_json, Task.class); //更新数据库信息 updateDb(task.getTaskId(),ScheduleConstants.EXECUTED); } }catch (Exception e){ e.printStackTrace(); log.error(\"poll task exception\"); } return task; } /** * 未来数据定时刷新 */ @Scheduled(cron = \"0 */1 * * * ?\") public void refresh(){ String token = cacheService.tryLock(\"FUTURE_TASK_SYNC\", 1000 * 30); if(StringUtils.isNotBlank(token)){ log.info(\"未来数据定时刷新---定时任务\"); //获取所有未来数据的集合key Set&lt;String&gt; futureKeys = cacheService.scan(ScheduleConstants.FUTURE + \"*\"); for (String futureKey : futureKeys) {//future_100_50 //获取当前数据的key topic String topicKey = ScheduleConstants.TOPIC+futureKey.split(ScheduleConstants.FUTURE)[1]; //按照key和分值查询符合条件的数据 Set&lt;String&gt; tasks = cacheService.zRangeByScore(futureKey, 0, System.currentTimeMillis()); //同步数据 if(!tasks.isEmpty()){ cacheService.refreshWithPipeline(futureKey,topicKey,tasks); log.info(\"成功的将\"+futureKey+\"刷新到了\"+topicKey); } } } } @Scheduled(cron = \"0 */5 * * * ?\") @PostConstruct public void reloadData() { clearCache(); log.info(\"数据库数据同步到缓存\"); Calendar calendar = Calendar.getInstance(); calendar.add(Calendar.MINUTE, 5); //查看小于未来5分钟的所有任务 List&lt;Taskinfo&gt; allTasks = taskinfoMapper.selectList(Wrappers.&lt;Taskinfo&gt;lambdaQuery().lt(Taskinfo::getExecuteTime,calendar.getTime())); if(allTasks != null &amp;&amp; allTasks.size() &gt; 0){ for (Taskinfo taskinfo : allTasks) { Task task = new Task(); BeanUtils.copyProperties(taskinfo,task); task.setExecuteTime(taskinfo.getExecuteTime().getTime()); addTaskToCache(task); } } } private void clearCache(){ // 删除缓存中未来数据集合和当前消费者队列的所有key Set&lt;String&gt; futurekeys = cacheService.scan(ScheduleConstants.FUTURE + \"*\");// future_ Set&lt;String&gt; topickeys = cacheService.scan(ScheduleConstants.TOPIC + \"*\");// topic_ cacheService.delete(futurekeys); cacheService.delete(topickeys); } } 三.redis内部定时刷新@Scheduled(cron = \"0 */1 * * * ?\") public void refresh() { System.out.println(System.currentTimeMillis() / 1000 + \"执行了定时任务\"); // 获取所有未来数据集合的key值 Set&lt;String&gt; futureKeys = cacheService.scan(ScheduleConstants.FUTURE + \"*\");// future_* for (String futureKey : futureKeys) { // future_250_250 String topicKey = ScheduleConstants.TOPIC + futureKey.split(ScheduleConstants.FUTURE)[1]; //获取该组key下当前需要消费的任务数据 Set&lt;String&gt; tasks = cacheService.zRangeByScore(futureKey, 0, System.currentTimeMillis()); if (!tasks.isEmpty()) { //将这些任务数据添加到消费者队列中 cacheService.refreshWithPipeline(futureKey, topicKey, tasks); System.out.println(\"成功的将\" + futureKey + \"下的当前需要执行的任务数据刷新到\" + topicKey + \"下\"); } } } 四.分布式锁Redis/** * 加锁 * * @param name * @param expire * @return */ public String tryLock(String name, long expire) { name = name + \"_lock\"; String token = UUID.randomUUID().toString(); RedisConnectionFactory factory = stringRedisTemplate.getConnectionFactory(); RedisConnection conn = factory.getConnection(); try { //参考redis命令： //set key value [EX seconds] [PX milliseconds] [NX|XX] Boolean result = conn.set( name.getBytes(), token.getBytes(), Expiration.from(expire, TimeUnit.MILLISECONDS), RedisStringCommands.SetOption.SET_IF_ABSENT //NX ); if (result != null &amp;&amp; result) return token; } finally { RedisConnectionUtils.releaseConnection(conn, factory,false); } return null; } 实现 /** * 未来数据定时刷新 */ @Scheduled(cron = \"0 */1 * * * ?\") public void refresh(){ String token = cacheService.tryLock(\"FUTURE_TASK_SYNC\", 1000 * 30); if(StringUtils.isNotBlank(token)){ log.info(\"未来数据定时刷新---定时任务\"); //获取所有未来数据的集合key Set&lt;String&gt; futureKeys = cacheService.scan(ScheduleConstants.FUTURE + \"*\"); for (String futureKey : futureKeys) {//future_100_50 //获取当前数据的key topic String topicKey = ScheduleConstants.TOPIC+futureKey.split(ScheduleConstants.FUTURE)[1]; //按照key和分值查询符合条件的数据 Set&lt;String&gt; tasks = cacheService.zRangeByScore(futureKey, 0, System.currentTimeMillis()); //同步数据 if(!tasks.isEmpty()){ cacheService.refreshWithPipeline(futureKey,topicKey,tasks); log.info(\"成功的将\"+futureKey+\"刷新到了\"+topicKey); } } } } 五.数据库数据同步Redis@Scheduled(cron = \"0 */5 * * * ?\") @PostConstruct public void reloadData() { clearCache(); log.info(\"数据库数据同步到缓存\"); Calendar calendar = Calendar.getInstance(); calendar.add(Calendar.MINUTE, 5); //查看小于未来5分钟的所有任务 List&lt;Taskinfo&gt; allTasks = taskinfoMapper.selectList(Wrappers.&lt;Taskinfo&gt;lambdaQuery().lt(Taskinfo::getExecuteTime,calendar.getTime())); if(allTasks != null &amp;&amp; allTasks.size() &gt; 0){ for (Taskinfo taskinfo : allTasks) { Task task = new Task(); BeanUtils.copyProperties(taskinfo,task); task.setExecuteTime(taskinfo.getExecuteTime().getTime()); addTaskToCache(task); } } } private void clearCache(){ // 删除缓存中未来数据集合和当前消费者队列的所有key Set&lt;String&gt; futurekeys = cacheService.scan(ScheduleConstants.FUTURE + \"*\");// future_ Set&lt;String&gt; topickeys = cacheService.scan(ScheduleConstants.TOPIC + \"*\");// topic_ cacheService.delete(futurekeys); cacheService.delete(topickeys); }","categories":[{"name":"延时任务","slug":"延时任务","permalink":"https://macongmc.github.io/categories/%E5%BB%B6%E6%97%B6%E4%BB%BB%E5%8A%A1/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://macongmc.github.io/tags/redis/"}],"author":"马聪"},{"title":"文档操作API","slug":"文档操作API","date":"2022-07-31T13:29:15.000Z","updated":"2022-07-31T13:29:15.000Z","comments":true,"path":"posts/bbabe393.html","link":"","permalink":"https://macongmc.github.io/posts/bbabe393.html","excerpt":"","text":"1.需求分析使用Java开发语言对word文档的数据存储到数据库中。 2.技术1. poi Apipoi读取分为顺序读取和根据类型读取。 首先 获取文档 XWPFDocument docx = new XWPFDocument(new FileInputStream(\"./deepoove.docx\")); 一.顺序读写核心api List&lt;IBodyElement&gt; list=docx.getBodyElements();//获取全文数据 \"PARAGRAPH\".equals(iBodyElement.getElementType().toString();//读取到之后根据类型向上转型来展示 XWPFParagraph para=(XWPFParagraph)iBodyElement; //文本数据 XWPFTable table=(XWPFTable)iBodyElement;//表格数据 局限性： poi 的getElementType()里只有表格和文本数据，图片会被直接忽略。 BodyElementType 源码 package org.apache.poi.xwpf.usermodel; public enum BodyElementType { CONTENTCONTROL, PARAGRAPH, TABLE; private BodyElementType() { } } 顺序读取案例 public static String toString(String path) throws IOException{ FileInputStream is = new FileInputStream(path); XWPFDocument doc = new XWPFDocument(is); int index=0; String m=\"\"; int n=1; int csize=0; List&lt;IBodyElement&gt; list=doc.getBodyElements(); for(IBodyElement iBodyElement:list){ if(\"PARAGRAPH\".equals(iBodyElement.getElementType().toString())){//读取文档中段落 XWPFParagraph para=(XWPFParagraph)iBodyElement; System.out.println(para.getText()); }else if(\"TABLE\".equals(iBodyElement.getElementType().toString())){ //读取文档中表格 XWPFTable table=(XWPFTable)iBodyElement; List&lt;XWPFTableRow&gt; rows = table.getRows(); for(int y=0;y&lt;rows.size();y++) { XWPFTableRow row=rows.get(y); List&lt;XWPFTableCell&gt; cells = row.getTableCells(); csize=cells.size(); for (int z=0;z&lt;csize;z++) { XWPFTableCell cell=cells.get(z); if(cell.getCTTc().getTcPr().getGridSpan()!=null){ n=Integer.parseInt(cell.getCTTc().getTcPr().getGridSpan().getVal().toString()); } m=\"\"; if(cell.getCTTc().getTcPr().getVMerge()!=null){ if(cell.getCTTc().getTcPr().getVMerge().getVal()!=null){ m=cell.getCTTc().getTcPr().getVMerge().getVal().toString(); }else{ m=null; } } System.out.print(index+\"-\"+csize+\"-\"+y+\"-\"+z+\"-\"+n+\"-\"+m+\":\"+cell.getText()+\" \"); } System.out.println(); } } } is.close(); return \"\"; } public static void main( String[] args ) throws IOException{ toString(\"C:\\\\Users\\\\admin\\\\Desktop\\\\553e34d7-e899-4f5c-a1e7-1889f5c2dfd0.docx\"); } } 二.根据类型读写// 段落 List&lt;XWPFParagraph&gt; paragraphs = doc.getParagraphs(); // 表格 List&lt;XWPFTable&gt; tables = doc.getTables(); // 图片 List&lt;XWPFPictureData&gt; allPictures = doc.getAllPictures(); // 页眉 List&lt;XWPFHeader&gt; headerList = doc.getHeaderList(); // 页脚 List&lt;XWPFFooter&gt; footerList = doc.getFooterList(); 根据段落读取 List&lt;XWPFParagraph&gt; paras = doc.getParagraphs(); for (XWPFParagraph para : paras) { String text = para.getText(); System.out.println(text); } 根据表格读取 List&lt;XWPFParagraph&gt; paras = doc.getParagraphs(); //获取文档中所有的表格 List&lt;XWPFTable&gt; tables = doc.getTables(); List&lt;XWPFTableRow&gt; rows; List&lt;XWPFTableCell&gt; cells; for (XWPFTable table : tables) { rows = table.getRows(); for (XWPFTableRow row : rows) { cells = row.getTableCells(); for (XWPFTableCell cell : cells) { System.out.println(cell); } } } 根据图片读取 public static void doxc() throws InvalidFormatException { String importPath = \"E://123.docx\"; String absolutePath = \"E://qwe//\"; try { FileInputStream inputStream = new FileInputStream(importPath); XWPFDocument xDocument = new XWPFDocument(inputStream); List&lt;XWPFParagraph&gt; paragraphs = xDocument.getParagraphs(); List&lt;XWPFPictureData&gt; pictures = xDocument.getAllPictures(); Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); for(XWPFPictureData picture : pictures){ String id = picture.getParent().getRelationId(picture); File folder = new File(absolutePath); if (!folder.exists()) { folder.mkdirs(); } String rawName = picture.getFileName(); String fileExt = rawName.substring(rawName.lastIndexOf(\".\")); String newName = System.currentTimeMillis() + UUID.randomUUID().toString() + fileExt; File saveFile = new File(absolutePath + File.separator + newName); @SuppressWarnings(\"resource\") FileOutputStream fos = new FileOutputStream(saveFile); fos.write(picture.getData()); System.out.println(id); System.out.println(saveFile.getAbsolutePath()); map.put(id, saveFile.getAbsolutePath()); } String text = \"\"; for(XWPFParagraph paragraph : paragraphs){ //System.out.println(paragraph.getParagraphText()); List&lt;XWPFRun&gt; runs = paragraph.getRuns(); for(XWPFRun run : runs){ /*System.out.println(run.getCTR().xmlText());*/ if(run.getCTR().xmlText().indexOf(\"&lt;w:drawing&gt;\")!=-1){ String runXmlText = run.getCTR().xmlText(); int rIdIndex = runXmlText.indexOf(\"r:embed\"); int rIdEndIndex = runXmlText.indexOf(\"/&gt;\", rIdIndex); String rIdText = runXmlText.substring(rIdIndex, rIdEndIndex); System.out.println(rIdText.split(\"\\\"\")[1].substring(\"rId\".length())); String id = rIdText.split(\"\\\"\")[1]; System.out.println(map.get(id)); text = text +\"&lt;img src = '\"+map.get(id)+\"'/&gt;\"; }else{ text = text + run; } } } System.out.println(text); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } } 2.spire.doc API一.转换方法docx转化html //实例化Document类的对象 Document doc = new Document(); //加载Word文档 doc.loadFromFile(\"inputfile.docx\"); //保存为HTML格式 doc.saveToFile(\"ToHtml.html\",FileFormat.Html); doc.dispose(); docx转PDF Document doc = new Document(); //加载Word doc.loadFromFile(\"测试.docx\"); //保存为PDF格式 doc.saveToFile(\"WordToPDF.pdf\",FileFormat.PDF); 主要根据FileFormat枚举类来进行类型选择； 二.案例import com.spire.doc.*; public class WordtoHtml { public static void main(String[] args) { //实例化Document类的对象 Document doc = new Document(); //加载Word文档 doc.loadFromFile(\"inputfile.docx\"); //保存为HTML格式 doc.saveToFile(\"ToHtml.html\",FileFormat.Html); doc.dispose(); } } 3.jsoup API一.读取html方法jsoup解析Jsoup提供一系列的静态解析方法生成Document对象static Document parse(File in, String charsetName)static Document parse(File in, String charsetName, String baseUri)static Document parse(InputStream in, String charsetName, String baseUri)static Document parse(String html)static Document parse(String html, String baseUri)static Document parse(URL url, int timeoutMillis)static Document parseBodyFragment(String bodyHtml)static Document parseBodyFragment(String bodyHtml, String baseUri)其中baseUri表示检索到的相对URL是相对于baseUriURL的其中charsetName表示字符集 案例 Document docx = Jsoup.parse(new File(html),\"GBK\"); 解析分为顺序解析和根据标签等解析。 1.全文顺序解析 Elements allElements = docx.getAllElements(); 2.根据特殊标签解析 docx.getElementsByTag(); // 指定标签 docx.getElementsByClass();//指定类 docx.getElementById();//指定ID 二.案例Elements allElements = docx.getAllElements(); int flag = 1; boolean flagOne = false; List&lt;Image&gt; stringList = new ArrayList&lt;&gt;();; String tu = \"图\"; int count = 1; for (Element allElement : allElements) { if (allElement.tagName().equals(\"span\") &amp;&amp; allElement.getElementsByTag(\"span\").text().contains(\"、附图\")){ String style = allElement.attr(\"style\"); if (style.equals(\"font-size:22.0pt;font-family:Calibri;mso-fareast-font-family:宋体;mso-bidi-font-family:'Times New Roman';lang:EN-US;mso-fareast-language:ZH-CN;mso-ansi-language:AR-SA;font-weight:bold;\")){ flagOne = true; } flag++; } if (allElement.tagName().equals(\"img\") &amp;&amp; flagOne == true){ Image image = new Image(tu+count,docPath+\"/\"+allElement.attr(\"src\"),file.getOriginalFilename()); count++; stringList.add(image); } if(allElement.tagName().equals(\"img\") &amp;&amp; flag==3){ Image image = new Image(tu+count,docPath+\"/\"+allElement.attr(\"src\"),file.getOriginalFilename()); count++; stringList.add(image); } } 3.综合案例如樟岭隧道进口雷达检测报告-何登凯-审核人.docx,中部引黄工程施工10标雷达检测报告 (3)(1).docx 遇见问题： poi 顺序读取忽略图片，类型读取无法筛选附图的图片所在。 故使用poi进行所有表格读取。 核心代码 public void downDB(MultipartFile file,List&lt;Image&gt; all) throws IOException { String word = file.getOriginalFilename().substring(file.getOriginalFilename().lastIndexOf(\".\")); InputStream is = file.getInputStream(); XWPFDocument doc = new XWPFDocument(is); //获取文档中所有的表格 List&lt;XWPFTable&gt; tables = doc.getTables(); int count = 1; for (XWPFTable table : tables) { //表格属性 storageUtils.storageDB(table,all); } this.close(is); } @Async public void storageDB(XWPFTable table,List&lt;Image&gt; list) { List&lt;XWPFTableRow&gt; rows = table.getRows(); if (rows.get(0).getTableCells().size()&gt;=7) { String text = rows.get(0).getTableCells().get(4).getText(); switch (text) { case \"设计厚度（cm）\": dbConcreteReinforcement(table,list); break; case \"缺陷类型\": dbNotDenseSummary(table,list); break; case \"环向钢筋实测数量（根）\": dbRebarProblems(table,list); break; default: break; } }else if(rows.get(0).getTableCells().size() == 1) { String text = rows.get(1).getTableCells().get(2).getText(); switch (text){ case \"缺陷类型\": dbInternalDefects(table,list); break; case \"围岩类别\" : dbInsufficientThickness(table,list); break; default: break; } } } private void dbInsufficientThickness(XWPFTable table,List&lt;Image&gt; list) { List&lt;Image&gt; all = getList(list); List&lt;XWPFTableRow&gt; rows; List&lt;XWPFTableCell&gt; cells; List&lt;InsufficientThickness&gt; insufficientThicknesses = new ArrayList&lt;&gt;(); rows = table.getRows(); for (int i = 2; i &lt; rows.size(); i++) { cells= rows.get(i).getTableCells(); if (cells.get(0).getText().equals(\"缺陷位置及桩号\")){ continue; } String text = cells.get(5).getText(); for (Image image : all) { if (text.contains(image.getName())){ text = image.getUrl(); break; } } InsufficientThickness insufficientThickness = new InsufficientThickness( cells.get(0).getText(), new BigDecimal(cells.get(1).getText()), cells.get(2).getText(), cells.get(3).getText(), cells.get(4).getText(), text ); insufficientThicknesses.add(insufficientThickness); } insufficientThicknessService.saveList(insufficientThicknesses); } 根基表格设置实体类映射数据库，在附图字段要存储图片的实际路径。 故需要把图片读取出来，并且知道图片路径。 设计实体用来放图片 名称 位置 文件名称。 读取图片把word转换为html使用spire.doc 核心代码 com.spire.doc.Document doc = new com.spire.doc.Document(); //加载Word文档 doc.loadFromFile(path); //保存为HTML格式 String html = \"D:\\\\html\\\\\"+substring+ \".html\"; doc.saveToFile(html, FileFormat.Html); doc.dispose(); 转换为html后根据标签筛选进行图片过滤。 核心代码 public void saveHtml(MultipartFile file) throws IOException { InputStream in = file.getInputStream(); // 构建目标文件 String substring = file.getOriginalFilename().substring(0,file.getOriginalFilename().lastIndexOf(\".\")); String path = \"D:\\\\html\\\\\"+substring+ \".docx\"; String docPath =\"D:\\\\html\"; File fileCopy = new File(path); OutputStream out = null; try { if (!fileCopy.getParentFile().exists()) { fileCopy.getParentFile().mkdirs(); } try { file.transferTo(fileCopy); } catch (IOException e) { //抛出异常 } // 源文件创建输入流 // 目标文件创建输出流 out = new FileOutputStream(fileCopy, true); // 创建字节数组 byte[] temp = new byte[1024]; int length = 0; // 源文件读取一部分内容 while ((length = in.read(temp)) != -1) { // 目标文件写入一部分内容 out.write(temp, 0, length); } com.spire.doc.Document doc = new com.spire.doc.Document(); //加载Word文档 doc.loadFromFile(path); //保存为HTML格式 String html = \"D:\\\\html\\\\\"+substring+ \".html\"; doc.saveToFile(html, FileFormat.Html); doc.dispose(); ValueOperations valueOperations = redisTemplate.opsForValue(); valueOperations.set(\"keyDoc\",file.getOriginalFilename()); //读取.html文件为字符串 //解析字符串为Document对象 Document docx = Jsoup.parse(new File(html),\"GBK\"); //获取body元素，获取class=\"fc\"的table元素 Elements allElements = docx.getAllElements(); int flag = 1; boolean flagOne = false; List&lt;Image&gt; stringList = new ArrayList&lt;&gt;();; String tu = \"图\"; int count = 1; for (Element allElement : allElements) { if (allElement.tagName().equals(\"span\") &amp;&amp; allElement.getElementsByTag(\"span\").text().contains(\"、附图\")){ String style = allElement.attr(\"style\"); if (style.equals(\"font-size:22.0pt;font-family:Calibri;mso-fareast-font-family:宋体;mso-bidi-font-family:'Times New Roman';lang:EN-US;mso-fareast-language:ZH-CN;mso-ansi-language:AR-SA;font-weight:bold;\")){ flagOne = true; } flag++; } if (allElement.tagName().equals(\"img\") &amp;&amp; flagOne == true){ Image image = new Image(tu+count,docPath+\"/\"+allElement.attr(\"src\"),file.getOriginalFilename()); count++; stringList.add(image); } if(allElement.tagName().equals(\"img\") &amp;&amp; flag==3){ Image image = new Image(tu+count,docPath+\"/\"+allElement.attr(\"src\"),file.getOriginalFilename()); count++; stringList.add(image); } } imageDao.saveList(stringList); } catch (Exception e) { e.printStackTrace(); } finally { try { // 关闭文件输入输出流 in.close(); out.close(); } catch (Exception e) { e.printStackTrace(); } } }","categories":[{"name":"API","slug":"API","permalink":"https://macongmc.github.io/categories/API/"}],"tags":[{"name":"word","slug":"word","permalink":"https://macongmc.github.io/tags/word/"},{"name":"html","slug":"html","permalink":"https://macongmc.github.io/tags/html/"}],"author":"马聪"},{"title":"SDK内容安全","slug":"SDK内容安全","date":"2022-07-31T12:42:46.000Z","updated":"2022-07-31T12:42:46.000Z","comments":true,"path":"posts/57bcaeae.html","link":"","permalink":"https://macongmc.github.io/posts/57bcaeae.html","excerpt":"","text":"一.技术说明1.阿里云内容安全 内容安全控制台 2.在在AccessKey管理页面管理您的AccessKeyID和AccessKeySecret 二.文本内容审核接口文本垃圾内容检测：https://help.aliyun.com/document_detail/70439.html?spm=a2c4g.11186623.6.659.35ac3db3l0wV5k 文本垃圾内容Java SDK: https://help.aliyun.com/document_detail/53427.html?spm=a2c4g.11186623.6.717.466d7544QbU8Lr 三.图片审核接口图片垃圾内容检测：https://help.aliyun.com/document_detail/70292.html?spm=a2c4g.11186623.6.616.5d7d1e7f9vDRz4 图片垃圾内容Java SDK: https://help.aliyun.com/document_detail/53424.html?spm=a2c4g.11186623.6.715.c8f69b12ey35j4 四.集成使用1.依赖 &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;4.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-green&lt;/artifactId&gt; &lt;version&gt;3.6.5&lt;/version&gt; &lt;/dependency&gt; 2.配置accessKeyId和secret aliyun: accessKeyId: secret: #aliyun.scenes=porn,terrorism,ad,qrcode,live,logo scenes: terrorism 3.封装方法 封装方法：http://82.157.254.101:9000 spring.factories中加入两个类 五.自管理敏感词DFA全称为：Deterministic Finite Automaton,即确定有穷自动机。 存储：一次性的把所有的敏感词存储到了多个map中，就是下图表示这种结构 封装方法 package com.heima.utils.common; import java.util.*; public class SensitiveWordUtil { public static Map&lt;String, Object&gt; dictionaryMap = new HashMap&lt;&gt;(); /** * 生成关键词字典库 * @param words * @return */ public static void initMap(Collection&lt;String&gt; words) { if (words == null) { System.out.println(\"敏感词列表不能为空\"); return ; } // map初始长度words.size()，整个字典库的入口字数(小于words.size()，因为不同的词可能会有相同的首字) Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(words.size()); // 遍历过程中当前层次的数据 Map&lt;String, Object&gt; curMap = null; Iterator&lt;String&gt; iterator = words.iterator(); while (iterator.hasNext()) { String word = iterator.next(); curMap = map; int len = word.length(); for (int i =0; i &lt; len; i++) { // 遍历每个词的字 String key = String.valueOf(word.charAt(i)); // 当前字在当前层是否存在, 不存在则新建, 当前层数据指向下一个节点, 继续判断是否存在数据 Map&lt;String, Object&gt; wordMap = (Map&lt;String, Object&gt;) curMap.get(key); if (wordMap == null) { // 每个节点存在两个数据: 下一个节点和isEnd(是否结束标志) wordMap = new HashMap&lt;&gt;(2); wordMap.put(\"isEnd\", \"0\"); curMap.put(key, wordMap); } curMap = wordMap; // 如果当前字是词的最后一个字，则将isEnd标志置1 if (i == len -1) { curMap.put(\"isEnd\", \"1\"); } } } dictionaryMap = map; } /** * 搜索文本中某个文字是否匹配关键词 * @param text * @param beginIndex * @return */ private static int checkWord(String text, int beginIndex) { if (dictionaryMap == null) { throw new RuntimeException(\"字典不能为空\"); } boolean isEnd = false; int wordLength = 0; Map&lt;String, Object&gt; curMap = dictionaryMap; int len = text.length(); // 从文本的第beginIndex开始匹配 for (int i = beginIndex; i &lt; len; i++) { String key = String.valueOf(text.charAt(i)); // 获取当前key的下一个节点 curMap = (Map&lt;String, Object&gt;) curMap.get(key); if (curMap == null) { break; } else { wordLength ++; if (\"1\".equals(curMap.get(\"isEnd\"))) { isEnd = true; } } } if (!isEnd) { wordLength = 0; } return wordLength; } /** * 获取匹配的关键词和命中次数 * @param text * @return */ public static Map&lt;String, Integer&gt; matchWords(String text) { Map&lt;String, Integer&gt; wordMap = new HashMap&lt;&gt;(); int len = text.length(); for (int i = 0; i &lt; len; i++) { int wordLength = checkWord(text, i); if (wordLength &gt; 0) { String word = text.substring(i, i + wordLength); // 添加关键词匹配次数 if (wordMap.containsKey(word)) { wordMap.put(word, wordMap.get(word) + 1); } else { wordMap.put(word, 1); } i += wordLength - 1; } } return wordMap; } public static void main(String[] args) { List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(\"法轮\"); list.add(\"法轮功\"); list.add(\"冰毒\"); initMap(list); String content=\"我是一个好人，并不会卖冰毒，也不操练法轮功,我真的不卖冰毒\"; Map&lt;String, Integer&gt; map = matchWords(content); System.out.println(map); } } 六.图片识别文字Tess4j依赖 &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.tess4j&lt;/groupId&gt; &lt;artifactId&gt;tess4j&lt;/artifactId&gt; &lt;version&gt;4.1.1&lt;/version&gt; &lt;/dependency&gt; 工具类 package com.heima.common.tess4j; import lombok.Getter; import lombok.Setter; import net.sourceforge.tess4j.ITesseract; import net.sourceforge.tess4j.Tesseract; import net.sourceforge.tess4j.TesseractException; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; import java.awt.image.BufferedImage; @Getter @Setter @Component @ConfigurationProperties(prefix = \"tess4j\") public class Tess4jClient { private String dataPath; //路径 private String language; //名称 public String doOCR(BufferedImage image) throws TesseractException { //创建Tesseract对象 ITesseract tesseract = new Tesseract(); //设置字体库路径 tesseract.setDatapath(dataPath); //中文识别 tesseract.setLanguage(language); //执行ocr识别 String result = tesseract.doOCR(image); //替换回车和tal键 使结果为一行 result = result.replaceAll(\"\\\\r|\\\\n\", \"-\").replaceAll(\" \", \"\"); return result; } }","categories":[{"name":"SDK","slug":"SDK","permalink":"https://macongmc.github.io/categories/SDK/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"https://macongmc.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"内容安全","slug":"内容安全","permalink":"https://macongmc.github.io/tags/%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8/"},{"name":"机审核","slug":"机审核","permalink":"https://macongmc.github.io/tags/%E6%9C%BA%E5%AE%A1%E6%A0%B8/"}],"author":"马聪"},{"title":"minio","slug":"minio","date":"2022-07-27T11:47:36.000Z","updated":"2022-07-27T11:47:36.000Z","comments":true,"path":"posts/cad5b665.html","link":"","permalink":"https://macongmc.github.io/posts/cad5b665.html","excerpt":"","text":"一.Minio部署使用docker安装拉取镜像 docker pull minio/minio 创建目录 mkdir -p /data/minio/config mkdir -p /data/minio/data 运行容器 docker run -p 9000:9000 -p 9090:9090 \\ --net=host \\ --name minio \\ -d --restart=always \\ -e \"MINIO_ACCESS_KEY=minio\" \\ -e \"MINIO_SECRET_KEY=minio123\" \\ -v /mydata/minio/data:/mydata/minio/data \\ -v /mydata/minio/config:/mydata/minio/config \\ minio/minio server \\ /data --console-address \":9090\" -address \":9000\" 控制台地址 二.封装MinIO为starter1.导入依赖&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.minio&lt;/groupId&gt; &lt;artifactId&gt;minio&lt;/artifactId&gt; &lt;version&gt;7.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2.配置类MinIOConfigProperties import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import java.io.Serializable; @Data @ConfigurationProperties(prefix = \"minio\") // 文件上传 配置前缀file.oss public class MinIOConfigProperties implements Serializable { private String accessKey; private String secretKey; private String bucket; private String endpoint; private String readPath; } MinIOConfig import com.heima.file.service.FileStorageService; import io.minio.MinioClient; import lombok.Data; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.autoconfigure.condition.ConditionalOnClass; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Data @Configuration @EnableConfigurationProperties({MinIOConfigProperties.class}) //当引入FileStorageService接口时 @ConditionalOnClass(FileStorageService.class) public class MinIOConfig { @Autowired private MinIOConfigProperties minIOConfigProperties; @Bean public MinioClient buildMinioClient(){ return MinioClient .builder() .credentials(minIOConfigProperties.getAccessKey(), minIOConfigProperties.getSecretKey()) .endpoint(minIOConfigProperties.getEndpoint()) .build(); } } 3.封装操作minIO类FileStorageService import java.io.InputStream; /** * @author itheima */ public interface FileStorageService { /** * 上传图片文件 * @param prefix 文件前缀 * @param filename 文件名 * @param inputStream 文件流 * @return 文件全路径 */ public String uploadImgFile(String prefix, String filename,InputStream inputStream); /** * 上传html文件 * @param prefix 文件前缀 * @param filename 文件名 * @param inputStream 文件流 * @return 文件全路径 */ public String uploadHtmlFile(String prefix, String filename,InputStream inputStream); /** * 删除文件 * @param pathUrl 文件全路径 */ public void delete(String pathUrl); /** * 下载文件 * @param pathUrl 文件全路径 * @return * */ public byte[] downLoadFile(String pathUrl); } MinIOFileStorageService import com.heima.file.config.MinIOConfig; import com.heima.file.config.MinIOConfigProperties; import com.heima.file.service.FileStorageService; import io.minio.GetObjectArgs; import io.minio.MinioClient; import io.minio.PutObjectArgs; import io.minio.RemoveObjectArgs; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.context.annotation.Import; import org.springframework.util.StringUtils; import java.io.ByteArrayOutputStream; import java.io.IOException; import java.io.InputStream; import java.text.SimpleDateFormat; import java.util.Date; @Slf4j @EnableConfigurationProperties(MinIOConfigProperties.class) @Import(MinIOConfig.class) public class MinIOFileStorageService implements FileStorageService { @Autowired private MinioClient minioClient; @Autowired private MinIOConfigProperties minIOConfigProperties; private final static String separator = \"/\"; /** * @param dirPath * @param filename yyyy/mm/dd/file.jpg * @return */ public String builderFilePath(String dirPath,String filename) { StringBuilder stringBuilder = new StringBuilder(50); if(!StringUtils.isEmpty(dirPath)){ stringBuilder.append(dirPath).append(separator); } SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy/MM/dd\"); String todayStr = sdf.format(new Date()); stringBuilder.append(todayStr).append(separator); stringBuilder.append(filename); return stringBuilder.toString(); } /** * 上传图片文件 * @param prefix 文件前缀 * @param filename 文件名 * @param inputStream 文件流 * @return 文件全路径 */ @Override public String uploadImgFile(String prefix, String filename,InputStream inputStream) { String filePath = builderFilePath(prefix, filename); try { PutObjectArgs putObjectArgs = PutObjectArgs.builder() .object(filePath) .contentType(\"image/jpg\") .bucket(minIOConfigProperties.getBucket()).stream(inputStream,inputStream.available(),-1) .build(); minioClient.putObject(putObjectArgs); StringBuilder urlPath = new StringBuilder(minIOConfigProperties.getReadPath()); urlPath.append(separator+minIOConfigProperties.getBucket()); urlPath.append(separator); urlPath.append(filePath); return urlPath.toString(); }catch (Exception ex){ log.error(\"minio put file error.\",ex); throw new RuntimeException(\"上传文件失败\"); } } /** * 上传html文件 * @param prefix 文件前缀 * @param filename 文件名 * @param inputStream 文件流 * @return 文件全路径 */ @Override public String uploadHtmlFile(String prefix, String filename,InputStream inputStream) { String filePath = builderFilePath(prefix, filename); try { PutObjectArgs putObjectArgs = PutObjectArgs.builder() .object(filePath) .contentType(\"text/html\") .bucket(minIOConfigProperties.getBucket()).stream(inputStream,inputStream.available(),-1) .build(); minioClient.putObject(putObjectArgs); StringBuilder urlPath = new StringBuilder(minIOConfigProperties.getReadPath()); urlPath.append(separator+minIOConfigProperties.getBucket()); urlPath.append(separator); urlPath.append(filePath); return urlPath.toString(); }catch (Exception ex){ log.error(\"minio put file error.\",ex); ex.printStackTrace(); throw new RuntimeException(\"上传文件失败\"); } } /** * 删除文件 * @param pathUrl 文件全路径 */ @Override public void delete(String pathUrl) { String key = pathUrl.replace(minIOConfigProperties.getEndpoint()+\"/\",\"\"); int index = key.indexOf(separator); String bucket = key.substring(0,index); String filePath = key.substring(index+1); // 删除Objects RemoveObjectArgs removeObjectArgs = RemoveObjectArgs.builder().bucket(bucket).object(filePath).build(); try { minioClient.removeObject(removeObjectArgs); } catch (Exception e) { log.error(\"minio remove file error. pathUrl:{}\",pathUrl); e.printStackTrace(); } } /** * 下载文件 * @param pathUrl 文件全路径 * @return 文件流 * */ @Override public byte[] downLoadFile(String pathUrl) { String key = pathUrl.replace(minIOConfigProperties.getEndpoint()+\"/\",\"\"); int index = key.indexOf(separator); String bucket = key.substring(0,index); String filePath = key.substring(index+1); InputStream inputStream = null; try { inputStream = minioClient.getObject(GetObjectArgs.builder().bucket(minIOConfigProperties.getBucket()).object(filePath).build()); } catch (Exception e) { log.error(\"minio down file error. pathUrl:{}\",pathUrl); e.printStackTrace(); } ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); byte[] buff = new byte[100]; int rc = 0; while (true) { try { if (!((rc = inputStream.read(buff, 0, 100)) &gt; 0)) break; } catch (IOException e) { e.printStackTrace(); } byteArrayOutputStream.write(buff, 0, rc); } return byteArrayOutputStream.toByteArray(); } } 4.对外加入自动配置在resources中新建META-INF/spring.factories org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.heima.file.service.impl.MinIOFileStorageService 三.其他微服务使用第一，导入file-starter的依赖 第二，在微服务中添加minio所需要的配置 minio: accessKey: minio secretKey: minio123 bucket: leadnews endpoint: http://192.168.200.130:9000 readPath: http://192.168.200.130:9000 注入 @Autowired private FileStorageService fileStorageService; 修改minio权限","categories":[{"name":"API","slug":"API","permalink":"https://macongmc.github.io/categories/API/"}],"tags":[{"name":"存储","slug":"存储","permalink":"https://macongmc.github.io/tags/%E5%AD%98%E5%82%A8/"}],"author":"马聪"},{"title":"静态模板freemarker","slug":"静态模板freemarker","date":"2022-07-27T00:59:28.000Z","updated":"2022-07-27T02:15:56.000Z","comments":true,"path":"posts/fad62ca1.html","link":"","permalink":"https://macongmc.github.io/posts/fad62ca1.html","excerpt":"","text":"1.freemarker1.1freemarker 介绍​ FreeMarker 是一款 模板引擎： 即一种基于模板和要改变的数据， 并用来生成输出文本(HTML网页，电子邮件，配置文件，源代码等)的通用工具。 它不是面向最终用户的，而是一个Java类库，是一款程序员可以嵌入他们所开发产品的组件。 ​ 模板编写为FreeMarker Template Language (FTL)。它是简单的，专用的语言， 不是 像PHP那样成熟的编程语言。 那就意味着要准备数据在真实编程语言中来显示，比如数据库查询和业务运算， 之后模板显示已经准备好的数据。在模板中，你可以专注于如何展现数据， 而在模板之外可以专注于要展示什么数据。 常用的java模板引擎还有哪些？ Jsp、Freemarker、Thymeleaf 、Velocity 等。 1.Jsp 为 Servlet 专用，不能单独进行使用。 2.Thymeleaf 为新技术，功能较为强大，但是执行的效率比较低。 3.Velocity从2010年更新完 2.0 版本后，便没有在更新。Spring Boot 官方在 1.4 版本后对此也不在支持，虽然 Velocity 在 2017 年版本得到迭代，但为时已晚。 1.2 环境搭建&amp;&amp;快速入门freemarker作为springmvc一种视图格式，默认情况下SpringMVC支持freemarker视图格式。 需要创建Spring Boot+Freemarker工程用于测试模板。 1.3 创建测试工程创建一个freemarker-demo 的测试工程专门用于freemarker的功能测试与模板的测试。 pom.xml如下 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;heima-leadnews-test&lt;/artifactId&gt; &lt;groupId&gt;com.heima&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;freemarker-demo&lt;/artifactId&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- apache 对 java io 的封装工具库 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 1.4配置文件配置application.yml server: port: 8881 #服务端口 spring: application: name: freemarker-demo #指定服务名 freemarker: cache: false #关闭模板缓存，方便测试 settings: template_update_delay: 0 #检查模板更新延迟时间，设置为0表示立即检查，如果时间大于0会有缓存不方便进行模板测试 suffix: .ftl #指定Freemarker模板文件的后缀名 1.5 创建模型类在freemarker的测试工程下创建模型类型用于测试 package com.heima.freemarker.entity; import lombok.Data; import java.util.Date; @Data public class Student { private String name;//姓名 private int age;//年龄 private Date birthday;//生日 private Float money;//钱包 } 1.6 创建模板在resources下创建templates，此目录为freemarker的默认模板存放目录。 在templates下创建模板文件 01-basic.ftl ，模板中的插值表达式最终会被freemarker替换成具体的数据。 &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;b&gt;普通文本 String 展示：&lt;/b&gt;&lt;br&gt;&lt;br&gt; Hello ${name} &lt;br&gt; &lt;hr&gt; &lt;b&gt;对象Student中的数据展示：&lt;/b&gt;&lt;br/&gt; 姓名：${stu.name}&lt;br/&gt; 年龄：${stu.age} &lt;hr&gt; &lt;/body&gt; &lt;/html&gt; 1.7创建controller创建Controller类，向Map中添加name，最后返回模板文件。 package com.xuecheng.test.freemarker.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.client.RestTemplate; import java.util.Map; @Controller public class HelloController { @GetMapping(\"/basic\") public String test(Model model) { //1.纯文本形式的参数 model.addAttribute(\"name\", \"freemarker\"); //2.实体类相关的参数 Student student = new Student(); student.setName(\"小明\"); student.setAge(18); model.addAttribute(\"stu\", student); return \"01-basic\"; } } 01-basic.ftl，使用插值表达式填充数据 &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;b&gt;普通文本 String 展示：&lt;/b&gt;&lt;br&gt;&lt;br&gt; Hello ${name} &lt;br&gt; &lt;hr&gt; &lt;b&gt;对象Student中的数据展示：&lt;/b&gt;&lt;br/&gt; 姓名：${stu.name}&lt;br/&gt; 年龄：${stu.age} &lt;hr&gt; &lt;/body&gt; &lt;/html&gt; 1.8 创建启动类package com.heima.freemarker; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class FreemarkerDemotApplication { public static void main(String[] args) { SpringApplication.run(FreemarkerDemotApplication.class,args); } } 1.9 测试请求：http://localhost:8881/basic 2. freemarker基础2.1 基础语法种类 1、注释，即&lt;#– –&gt;，介于其之间的内容会被freemarker忽略 &lt;#--我是一个freemarker注释--&gt; 2、插值（Interpolation）：即 ${..} 部分,freemarker会用真实的值代替**${..}** Hello ${name} 3、FTL指令：和HTML标记类似，名字前加#予以区分，Freemarker会解析标签中的表达式或逻辑。 &lt;# &gt;FTL指令&lt;/#&gt; 4、文本，仅文本信息，这些不是freemarker的注释、插值、FTL指令的内容会被freemarker忽略解析，直接输出内容。 &lt;#--freemarker中的普通文本--&gt; 我是一个普通的文本 2.2 集合指令（List和Map）1、数据模型： 在HelloController中新增如下方法： @GetMapping(\"/list\") public String list(Model model){ //------------------------------------ Student stu1 = new Student(); stu1.setName(\"小强\"); stu1.setAge(18); stu1.setMoney(1000.86f); stu1.setBirthday(new Date()); //小红对象模型数据 Student stu2 = new Student(); stu2.setName(\"小红\"); stu2.setMoney(200.1f); stu2.setAge(19); //将两个对象模型数据存放到List集合中 List&lt;Student&gt; stus = new ArrayList&lt;&gt;(); stus.add(stu1); stus.add(stu2); //向model中存放List集合数据 model.addAttribute(\"stus\",stus); //------------------------------------ //创建Map数据 HashMap&lt;String,Student&gt; stuMap = new HashMap&lt;&gt;(); stuMap.put(\"stu1\",stu1); stuMap.put(\"stu2\",stu2); // 3.1 向model中存放Map数据 model.addAttribute(\"stuMap\", stuMap); return \"02-list\"; } 2、模板： 在templates中新增02-list.ftl文件 &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;#-- list 数据的展示 --&gt; &lt;b&gt;展示list中的stu数据:&lt;/b&gt; &lt;br&gt; &lt;br&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;序号&lt;/td&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;年龄&lt;/td&gt; &lt;td&gt;钱包&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;hr&gt; &lt;#-- Map 数据的展示 --&gt; &lt;b&gt;map数据的展示：&lt;/b&gt; &lt;br/&gt;&lt;br/&gt; &lt;a href=\"###\"&gt;方式一：通过map['keyname'].property&lt;/a&gt;&lt;br/&gt; 输出stu1的学生信息：&lt;br/&gt; 姓名：&lt;br/&gt; 年龄：&lt;br/&gt; &lt;br/&gt; &lt;a href=\"###\"&gt;方式二：通过map.keyname.property&lt;/a&gt;&lt;br/&gt; 输出stu2的学生信息：&lt;br/&gt; 姓名：&lt;br/&gt; 年龄：&lt;br/&gt; &lt;br/&gt; &lt;a href=\"###\"&gt;遍历map中两个学生信息：&lt;/a&gt;&lt;br/&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;序号&lt;/td&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;年龄&lt;/td&gt; &lt;td&gt;钱包&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;hr&gt; &lt;/body&gt; &lt;/html&gt; 实例代码： &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;#-- list 数据的展示 --&gt; &lt;b&gt;展示list中的stu数据:&lt;/b&gt; &lt;br&gt; &lt;br&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;序号&lt;/td&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;年龄&lt;/td&gt; &lt;td&gt;钱包&lt;/td&gt; &lt;/tr&gt; &lt;#list stus as stu&gt; &lt;tr&gt; &lt;td&gt;${stu_index+1}&lt;/td&gt; &lt;td&gt;${stu.name}&lt;/td&gt; &lt;td&gt;${stu.age}&lt;/td&gt; &lt;td&gt;${stu.money}&lt;/td&gt; &lt;/tr&gt; &lt;/#list&gt; &lt;/table&gt; &lt;hr&gt; &lt;#-- Map 数据的展示 --&gt; &lt;b&gt;map数据的展示：&lt;/b&gt; &lt;br/&gt;&lt;br/&gt; &lt;a href=\"###\"&gt;方式一：通过map['keyname'].property&lt;/a&gt;&lt;br/&gt; 输出stu1的学生信息：&lt;br/&gt; 姓名：${stuMap['stu1'].name}&lt;br/&gt; 年龄：${stuMap['stu1'].age}&lt;br/&gt; &lt;br/&gt; &lt;a href=\"###\"&gt;方式二：通过map.keyname.property&lt;/a&gt;&lt;br/&gt; 输出stu2的学生信息：&lt;br/&gt; 姓名：${stuMap.stu2.name}&lt;br/&gt; 年龄：${stuMap.stu2.age}&lt;br/&gt; &lt;br/&gt; &lt;a href=\"###\"&gt;遍历map中两个学生信息：&lt;/a&gt;&lt;br/&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;序号&lt;/td&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;年龄&lt;/td&gt; &lt;td&gt;钱包&lt;/td&gt; &lt;/tr&gt; &lt;#list stuMap?keys as key &gt; &lt;tr&gt; &lt;td&gt;${key_index}&lt;/td&gt; &lt;td&gt;${stuMap[key].name}&lt;/td&gt; &lt;td&gt;${stuMap[key].age}&lt;/td&gt; &lt;td&gt;${stuMap[key].money}&lt;/td&gt; &lt;/tr&gt; &lt;/#list&gt; &lt;/table&gt; &lt;hr&gt; &lt;/body&gt; &lt;/html&gt; 👆上面代码解释： ${k_index}： index：得到循环的下标，使用方法是在stu后边加”_index”，它的值是从0开始 2.3 if指令​ if 指令即判断指令，是常用的FTL指令，freemarker在解析时遇到if会进行判断，条件为真则输出if中间的内容，否则跳过内容不再输出。 指令格式 &lt;#if &gt;&lt;/if&gt; 1、数据模型： 使用list指令中测试数据模型，判断名称为小红的数据字体显示为红色。 2、模板： &lt;table&gt; &lt;tr&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;年龄&lt;/td&gt; &lt;td&gt;钱包&lt;/td&gt; &lt;/tr&gt; &lt;#list stus as stu&gt; &lt;tr&gt; &lt;td &gt;${stu.name}&lt;/td&gt; &lt;td&gt;${stu.age}&lt;/td&gt; &lt;td &gt;${stu.mondy}&lt;/td&gt; &lt;/tr&gt; &lt;/#list&gt; &lt;/table&gt; 实例代码： &lt;table&gt; &lt;tr&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;年龄&lt;/td&gt; &lt;td&gt;钱包&lt;/td&gt; &lt;/tr&gt; &lt;#list stus as stu &gt; &lt;#if stu.name='小红'&gt; &lt;tr style=\"color: red\"&gt; &lt;td&gt;${stu_index}&lt;/td&gt; &lt;td&gt;${stu.name}&lt;/td&gt; &lt;td&gt;${stu.age}&lt;/td&gt; &lt;td&gt;${stu.money}&lt;/td&gt; &lt;/tr&gt; &lt;#else &gt; &lt;tr&gt; &lt;td&gt;${stu_index}&lt;/td&gt; &lt;td&gt;${stu.name}&lt;/td&gt; &lt;td&gt;${stu.age}&lt;/td&gt; &lt;td&gt;${stu.money}&lt;/td&gt; &lt;/tr&gt; &lt;/#if&gt; &lt;/#list&gt; &lt;/table&gt; 3、输出： 姓名为“小强”则字体颜色显示为红色。 2.4 运算符1、算数运算符 FreeMarker表达式中完全支持算术运算,FreeMarker支持的算术运算符包括: 加法： + 减法： - 乘法： * 除法： / 求模 (求余)： % 模板代码 &lt;b&gt;算数运算符&lt;/b&gt; &lt;br/&gt;&lt;br/&gt; 100+5 运算： ${100 + 5 }&lt;br/&gt; 100 - 5 * 5运算：${100 - 5 * 5}&lt;br/&gt; 5 / 2运算：${5 / 2}&lt;br/&gt; 12 % 10运算：${12 % 10}&lt;br/&gt; &lt;hr&gt; 除了 + 运算以外，其他的运算只能和 number 数字类型的计算。 2、比较运算符 =**或者==**:判断两个值是否相等. !=:判断两个值是否不等. &gt;**或者gt**:判断左边值是否大于右边值 &gt;=**或者gte**:判断左边值是否大于等于右边值 &lt;**或者lt**:判断左边值是否小于右边值 &lt;=**或者lte**:判断左边值是否小于等于右边值 = 和 == 模板代码 &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;b&gt;比较运算符&lt;/b&gt; &lt;br/&gt; &lt;br/&gt; &lt;dl&gt; &lt;dt&gt; =/== 和 != 比较：&lt;/dt&gt; &lt;dd&gt; &lt;#if \"xiaoming\" == \"xiaoming\"&gt; 字符串的比较 \"xiaoming\" == \"xiaoming\" &lt;/#if&gt; &lt;/dd&gt; &lt;dd&gt; &lt;#if 10 != 100&gt; 数值的比较 10 != 100 &lt;/#if&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;dl&gt; &lt;dt&gt;其他比较&lt;/dt&gt; &lt;dd&gt; &lt;#if 10 gt 5 &gt; 形式一：使用特殊字符比较数值 10 gt 5 &lt;/#if&gt; &lt;/dd&gt; &lt;dd&gt; &lt;#-- 日期的比较需要通过?date将属性转为data类型才能进行比较 --&gt; &lt;#if (date1?date &gt;= date2?date)&gt; 形式二：使用括号形式比较时间 date1?date &gt;= date2?date &lt;/#if&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;br/&gt; &lt;hr&gt; &lt;/body&gt; &lt;/html&gt; Controller 的 数据模型代码 @GetMapping(\"operation\") public String testOperation(Model model) { //构建 Date 数据 Date now = new Date(); model.addAttribute(\"date1\", now); model.addAttribute(\"date2\", now); return \"03-operation\"; } 比较运算符注意 =**和!=**可以用于字符串、数值和日期来比较是否相等 =**和!=**两边必须是相同类型的值,否则会产生错误 字符串 \"x\" 、**\"x \"** 、**\"X\"**比较是不等的.因为FreeMarker是精确比较 其它的运行符可以作用于数字和日期,但不能作用于字符串 使用**gt等字母运算符代替&gt;会有更好的效果,因为 FreeMarker会把&gt;**解释成FTL标签的结束字符 可以使用括号来避免这种情况,如:&lt;#if (x&gt;y)&gt; 3、逻辑运算符 逻辑与:&amp;&amp; 逻辑或:|| 逻辑非:! 逻辑运算符只能作用于布尔值,否则将产生错误 。 模板代码 &lt;b&gt;逻辑运算符&lt;/b&gt; &lt;br/&gt; &lt;br/&gt; &lt;#if (10 lt 12 )&amp;&amp;( 10 gt 5 ) &gt; (10 lt 12 )&amp;&amp;( 10 gt 5 ) 显示为 true &lt;/#if&gt; &lt;br/&gt; &lt;br/&gt; &lt;#if !false&gt; false 取反为true &lt;/#if&gt; &lt;hr&gt; 2.5 空值处理1、判断某变量是否存在使用 “??” 用法为:variable??,如果该变量存在,返回true,否则返回false 例：为防止stus为空报错可以加上判断如下： &lt;#if stus??&gt; &lt;#list stus as stu&gt; ...... &lt;/#list&gt; &lt;/#if&gt; 2、缺失变量默认值使用 “!” 使用!要以指定一个默认值，当变量为空时显示默认值 例： ${name!’’}表示如果name为空显示空字符串。 如果是嵌套对象则建议使用（）括起来 例： ${(stu.bestFriend.name)!’’}表示，如果stu或bestFriend或name为空默认显示空字符串。 2.6 内建函数内建函数语法格式： 变量+?+函数名称 1、和到某个集合的大小 ${集合名?size} 2、日期格式化 显示年月日: ${today?date}显示时分秒：**${today?time}**显示日期+时间：**${today?datetime}**自定义格式化： ${today?string(\"yyyy年MM月\")} 3、内建函数c model.addAttribute(“point”, 102920122); point是数字型，使用${point}会显示这个数字的值，每三位使用逗号分隔。 如果不想显示为每三位分隔的数字，可以使用c函数将数字型转成字符串输出 ${point?c} 4、将json字符串转成对象 一个例子： 其中用到了 assign标签，assign的作用是定义一个变量。 &lt;#assign text=\"{'bank':'工商银行','account':'10101920201920212'}\" /&gt; &lt;#assign data=text?eval /&gt; 开户行：${data.bank} 账号：${data.account} 模板代码： &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;inner Function&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;b&gt;获得集合大小&lt;/b&gt;&lt;br&gt; 集合大小： &lt;hr&gt; &lt;b&gt;获得日期&lt;/b&gt;&lt;br&gt; 显示年月日: &lt;br&gt; 显示时分秒：&lt;br&gt; 显示日期+时间：&lt;br&gt; 自定义格式化： &lt;br&gt; &lt;hr&gt; &lt;b&gt;内建函数C&lt;/b&gt;&lt;br&gt; 没有C函数显示的数值： &lt;br&gt; 有C函数显示的数值： &lt;hr&gt; &lt;b&gt;声明变量assign&lt;/b&gt;&lt;br&gt; &lt;hr&gt; &lt;/body&gt; &lt;/html&gt; 内建函数模板页面： &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;inner Function&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;b&gt;获得集合大小&lt;/b&gt;&lt;br&gt; 集合大小：${stus?size} &lt;hr&gt; &lt;b&gt;获得日期&lt;/b&gt;&lt;br&gt; 显示年月日: ${today?date} &lt;br&gt; 显示时分秒：${today?time}&lt;br&gt; 显示日期+时间：${today?datetime}&lt;br&gt; 自定义格式化： ${today?string(\"yyyy年MM月\")}&lt;br&gt; &lt;hr&gt; &lt;b&gt;内建函数C&lt;/b&gt;&lt;br&gt; 没有C函数显示的数值：${point} &lt;br&gt; 有C函数显示的数值：${point?c} &lt;hr&gt; &lt;b&gt;声明变量assign&lt;/b&gt;&lt;br&gt; &lt;#assign text=\"{'bank':'工商银行','account':'10101920201920212'}\" /&gt; &lt;#assign data=text?eval /&gt; 开户行：${data.bank} 账号：${data.account} &lt;hr&gt; &lt;/body&gt; &lt;/html&gt; 内建函数Controller数据模型： @GetMapping(\"innerFunc\") public String testInnerFunc(Model model) { //1.1 小强对象模型数据 Student stu1 = new Student(); stu1.setName(\"小强\"); stu1.setAge(18); stu1.setMoney(1000.86f); stu1.setBirthday(new Date()); //1.2 小红对象模型数据 Student stu2 = new Student(); stu2.setName(\"小红\"); stu2.setMoney(200.1f); stu2.setAge(19); //1.3 将两个对象模型数据存放到List集合中 List&lt;Student&gt; stus = new ArrayList&lt;&gt;(); stus.add(stu1); stus.add(stu2); model.addAttribute(\"stus\", stus); // 2.1 添加日期 Date date = new Date(); model.addAttribute(\"today\", date); // 3.1 添加数值 model.addAttribute(\"point\", 102920122); return \"04-innerFunc\"; } 3. 静态化测试之前的测试都是SpringMVC将Freemarker作为视图解析器（ViewReporter）来集成到项目中，工作中，有的时候需要使用Freemarker原生Api来生成静态内容，下面一起来学习下原生Api生成文本文件。 3.1 需求分析使用freemarker原生Api将页面生成html文件，本节测试html文件生成的方法： 3.2静态化测试根据模板文件生成html文件 ①：修改application.yml文件，添加以下模板存放位置的配置信息，完整配置如下： server: port: 8881 #服务端口 spring: application: name: freemarker-demo #指定服务名 freemarker: cache: false #关闭模板缓存，方便测试 settings: template_update_delay: 0 #检查模板更新延迟时间，设置为0表示立即检查，如果时间大于0会有缓存不方便进行模板测试 suffix: .ftl #指定Freemarker模板文件的后缀名 template-loader-path: classpath:/templates #模板存放位置 ②：在test下创建测试类 package com.heima.freemarker.test; import com.heima.freemarker.FreemarkerDemoApplication; import com.heima.freemarker.entity.Student; import freemarker.template.Configuration; import freemarker.template.Template; import freemarker.template.TemplateException; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import java.io.FileWriter; import java.io.IOException; import java.util.*; @SpringBootTest(classes = FreemarkerDemoApplication.class) @RunWith(SpringRunner.class) public class FreemarkerTest { @Autowired private Configuration configuration; @Test public void test() throws IOException, TemplateException { //freemarker的模板对象，获取模板 Template template = configuration.getTemplate(\"02-list.ftl\"); Map params = getData(); //合成 //第一个参数 数据模型 //第二个参数 输出流 template.process(params, new FileWriter(\"d:/list.html\")); } private Map getData() { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); //小强对象模型数据 Student stu1 = new Student(); stu1.setName(\"小强\"); stu1.setAge(18); stu1.setMoney(1000.86f); stu1.setBirthday(new Date()); //小红对象模型数据 Student stu2 = new Student(); stu2.setName(\"小红\"); stu2.setMoney(200.1f); stu2.setAge(19); //将两个对象模型数据存放到List集合中 List&lt;Student&gt; stus = new ArrayList&lt;&gt;(); stus.add(stu1); stus.add(stu2); //向map中存放List集合数据 map.put(\"stus\", stus); //创建Map数据 HashMap&lt;String, Student&gt; stuMap = new HashMap&lt;&gt;(); stuMap.put(\"stu1\", stu1); stuMap.put(\"stu2\", stu2); //向map中存放Map数据 map.put(\"stuMap\", stuMap); //返回Map return map; } }","categories":[{"name":"API","slug":"API","permalink":"https://macongmc.github.io/categories/API/"}],"tags":[{"name":"api","slug":"api","permalink":"https://macongmc.github.io/tags/api/"}],"author":"马聪"},{"title":"接口工具Swagger","slug":"接口工具","date":"2022-07-26T09:38:28.000Z","updated":"2023-01-01T15:39:18.440Z","comments":true,"path":"posts/undefined.html","link":"","permalink":"https://macongmc.github.io/posts/undefined.html","excerpt":"","text":"1.swagger依赖 &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;/dependency&gt; 配置类 package com.heima.common.swagger; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.Contact; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; @Configuration @EnableSwagger2 public class SwaggerConfiguration { @Bean public Docket buildDocket() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(buildApiInfo()) .select() // 要扫描的API(Controller)基础包 .apis(RequestHandlerSelectors.basePackage(\"com.heima\")) .paths(PathSelectors.any()) .build(); } private ApiInfo buildApiInfo() { Contact contact = new Contact(\"黑马程序员\",\"\",\"\"); return new ApiInfoBuilder() .title(\"黑马头条-平台管理API文档\") .description(\"黑马头条后台api\") .contact(contact) .version(\"1.0.0\").build(); } } resources目录中新增以下目录和文件 文件：resources/META-INF/Spring.factories org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.heima.common.swagger.SwaggerConfiguration 常用注解在Java类中添加Swagger的注解即可生成Swagger接口文档，常用Swagger注解如下： @Api：修饰整个类，描述Controller的作用 @ApiOperation：描述一个类的一个方法，或者说一个接口 @ApiParam：单个参数的描述信息 @ApiModel：用对象来接收参数 @ApiModelProperty：用对象接收参数时，描述对象的一个字段 @ApiResponse：HTTP响应其中1个描述 @ApiResponses：HTTP响应整体描述 @ApiIgnore：使用该注解忽略这个API @ApiError ：发生错误返回的信息 @ApiImplicitParam：一个请求参数 @ApiImplicitParams：多个请求参数的描述信息 属性 取值 作用 paramType 查询参数类型 path 以地址的形式提交数据 query 直接跟参数完成自动映射赋值 body 以流的形式提交 仅支持POST header 参数在request headers 里边提交 form 以form表单的形式提交 仅支持POST dataType 参数的数据类型 只作为标志说明，并没有实际验证 Long String name 接收参数名 value 接收参数的意义描述 required 参数是否必填 true 必填 false 非必填 defaultValue 默认值 @RestController @RequestMapping(\"/api/v1/login\") @Api(value = \"app端用户登录\", tags = \"ap_user\", description = \"app端用户登录API\") public class ApUserLoginController { @Autowired private ApUserService apUserService; @PostMapping(\"/login_auth\") @ApiOperation(\"用户登录\") public ResponseResult login(@RequestBody LoginDto dto){ return apUserService.login(dto); } } @Data public class LoginDto { /** * 手机号 */ @ApiModelProperty(value=\"手机号\",required = true) private String phone; /** * 密码 */ @ApiModelProperty(value=\"密码\",required = true) private String password; } 访问地址启动user微服务，访问地址：http://localhost:51801/swagger-ui.html 2.knife4j&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; Swagger配置文件package com.heima.common.knife4j; import com.github.xiaoymin.knife4j.spring.annotations.EnableKnife4j; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Import; import springfox.bean.validators.configuration.BeanValidatorPluginsConfiguration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; @Configuration @EnableSwagger2 @EnableKnife4j @Import(BeanValidatorPluginsConfiguration.class) public class Swagger2Configuration { @Bean(value = \"defaultApi2\") public Docket defaultApi2() { Docket docket=new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) //分组名称 .groupName(\"1.0\") .select() //这里指定Controller扫描包路径 .apis(RequestHandlerSelectors.basePackage(\"com.heima\")) .paths(PathSelectors.any()) .build(); return docket; } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"黑马头条API文档\") .description(\"黑马头条API文档\") .version(\"1.0\") .build(); } } 注解 说明 @EnableSwagger2 该注解是Springfox-swagger框架提供的使用Swagger注解，该注解必须加 @EnableKnife4j 该注解是knife4j提供的增强注解,Ui提供了例如动态参数、参数过滤、接口排序等增强功能,如果你想使用这些增强功能就必须加该注解，否则可以不用加 添加配置 在Spring.factories中新增配置 org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.heima.common.swagger.Swagger2Configuration, \\ com.heima.common.swagger.SwaggerConfiguration 访问 在浏览器输入地址：http://host:port/doc.html","categories":[{"name":"API","slug":"API","permalink":"https://macongmc.github.io/categories/API/"}],"tags":[{"name":"工具使用","slug":"工具使用","permalink":"https://macongmc.github.io/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"},{"name":"api","slug":"api","permalink":"https://macongmc.github.io/tags/api/"}],"author":"马聪"},{"title":"SDK集成IDEA","slug":"SDK集成IDEA","date":"2022-07-25T07:28:49.000Z","updated":"2022-07-25T07:28:49.000Z","comments":true,"path":"posts/3594a379.html","link":"","permalink":"https://macongmc.github.io/posts/3594a379.html","excerpt":"","text":"一.配置文件配置文件META-INF目录中下建立spring.factoriesspring.factories org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ 配置类的全路径名 二.配置类主要把SDK配置成Template供我们使用。1.配置Properties类存放SDK所需的参数。2.配置Template类存放SDK的方法。3.编写配置类@EnableConfigurationProperties和@Bean注解来把SDKTemplate注册到容器中让我们使用。","categories":[{"name":"SDK","slug":"SDK","permalink":"https://macongmc.github.io/categories/SDK/"}],"tags":[{"name":"sdk","slug":"sdk","permalink":"https://macongmc.github.io/tags/sdk/"},{"name":"java","slug":"java","permalink":"https://macongmc.github.io/tags/java/"}],"author":"马聪"},{"title":"注解翻译字典","slug":"注解翻译字典","date":"2022-07-25T07:12:07.000Z","updated":"2022-07-25T07:12:07.000Z","comments":true,"path":"posts/715cdf7a.html","link":"","permalink":"https://macongmc.github.io/posts/715cdf7a.html","excerpt":"","text":"一.注解1.注解说明，自定义两个注解，一个进行标记字段，里面存字典字段的值，一个标记controller标记在那个查询方法上进行转化。 字段注解： import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) public @interface Dict { /** * 需要翻译的字段名称 */ String fieldName(); } 标记注解 import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface DoDict { } 二.实现方法使用AOP对查询的返回结果进行判断。分别为对象或者集合分类。通过反射对字段进行翻译。 import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.JSONObject; import com.fn.common.core.page.TableDataInfo; import com.fn.safe.annotation.Dict; import com.fn.safe.init.InitData; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.springframework.stereotype.Component; import java.lang.reflect.Field; import java.util.List; @Aspect @Component public class DoDictAspect { @Pointcut(\"@annotation(com.fn.safe.annotation.DoDict)\") public void execute() { } @Around(\"execute()\") public Object around(ProceedingJoinPoint point) throws Throwable { Object proceed = point.proceed(); System.out.println(\"JSON.toJSONString(proceed) = \" + JSON.toJSONString(proceed)); doDict(proceed); return proceed; } private void doDict(Object proceed) { if (!(proceed instanceof TableDataInfo)){ Object object = invert(proceed); JSONObject.toJSONString(object); return ; } TableDataInfo dataInfo = (TableDataInfo) proceed; List&lt;?&gt; rows = dataInfo.getRows(); List&lt;?&gt; rowsDict=convertList(rows); dataInfo.setRows(rowsDict); JSONObject.toJSONString(dataInfo); } private Object invert(Object obj) { filedName(obj); return obj; } private void filedName(Object obj) { Class&lt;?&gt; aClass = obj.getClass(); Field[] declaredFields = aClass.getDeclaredFields(); for (Field declaredField : declaredFields) { declaredField.setAccessible(true); if (declaredField.getAnnotation(Dict.class)==null){ continue; } String fieldName = declaredField.getAnnotation(Dict.class).fieldName(); try { Object fieldValue = declaredField.get(obj); if (fieldValue!=null){ Dict dict = declaredField.getAnnotation(Dict.class); String dictName = dict.fieldName(); String code =dictName+\":\"+fieldValue; String dictCode = InitData.map.get(code); fieldValue =dictCode; declaredField.set(obj,fieldValue); } } catch (IllegalAccessException e) { } } } private List&lt;?&gt; convertList(List&lt;?&gt; rows) { if (rows.isEmpty()){ return null; } for (Object row : rows) { filedName(row); } return rows; } } 三.使用方法标记放在controller 翻译放在对象需要翻译的字段上。 四.实例代码import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.JSONObject; import com.fn.common.core.page.TableDataInfo; import com.fn.safe.annotation.Dict; import com.fn.safe.init.InitData; import org.apache.commons.lang3.StringUtils; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.springframework.stereotype.Component; import java.lang.reflect.Field; import java.util.List; @Aspect @Component public class DoDictAspect { @Pointcut(\"@annotation(com.fn.safe.annotation.DoDict)\") public void execute() { } @Around(\"execute()\") public Object around(ProceedingJoinPoint point) throws Throwable { Object proceed = point.proceed(); System.out.println(\"JSON.toJSONString(proceed) = \" + JSON.toJSONString(proceed)); doDict(proceed); return proceed; } private void doDict(Object proceed) { if (!(proceed instanceof TableDataInfo)){ Object object = invert(proceed); JSONObject.toJSONString(object); return ; } TableDataInfo dataInfo = (TableDataInfo) proceed; List&lt;?&gt; rows = dataInfo.getRows(); List&lt;?&gt; rowsDict=convertList(rows); dataInfo.setRows(rowsDict); JSONObject.toJSONString(dataInfo); } private Object invert(Object obj) { filedName(obj); return obj; } private void filedName(Object obj) { Class&lt;?&gt; aClass = obj.getClass(); Field[] declaredFields = aClass.getDeclaredFields(); for (Field declaredField : declaredFields) { declaredField.setAccessible(true); if (declaredField.getAnnotation(Dict.class)==null){ continue; } String fieldName = declaredField.getAnnotation(Dict.class).fieldName(); try { Object fieldValue = declaredField.get(obj); if (fieldValue!=null){ Dict dict = declaredField.getAnnotation(Dict.class); String dictName = dict.fieldName(); String code =dictName+\":\"+fieldValue; String dictCode = InitData.map.get(code); if (StringUtils.isNotEmpty(dictCode)){ fieldValue =dictCode; declaredField.set(obj,fieldValue); } } } catch (IllegalAccessException e) { } } } private List&lt;?&gt; convertList(List&lt;?&gt; rows) { if (rows.isEmpty()){ return null; } for (Object row : rows) { filedName(row); } return rows; } }","categories":[{"name":"工具篇","slug":"工具篇","permalink":"https://macongmc.github.io/categories/%E5%B7%A5%E5%85%B7%E7%AF%87/"}],"tags":[{"name":"aop","slug":"aop","permalink":"https://macongmc.github.io/tags/aop/"},{"name":"注解","slug":"注解","permalink":"https://macongmc.github.io/tags/%E6%B3%A8%E8%A7%A3/"}],"author":"马聪"},{"title":"城市-省","slug":"城市-省","date":"2022-07-25T03:26:53.000Z","updated":"2022-07-25T03:26:53.000Z","comments":true,"path":"posts/b4458878.html","link":"","permalink":"https://macongmc.github.io/posts/b4458878.html","excerpt":"","text":"一.实体设计//省份 import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.io.Serializable; import java.util.List; @Data @AllArgsConstructor @NoArgsConstructor public class Province implements Serializable { private String provinceType; private String provinceName; private List&lt;City&gt; city; } //城市 import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.io.Serializable; @Data @AllArgsConstructor @NoArgsConstructor public class City implements Serializable { private String cityName; private String areaType; private String isCapital; } 二.读取文章public static String getJson(){ StringBuilder sb = new StringBuilder(); Resource resource = new ClassPathResource(\"json/city.json\"); InputStream is = null; BufferedReader br =null; InputStreamReader isr = null; try { is = resource.getInputStream(); isr = new InputStreamReader(is); br = new BufferedReader(isr); String data = null; while((data = br.readLine()) != null) { sb.append(data); } } catch (IOException e) { log.error(\"加载JSON城市异常：{}\",e); }finally { try { br.close(); isr.close(); is.close(); } catch (IOException e) { e.printStackTrace(); } } return sb.toString(); } 三. 转换实体public static Map&lt;List&lt;City&gt;,String&gt; cityMap = new HashMap&lt;&gt;(); String value = getJson(); if (!StringUtils.isEmpty(value)){ List&lt;City&gt; list = new ArrayList&lt;&gt;(); List listCity = JSONObject.parseObject(value, list.getClass()); for (Object o : listCity) { Province province = JSONObject.parseObject(o.toString(), Province.class); List&lt;City&gt; cityList = new ArrayList&lt;&gt;(); for (City city : province.getCity()) { cityList.add(city); } cityMap.put(cityList,province.getProvinceName()); } } 四.映射方法static String getProvince(String cityName){ Set&lt;Map.Entry&lt;List&lt;City&gt;, String&gt;&gt; entries = cityMap.entrySet(); for (Map.Entry&lt;List&lt;City&gt;, String&gt; entry : entries) { List&lt;City&gt; key = entry.getKey(); for (City city : key) { if (city.getCityName().equals(cityName)){ return cityMap.get(key); } } } return \"其他\"; } 五.json文件 { \"provinceType\": 1, \"provinceName\": \"北京市\", \"city\": [ { \"cityName\": \"北京市\", \"areaType\": 1, \"isCapital\": true } ] }, { \"provinceType\": 1, \"provinceName\": \"上海市\", \"city\": [ { \"cityName\": \"上海市\", \"areaType\": 1, \"isCapital\": true } ] }, { \"provinceType\": 1, \"provinceName\": \"天津市\", \"city\": [ { \"cityName\": \"天津市\", \"areaType\": 1, \"isCapital\": true } ] }, { \"provinceType\": 1, \"provinceName\": \"重庆市\", \"city\": [ { \"cityName\": \"重庆市\", \"areaType\": 1, \"isCapital\": true } ] }, { \"provinceType\": 2, \"provinceName\": \"河北省\", \"city\": [ { \"cityName\": \"石家庄市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"唐山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"秦皇岛市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"邯郸市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"邢台市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"保定市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"张家口市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"承德市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"沧州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"廊坊市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"衡水市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"辛集市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"藁城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"晋州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"新乐市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"鹿泉市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"遵化市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"迁安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"武安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"南宫市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"沙河市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"涿州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"定州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"安国市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"高碑店市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"泊头市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"任丘市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"黄骅市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"河间市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"霸州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"三河市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"冀州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"深州市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"山西省\", \"city\": [ { \"cityName\": \"太原市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"大同市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"朔州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"阳泉市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"长治市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"晋城市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"忻州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"晋中市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"临汾市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"运城市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"吕梁市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"古交市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"潞城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"高平市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"原平市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"介休市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"侯马市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"霍州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"永济市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"河津市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"孝义市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"汾阳市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"陕西省\", \"city\": [ { \"cityName\": \"西安市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"铜川市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"宝鸡市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"咸阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"渭南市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"延安市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"汉中市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"榆林市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"安康市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"商洛市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"兴平市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"韩城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"华阴市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"山东省\", \"city\": [ { \"cityName\": \"济南市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"青岛市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"淄博市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"枣庄市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"东营市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"烟台市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"潍坊市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"济宁市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"泰安市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"威海市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"日照市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"莱芜市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"临沂市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"德州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"聊城市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"滨州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"菏泽市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"章丘市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"胶南市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"胶州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"平度市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"莱西市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"即墨市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"滕州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"龙口市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"莱阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"莱州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"招远市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"蓬莱市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"栖霞市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"海阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"青州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"诸城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"寿光市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"安丘市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"高密市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"昌邑市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"曲阜市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"兖州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"邹城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"新泰市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"肥城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"乳山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"文登市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"荣成市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"乐陵市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"禹城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"临清市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"河南省\", \"city\": [ { \"cityName\": \"郑州市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"开封市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"洛阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"平顶山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"安阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"鹤壁市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"新乡市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"焦作市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"濮阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"许昌市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"漯河市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"三门峡市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"南阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"商丘市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"信阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"周口市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"驻马店市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"巩义市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"新郑市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"新密市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"登封市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"荥阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"中牟县\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"偃师市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"汝州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"舞钢市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"林州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"卫辉市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"辉县市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"沁阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"孟州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"禹州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"长葛市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"义马市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"灵宝市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"邓州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"永城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"项城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"济源市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"辽宁省\", \"city\": [ { \"cityName\": \"沈阳市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"大连市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"鞍山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"抚顺市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"本溪市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"丹东市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"锦州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"营口市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"阜新市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"辽阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"盘锦市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"铁岭市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"朝阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"葫芦岛市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"新民市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"瓦房店市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"普兰店市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"庄河市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"海城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"东港市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"凤城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"凌海市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"北镇市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"大石桥市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"盖州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"灯塔市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"调兵山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"开原市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"凌源市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"北票市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"兴城市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"吉林省\", \"city\": [ { \"cityName\": \"长春市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"吉林市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"四平市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"辽源市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"通化市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"白山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"松原市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"白城市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"延边朝鲜族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"九台市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"榆树市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"德惠市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"舒兰市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"桦甸市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"蛟河市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"磐石市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"公主岭市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"双辽市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"梅河口市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"集安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"临江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"大安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"洮南市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"延吉市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"图们市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"敦化市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"龙井市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"珲春市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"和龙市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"黑龙江省\", \"city\": [ { \"cityName\": \"哈尔滨市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"齐齐哈尔市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"鹤岗市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"双鸭山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"鸡西市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"大庆市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"伊春市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"牡丹江市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"佳木斯市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"七台河市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"黑河市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"绥化市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"大兴安岭地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"尚志市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"双城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"五常市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"讷河市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"密山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"虎林市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"铁力市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"绥芬河市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"宁安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"海林市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"穆棱市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"同江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"富锦市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"北安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"五大连池市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"安达市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"肇东市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"海伦市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"江苏省\", \"city\": [ { \"cityName\": \"南京市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"无锡市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"徐州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"常州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"苏州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"南通市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"连云港市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"淮安市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"盐城市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"扬州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"镇江市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"泰州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"宿迁市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"江阴市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"宜兴市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"邳州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"新沂市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"金坛市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"溧阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"常熟市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"张家港市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"太仓市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"昆山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"吴江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"如皋市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"通州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"海门市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"启东市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"东台市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"大丰市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"高邮市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"江都市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"仪征市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"丹阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"扬中市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"句容市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"泰兴市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"姜堰市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"靖江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"兴化市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"浙江省\", \"city\": [ { \"cityName\": \"杭州市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"宁波市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"温州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"嘉兴市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"湖州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"绍兴市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"金华市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"衢州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"舟山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"台州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"丽水市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"建德市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"富阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"临安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"余姚市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"慈溪市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"奉化市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"瑞安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"乐清市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"海宁市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"平湖市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"桐乡市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"诸暨市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"上虞市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"嵊州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"兰溪市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"义乌市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"东阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"永康市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"江山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"临海市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"温岭市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"龙泉市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"安徽省\", \"city\": [ { \"cityName\": \"合肥市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"芜湖市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"蚌埠市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"淮南市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"马鞍山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"淮北市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"铜陵市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"安庆市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"黄山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"滁州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"阜阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"宿州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"巢湖市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"六安市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"亳州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"池州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"宣城市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"桐城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"天长市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"明光市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"界首市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"宁国市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"江西省\", \"city\": [ { \"cityName\": \"南昌市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"景德镇市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"萍乡市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"九江市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"新余市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"鹰潭市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"赣州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"吉安市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"宜春市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"抚州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"上饶市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"乐平市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"瑞昌市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"贵溪市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"瑞金市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"南康市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"井冈山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"丰城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"樟树市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"高安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"德兴市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"福建省\", \"city\": [ { \"cityName\": \"福州市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"厦门市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"莆田市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"三明市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"泉州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"漳州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"南平市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"龙岩市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"宁德市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"福清市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"长乐市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"永安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"石狮市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"晋江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"南安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"龙海市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"邵武市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"武夷山\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"建瓯市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"漳平市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"建阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"福安市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"福鼎市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"湖北省\", \"city\": [ { \"cityName\": \"武汉市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"黄石市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"十堰市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"荆州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"宜昌市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"襄樊市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"鄂州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"荆门市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"孝感市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"黄冈市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"咸宁市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"随州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"恩施土家族苗族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"大冶市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"丹江口市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"洪湖市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"石首市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"松滋市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"宜都市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"当阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"枝江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"老河口市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"枣阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"宜城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"钟祥市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"应城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"安陆市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"汉川市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"麻城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"武穴市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"赤壁市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"广水市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"仙桃市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"天门市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"潜江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"恩施市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"利川市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"湖南省\", \"city\": [ { \"cityName\": \"长沙市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"株洲市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"湘潭市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"衡阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"邵阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"岳阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"常德市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"张家界市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"益阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"郴州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"永州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"怀化市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"娄底市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"湘西土家族苗族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"浏阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"醴陵市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"湘乡市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"韶山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"耒阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"常宁市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"武冈市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"临湘市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"汨罗市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"津市市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"沅江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"资兴市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"洪江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"冷水江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"涟源市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"吉首市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"四川省\", \"city\": [ { \"cityName\": \"成都市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"自贡市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"攀枝花市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"泸州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"德阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"绵阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"广元市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"遂宁市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"内江市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"乐山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"南充市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"眉山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"宜宾市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"广安市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"达州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"雅安市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"巴中市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"资阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"阿坝藏族羌族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"甘孜藏族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"凉山彝族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"都江堰市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"彭州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"邛崃市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"崇州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"广汉市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"什邡市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"绵竹市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"江油市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"峨眉山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"阆中市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"华蓥市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"万源市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"简阳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"西昌市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"贵州省\", \"city\": [ { \"cityName\": \"贵阳市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"六盘水市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"遵义市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"安顺市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"铜仁地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"毕节地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"黔西南布依族苗族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"黔东南苗族侗族自治州、\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"黔南布依族苗族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"清镇市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"赤水市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"仁怀市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"铜仁市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"毕节市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"兴义市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"凯里市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"都匀市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"福泉市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"云南省\", \"city\": [ { \"cityName\": \"昆明市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"曲靖市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"玉溪市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"保山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"昭通市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"丽江市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"普洱市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"临沧市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"文山壮族苗族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"红河哈尼族彝族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"西双版纳傣族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"楚雄彝族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"大理白族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"德宏傣族景颇族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"怒江僳僳族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"迪庆藏族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"安宁市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"宣威市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"个旧市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"开远市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"景洪市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"楚雄市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"大理市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"潞西市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"瑞丽市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"广东省\", \"city\": [ { \"cityName\": \"广州市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"深圳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"珠海市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"汕头市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"韶关市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"佛山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"江门市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"湛江市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"茂名市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"肇庆市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"惠州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"梅州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"汕尾市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"河源市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"阳江市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"清远市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"东莞市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"中山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"潮州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"揭阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"云浮市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"从化市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"增城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"乐昌市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"南雄市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"台山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"开平市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"鹤山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"恩平市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"廉江市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"雷州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"吴川市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"高州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"化州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"信宜市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"高要市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"四会市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"兴宁市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"陆丰市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"阳春市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"英德市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"连州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"普宁市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"罗定市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"海南省\", \"city\": [ { \"cityName\": \"海口市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"三亚市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"文昌市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"琼海市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"万宁市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"五指山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"东方市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"儋州市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"甘肃省\", \"city\": [ { \"cityName\": \"兰州市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"金昌市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"白银市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"天水市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"嘉峪关市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"武威市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"张掖市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"平凉市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"酒泉市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"庆阳市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"定西市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"陇南市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"临夏回族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"甘南藏族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"玉门市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"敦煌市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"临夏市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"合作市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"青海省\", \"city\": [ { \"cityName\": \"西宁市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"海东地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"海北藏族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"黄南藏族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"海南藏族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"果洛藏族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"玉树藏族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"海西蒙古族藏族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"德令哈市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"格尔木市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"台湾省\", \"city\": [ { \"cityName\": \"台北市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"高雄市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"基隆市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"台中市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"台南市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"新竹市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"嘉义市\", \"areaType\": 2, \"isCapital\": false } ] }, { \"provinceType\": 3, \"provinceName\": \"内蒙古自治区\", \"city\": [ { \"cityName\": \"呼和浩特市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"包头市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"乌海市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"赤峰市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"通辽市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"鄂尔多斯市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"呼伦贝尔市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"巴彦淖尔市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"乌兰察布市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"锡林郭勒盟\", \"areaType\": 6, \"isCapital\": false }, { \"cityName\": \"兴安盟\", \"areaType\": 6, \"isCapital\": false }, { \"cityName\": \"阿拉善盟\", \"areaType\": 6, \"isCapital\": false }, { \"cityName\": \"霍林郭勒市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"满洲里市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"牙克石市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"扎兰屯市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"根河市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"额尔古纳市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"丰镇市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"锡林浩特市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"二连浩特市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"乌兰浩特市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"阿尔山市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 3, \"provinceName\": \"新疆维吾尔自治区\", \"city\": [ { \"cityName\": \"乌鲁木齐市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"克拉玛依市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"吐鲁番地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"哈密地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"和田地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"阿克苏地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"喀什地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"塔城地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"阿勒泰地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"克孜勒苏柯尔克孜自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"巴音郭楞蒙古自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"昌吉回族自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"博尔塔拉蒙古自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"伊犁哈萨克自治州\", \"areaType\": 5, \"isCapital\": false }, { \"cityName\": \"石河子市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"阿拉尔市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"图木舒克市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"五家渠市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"吐鲁番市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"哈密市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"和田市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"阿克苏市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"喀什市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"阿图什市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"库尔勒市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"昌吉市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"阜康市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"米泉市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"博乐市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"伊宁市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"奎屯市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"塔城市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"乌苏市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"阿勒泰市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 3, \"provinceName\": \"西藏自治区\", \"city\": [ { \"cityName\": \"拉萨市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"那曲地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"昌都地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"山南地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"日喀则地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"阿里地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"林芝地区\", \"areaType\": 4, \"isCapital\": false }, { \"cityName\": \"日喀则市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 3, \"provinceName\": \"广西壮族自治区\", \"city\": [ { \"cityName\": \"南宁市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"柳州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"桂林市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"梧州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"北海市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"防城港市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"钦州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"贵港市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"玉林市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"百色市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"贺州市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"河池市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"来宾市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"崇左市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"岑溪市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"东兴市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"桂平市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"北流市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"宜州市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"合山市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"凭祥市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 2, \"provinceName\": \"宁夏回族自治区\", \"city\": [ { \"cityName\": \"银川市\", \"areaType\": 2, \"isCapital\": true }, { \"cityName\": \"石嘴山市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"吴忠市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"固原市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"中卫市\", \"areaType\": 2, \"isCapital\": false }, { \"cityName\": \"灵武市\", \"areaType\": 3, \"isCapital\": false }, { \"cityName\": \"青铜峡市\", \"areaType\": 3, \"isCapital\": false } ] }, { \"provinceType\": 4, \"provinceName\": \"香港\", \"city\": [ { \"cityName\": \"香港\", \"areaType\": 7, \"isCapital\": true } ] }, { \"provinceType\": 4, \"provinceName\": \"澳门\", \"city\": [ { \"cityName\": \"澳门\", \"areaType\": 7, \"isCapital\": true } ] } ] 六.读取文件方法1.读取文件方法","categories":[{"name":"工具篇","slug":"工具篇","permalink":"https://macongmc.github.io/categories/%E5%B7%A5%E5%85%B7%E7%AF%87/"}],"tags":[{"name":"映射","slug":"映射","permalink":"https://macongmc.github.io/tags/%E6%98%A0%E5%B0%84/"}],"author":"马聪"},{"title":"LuckyBlog开源搭建教程","slug":"BlogOpen","date":"2020-09-16T16:00:00.000Z","updated":"2023-01-01T15:56:43.830Z","comments":true,"path":"posts/d74d8b76.html","link":"","permalink":"https://macongmc.github.io/posts/d74d8b76.html","excerpt":"","text":"前言之前在B站上发布了个人博客的视频，播放量也破千了，有网友私聊也想要搭建一个这样的博客。经过一段时间的准备，现将本人博客的源代码公布出来，大家只需要根据以下的步骤，即可快速搭建一个漂亮完善的博客。 0x01 LuckyBlog 介绍上一个LuckyBlog版本发布于2020年的9月份，是在 洪卫の博客 基础上进行修改的。自从发布以来有很多网友都私信搭建了博客，同时也发现了旧版本中存在的一些问题需要解决，例如：搜索框不适配XML代码搜索，部分图片失效，代码块问题以及各种小问题。现在将最新的LuckyBlog版本代码发布出来，修复改进了不少的BUG，使其更加稳定运行。同时完善了博客的基础功能，例如：音乐、视频、相册、百宝箱等页面。同时增加了不少的新功能，例如：适配Hexo5.x、黑白天浏览模式、仿Windows页面，站点统计等。 博客演示地址：http://luckyzmj.cn/ 开源项目地址：https://github.com/LuckyZmj/LuckyBlog 主题特性 简单漂亮，文章内容美观易读 Material Design 设计 响应式设计，博客在桌面端、平板、手机等设备上均能很好的展现 首页轮播文章及每天动态切换 Banner 图片 瀑布流式的博客文章列表（文章无特色图片时会有 24 张漂亮的图片代替） 时间轴式的归档页 词云的标签页和雷达图的分类页 丰富的关于我页面（包括关于我、文章统计图、我的项目、我的技能、相册等） 可自定义的数据的友情链接页面 支持文章置顶和文章打赏 支持 MathJax TOC 目录，优化了目录显示效果 可设置复制文章内容时追加版权信息 可设置阅读文章时做密码验证 Gitalk、Gitment、Valine 和 Disqus 评论模块（推荐使用 Valine） 集成了不蒜子统计、谷歌分析（Google Analytics）和文章字数统计等功能 支持在首页的音乐播放和视频播放功能 修改了原主题以及基础主题中的一些BUG 加入图片懒加载功能，在根目录配置文件开启和关闭 增加留言板功能 在关于板块,加入简历功能页 增加完善音乐、相册、视频等功能页面 支持emoji表情，用markdown emoji语法书写直接生成对应的能跳跃的表情 增加网站运行时间显示 增加live2d 动漫人物模型 整体替换Banner图片和文章特色图片 增加实用的快捷导航栏功能 修改了一些控件的参数以及部分样式 优化了代码显示块的效果 增加页面樱花飘落动效 增加鼠标点击烟花爆炸动效 增加页面雪花飘落动效 增加博客白云背景效果 增加天气接口控件 加入鼠标点击文字特效 增加DaoVoice在线聊天插件 增加博客代码、图片压缩功能 增加黑白天浏览模式功能 增加仿Windows功能 增加站点统计功能 增加留言版一言功能 其他 0x02 LuckyBlog 安装1. 安装GitGit是目前世界上最先进的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。Git的作用是将本地的网页文件传到github上。 Git下载地址 Git教程 windows： 到git官网上下载.exe文件,Download git,安装选项全部默认即可。 2. 安装node.jsHexo是基于node.js编写的，所以需要安装一下node.js和里面的npm工具。 windows： 到Node.js官网下载.exe文件，安装选项全部默认。安装好之后，按Win+R打开cmd命令提示符，输入node -v和npm -v，若出现版本号，则说明安装成功。 3. 添加npm国内源使用阿里的国内镜像进行加速下载 npm config set registry https://registry.npm.taobao.org 4. 安装Hexo前面git和nodejs安装好后，就可以安装hexo了，你可以先创建一个文件夹MyBlog，用来存放自己的博客文件，然后cd到这个文件夹下（或者在这个文件夹下直接鼠标右键git bash打开）。 比如我的博客文件都存放在C:\\MyBlog目录下。 在该目录下右键点击Git Bash Here，打开git的控制台窗口，以后我们所有的操作都在git控制台进行，就不用Windows自带的cmd了。 定位到该目录下，输入npm install -g hexo-cli安装Hexo。可能会有几个报错，不用理会。 npm install -g hexo-cli 安装完后输入hexo -v验证是否安装成功。 接下来初始化一下hexo,即初始化我们的博客网站。例如我的在C:\\MyBlog文件夹下的命令行中，输入hexo init初始化文件夹 hexo init 新建完成后，指定文件夹MyBlog目录下有： node_modules: 依赖包 public：存放生成的页面 scaffolds：生成文章的一些模板 source：用来存放你的文章 themes：主题** _config.yml: 博客的配置文件** 到此为止，本地的Hexo基础环境搭建完成了。 5. 安装LuckyBlog下载源代码到本地文件下 git clone https://github.com/LuckyZmj/LuckyBlog.git 将下载好的LuckyBlog全部复制到MyBlog目录下，如果复制过程中出现重复文件，点击替换。 最后使用 npm i 或者 npm install 安装依赖环境包即可。 如果安装依赖环境出错，可以参考这篇文章。 最后执行 hexo clean 和 hexo s -g 启动Hexo本地预览，即可看到效果。 到此为止LuckyBlog安装完成，接下来就是个性化设置了。 0x03 LuckyBlog 个性化 注意！注意！注意！在阅读以下博客个性化之前，最好希望大家有Hexo博客配置主题的基础。如果是完全小白，建议去网上搜索学习相关Hexo搭建博客的过程，另外去B站上也有很多视频教程。博客个性化是需要大家有耐心的，因为每个人的操作不同，在配置过程中可能会遇到一些不可预期的问题，希望大家可以克服这些困难，如有需要帮助，也可以私信博主帮助大家解决问题。 1. 修改部署平台编辑根目录下的配置文件MyBlog/_config.yml，找到如下内容并修改 deploy: - type: git repo: git@github.com:LuckyZmj/LuckyZmj.github.io.git # 替换为你的部署平台地址 branch: master 2. 修改网站信息编辑根目录下的配置文件MyBlog/_config.yml，找到如下内容并修改 # Site title: Luckey subtitle: 'Luckeyの博客' description: '本科 | 计算机科学与技术 | 网络安全' keywords: 'luckyzmj 计算机 网络安全 渗透测试' # 博客网站关键词 author: Luckey # 博主名称 language: zh-CN timezone: '' # URL ## If your site is put in a subdirectory, set url as 'http://example.com/child' and root as '/child/' url: http://www.luckyzmj.cn # 更改为你的博客地址 root: / # permalink: :year/:month/:day/:title/ permalink: posts/:abbrlink.html # p 是自定义的前缀 abbrlink: alg: crc32 #算法： crc16(default) and crc32 rep: hex #进制： dec(default) and hex permalink_defaults: pretty_urls: trailing_index: true # Set to false to remove trailing 'index.html' from permalinks trailing_html: true # Set to false to remove trailing '.html' from permalinks 3. 修改博客头像编辑主题目录下的配置文件MyBlog/themes/matery/_config.yml，找到如下内容并修改 # Configure website favicon and LOGO # 将以下改为自己的头像链接即可 favicon: https://s1.ax1x.com/2020/05/17/YR20js.jpg logo: https://s1.ax1x.com/2020/05/17/YRWsYT.png 4. 修改留言板简介演示效果如下： 编辑 /MyBlog/contact/index.md，修改你想要内容即可 --- title: contact date: 2019-10-25 00:00:00 type: \"contact\" layout: \"contact\" --- ## 畅所欲言 --- 在这里可以留下你的足迹，欢迎在下方留言，欢迎交换友链，一起交流学习！ ## 友链 --- Lucky_Meの友链信息 博客名称: Lucky_Meの博客 博客网址: http://luckyzmj.cn 博客头像: https://s1.ax1x.com/2020/05/17/YRWsYT.png 博客介绍: 知识面决定攻击面，知识链决定攻击深度！ 5. 修改音乐列表想要修改自己喜欢的音乐之前，需要先获取音乐列表的id。 以QQ音乐为例：先登录QQ音乐网页版，点击打开自己喜欢的音乐列表，在网页的URL处包含了音乐列表的id，如下图所示 编辑主题目录下的配置文件MyBlog/themes/matery/_config.yml，找到如下内容并修改 # 默认是博主的QQ音乐的id，大家可以改为自己音乐喜欢列表的id # 更新完id，就可以同步加载自己喜欢的列表音乐了 # Whether to display the musics. # 是否在首页显示音乐. music: enable: true title: #非吸底模式有效 enable: true show: 听听音乐 autoHide: true # hide automaticaly server: tencent #require music platform: netease, tencent, kugou, xiami, baidu type: playlist #require song, playlist, album, search, artist id: 1776127550 #require song id / playlist id / album id / search keyword fixed: true # 开启吸底模式 autoplay: false # 是否自动播放 theme: '#42b983' loop: 'all' # 音频循环播放, 可选值: 'all', 'one', 'none' order: 'random' # 音频循环顺序, 可选值: 'list', 'random' preload: 'auto' # 预加载，可选值: 'none', 'metadata', 'auto' volume: 0.7 # 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效 listFolded: true # 列表默认折叠 hideLrc: true # 隐藏歌词 # Whether to display the musics. # 单独的音乐页面. musics: enable: true title: #非吸底模式有效 enable: true show: 听听音乐 server: tencent #require music platform: netease, tencent, kugou, xiami, baidu type: playlist #require song, playlist, album, search, artist id: 1776127550 #require song id / playlist id / album id / search keyword fixed: false # 开启吸底模式 autoplay: true # 是否自动播放 theme: '#42b983' loop: 'all' # 音频循环播放, 可选值: 'all', 'one', 'none' order: 'random' # 音频循环顺序, 可选值: 'list', 'random' preload: 'auto' # 预加载，可选值: 'none', 'metadata', 'auto' volume: 0.7 # 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效 listFolded: false # 列表默认折叠 listMaxHeight: \"525px\" #列表最大高度 6. 绑定 Valine 评论编辑主题目录下的配置文件MyBlog/themes/matery/_config.yml，找到如下内容并修改 # Valine 评论模块的配置，默认为不激活，如要使用，就请激活该配置项，并设置 appId 和 appKey. valine: enable: true appId: Ucrxxxxxxxxxxxxxxxx-xxxxsz # 自行注册valine获取 appKey: zPsLxxxxxxxxxxxxxxerLmd # 自行注册valine获取 notify: true verify: true visitor: true avatar: 'monsterid' # Gravatar style : mm/identicon/monsterid/wavatar/retro/hide pageSize: 10 placeholder: '留下你的足迹..' # Comment Box placeholder background: /medias/comment_bg.png count: true enableQQ: 16463223 # 改为自己的QQ号 recordIP: true requiredFields: - nick - mail guest_info: - nick - mail - link master: - 46606772953bed0812789d6dc955614e # md5加密后的博主邮箱 metaPlaceholder: # 输入框的背景文字 nick: 昵称/QQ号(必填) mail: 邮箱(必填) link: 网址(https://) lang: zh-CN tagMeta: # The String Array of Words to show Flag.[Just Only xCss Style mode] - 博主 - 小伙伴 - 访客 friends: # The MD5 String Array of friends Email to show friends Flag.[Just Only xCss Style mode] - cb3e577ff029d6073400d5557effd41f - 7. 绑定 DaoVoice 在线聊天编辑主题目录下的配置文件MyBlog/themes/matery/_config.yml，找到如下内容并修改 daovoice: enable: true app_id: 4xxxxxxxe #DaoVoice中的app_id 8. 快捷导航页面个性化编辑文件MyBlog/source/tools/index.html，以下简单标记出几处，还有其他涉及到博客信息的内容都需要改为你自己的博客信息即可。 9. 添加友情链接编辑文件MyBlog/suorce/_data/friends.json，按如下格式添加友情 [ { \"avatar\": \"https://s1.ax1x.com/2020/05/17/YRWsYT.png\", \"name\": \"Luckey\", \"introduction\": \"越努力，越幸运\", \"url\": \"http://www.luckyzmj.cn\", \"title\": \"访问主页\" },{ \"avatar\": \"https://sunhwee.com/hwsun.jpg\", \"name\": \"洪卫の博客\", \"introduction\": \"UESTC CVer\", \"url\": \"http://sunhwee.com\", \"title\": \"访问主页\" } ] 10. 添加相册比如你的图片上传图床后，链接地址如下 https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed/galleries/璀璨星空/01.jpg https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed/galleries/璀璨星空/02.jpg https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed/galleries/动漫风景/01.jpg https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed/galleries/动漫风景/02.jpg ... 首先提取出图片链接公共的部分，作为图床地址 https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed/galleries/ 然后再提取图片地址中不同的部分，作为图片地址 璀璨星空/01.jpg 璀璨星空/02.jpg 动漫风景/01.jpg 动漫风景/03.jpg ... 具体怎么分割根据你自己图床的链接格式而定，以上为我的github图床格式为例。 将相册图床的地址改为你自己的图床地址，需要更改两处文件 # 例如我的图床地址为： https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed/galleries/ themes/matery/layout/galleries.ejs themes/matery/layout/gallerie.ejs 为每个相册添加链接地址，在根目录/source/List/galleries/下新建 相册名称 文件夹，并在该文件夹下新建 index.md 最后，在根目录/source/_data/galleries.json中添加图片链接，格式如下, [ { \"name\": \"璀璨星空\", \"cover\": \"璀璨星空/01.jpg\", \"description\": \"璀璨星空\", \"photos\": [ \"璀璨星空/01.jpg\", \"璀璨星空/02.jpg\", \"璀璨星空/03.jpg\", \"璀璨星空/04.jpg\", \"璀璨星空/05.jpg\", \"璀璨星空/06.jpg\", \"璀璨星空/07.jpg\", \"璀璨星空/08.jpg\", \"璀璨星空/09.jpg\", \"璀璨星空/10.jpg\", \"璀璨星空/11.jpg\", \"璀璨星空/12.jpg\", \"璀璨星空/13.jpg\", \"璀璨星空/14.jpg\", \"璀璨星空/15.jpg\", \"璀璨星空/16.jpg\" ] }, { \"name\": \"动漫风景\", \"cover\": \"动漫风景/01.jpg\", \"description\": \"动漫风景\", \"photos\": [ \"动漫风景/01.jpg\", \"动漫风景/02.jpg\", \"动漫风景/03.jpg\", \"动漫风景/04.jpg\", \"动漫风景/05.jpg\", \"动漫风景/06.jpg\", \"动漫风景/07.jpg\", \"动漫风景/08.jpg\", \"动漫风景/09.jpg\", \"动漫风景/10.jpg\", \"动漫风景/11.jpg\", \"动漫风景/12.jpg\", \"动漫风景/13.jpg\", \"动漫风景/14.jpg\", \"动漫风景/15.jpg\", \"动漫风景/16.jpg\" ] } ] 11. 站点统计功能站点统计的数据来源于百度统计,当你的网站被百度收录后就会在百度统计中出现数据，具体效果如下： 由于博客的统计页面数据不能直接从百度站点中调用，因此需要自行从百度站点中将相应数据填入博客站点统计页面的源代码文件中，个人建议每隔一个月手动更新一次数据。 打开MyBlog\\themes\\matery\\layout\\census.ejs文件，将百度统计中的数据填入源代码中，修改代码如下： 11. 仿Windows个性化仿Windows页面是采用YLUI实现的，YLUI提供了社区版本供大家学习使用，具体效果如下： 大家可以查看YLUI官方的开发文档进行开发，有不懂的可以加官方的QQ群：191372634 进行讨论。 12. 博客动漫风格背景图因为在上一个LuckyBlog版本发布的网站风格是偏向动漫风格的，如果大家喜欢动漫风格，只需要替换以下配置即可。 博客每日轮播图： 以下链接图片全部下载保存到MyBlog\\themes\\matery\\source\\medias\\banner中，以0~7.jpg的文件名格式命名即可。 https://cdn.jsdelivr.net/gh/LuckyZmj/LuckyBlog@master/themes/matery/source/medias/banner/0.jpg https://cdn.jsdelivr.net/gh/LuckyZmj/LuckyBlog@master/themes/matery/source/medias/banner/1.jpg https://cdn.jsdelivr.net/gh/LuckyZmj/LuckyBlog@master/themes/matery/source/medias/banner/2.jpg https://cdn.jsdelivr.net/gh/LuckyZmj/LuckyBlog@master/themes/matery/source/medias/banner/3.jpg https://cdn.jsdelivr.net/gh/LuckyZmj/LuckyBlog@master/themes/matery/source/medias/banner/4.jpg https://cdn.jsdelivr.net/gh/LuckyZmj/LuckyBlog@master/themes/matery/source/medias/banner/5.jpg https://cdn.jsdelivr.net/gh/LuckyZmj/LuckyBlog@master/themes/matery/source/medias/banner/6.jpg https://cdn.jsdelivr.net/gh/LuckyZmj/LuckyBlog@master/themes/matery/source/medias/banner/7.jpg 无文章特色背景图： 打开主题配置文件MyBlog\\themes\\matery\\_config.yml，修改替换如下代码即可： # The post featured images that needs to be displayed when there is no image. # 无文章特色图片时需要显示的文章特色图片. featureImages: - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/01.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/02.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/04.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/06.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/07.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/10.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/11.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/12.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/09.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/14.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/15.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/16.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E4%BA%8C%E6%AC%A1%E5%85%83%E9%A3%8E/06.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/02.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/03.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/04.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/07.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/08.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/11.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/10.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/09.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/12.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/13.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/14.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/16.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/15.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/11.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/09.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/03.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/08.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/03.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/13.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/01.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/05.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/14.jpg - https://cdn.jsdelivr.net/gh/LuckyZmj/imgbed@master/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/01.jpg 0x04 更多内容优化以上简单介绍了 LuckyBlog 中一些要修改的个性化地方，其他更详细的优化参考其他关于Matery的文章。以下几篇文章都是基于hexo-theme-matery主题优化的教程，大家如果遇到问题，可以参考其中的方法。 个人博客搭建 Hexo+Github博客搭建完全教程 hexo-theme-matery作者教程 Hexo+github搭建博客(超级详细版，精细入微) hexo（matery）背景、滚动条优化+增加点击跳评论","categories":[{"name":"博客篇","slug":"博客篇","permalink":"https://macongmc.github.io/categories/%E5%8D%9A%E5%AE%A2%E7%AF%87/"}],"tags":[{"name":"hexo-blog-lucky","slug":"hexo-blog-lucky","permalink":"https://macongmc.github.io/tags/hexo-blog-lucky/"},{"name":"博客搭建教程","slug":"博客搭建教程","permalink":"https://macongmc.github.io/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"}],"author":"luckyzmj"},{"title":"文字背景粒子特效","slug":"jQuery+CSS3","date":"2020-03-26T16:00:00.000Z","updated":"2022-08-02T09:39:28.153Z","comments":true,"path":"posts/4b3510a4.html","link":"","permalink":"https://macongmc.github.io/posts/4b3510a4.html","excerpt":"","text":"前言一款jQuery+CSS3的文字背景粒子动画特效，一共6种粒子效果，每种文字背景的粒子效果都不同，有漂浮的有坠落的等等。 0x001 特效演示 This is fires This is lines This is hearts This is bubbles This is confetti This is sunbeams .particletext { } .fire > .particle { position: absolute; background-color: rgba(255, 193, 7, 0.5); border-radius: 40px; border-top-right-radius: 0px; -webkit-animation: fires 0.8s linear infinite; animation: fires 0.8s linear infinite; -webkit-transform: rotate(-45deg); transform: rotate(-45deg); opacity: 0; } /*css keyframes 动画*/ @-webkit-keyframes fires { 0% { -webkit-transform: rotate(-70deg) translateY(0%); transform: rotate(-70deg) translateY(0%); } 25% { -webkit-transform: rotate(-20deg) translateY(-5%); transform: rotate(-20deg) translateY(-5%); opacity: 1; } 50% { -webkit-transform: rotate(-70deg) translateY(-10%); transform: rotate(-70deg) translateY(-10%); } 75% { -webkit-transform: rotate(-20deg) translateY(-20%); transform: rotate(-20deg) translateY(-20%); } 100% { -webkit-transform: rotate(-70deg) translateY(-40%); transform: rotate(-70deg) translateY(-40%); opacity: 1; } } @keyframes fires { 0% { -webkit-transform: rotate(-70deg) translateY(0%); transform: rotate(-70deg) translateY(0%); } 25% { -webkit-transform: rotate(-20deg) translateY(-5%); transform: rotate(-20deg) translateY(-5%); opacity: 1; } 50% { -webkit-transform: rotate(-70deg) translateY(-10%); transform: rotate(-70deg) translateY(-10%); } 75% { -webkit-transform: rotate(-20deg) translateY(-20%); transform: rotate(-20deg) translateY(-20%); } 100% { -webkit-transform: rotate(-70deg) translateY(-40%); transform: rotate(-70deg) translateY(-40%); opacity: 1; } } function fire() { $.each($(\".particletext.fire\"), function(){ var firecount = ($(this).width()/50)*20; for(var i = 0; i .particle { position: absolute; background-color: rgba(244, 67, 54, 0.5); -webkit-animation: lines 3s linear infinite; animation: lines 3s linear infinite; } @-webkit-keyframes lines { 0%, 50%, 100% { -webkit-transform: translateY(0%); transform: translateY(0%); } 25% { -webkit-transform: translateY(100%); transform: translateY(100%); } 75% { -webkit-transform: translateY(-100%); transform: translateY(-100%); } } @keyframes lines { 0%, 50%, 100% { -webkit-transform: translateY(0%); transform: translateY(0%); } 25% { -webkit-transform: translateY(100%); transform: translateY(100%); } 75% { -webkit-transform: translateY(-100%); transform: translateY(-100%); } } function lines() { $.each($(\".particletext.lines\"), function(){ var linecount = ($(this).width()/50)*10; for(var i = 0; i .particle { opacity: 0; position: absolute; background-color: #cc2a5d; -webkit-animation: hearts 3s ease-in infinite; animation: hearts 3s ease-in infinite; } .hearts > .particle:before,.hearts > .particle:after { position: absolute; content: ''; border-radius: 100px; top: 0px; left: 0px; width: 100%; height: 100%; background-color: #cc2a5d; } .hearts > .particle:before { -webkit-transform: translateX(-50%); transform: translateX(-50%); } .hearts > .particle:after { -webkit-transform: translateY(-50%); transform: translateY(-50%); } @-webkit-keyframes hearts { 0% { opacity: 0; -webkit-transform: translate(0, 0%) rotate(45deg); transform: translate(0, 0%) rotate(45deg); } 20% { opacity: 0.8; -webkit-transform: translate(0, -20%) rotate(45deg); transform: translate(0, -20%) rotate(45deg); } 100% { opacity: 0; -webkit-transform: translate(0, -1000%) rotate(45deg); transform: translate(0, -1000%) rotate(45deg); } } @keyframes hearts { 0% { opacity: 0; -webkit-transform: translate(0, 0%) rotate(45deg); transform: translate(0, 0%) rotate(45deg); } 20% { opacity: 0.8; -webkit-transform: translate(0, -20%) rotate(45deg); transform: translate(0, -20%) rotate(45deg); } 100% { opacity: 0; -webkit-transform: translate(0, -1000%) rotate(45deg); transform: translate(0, -1000%) rotate(45deg); } } function hearts() { $.each($(\".particletext.hearts\"), function(){ var heartcount = ($(this).width()/50)*5; for(var i = 0; i .particle { opacity: 0; position: absolute; background-color: rgba(33, 150, 243, 0.5); -webkit-animation: bubbles 3s ease-in infinite; animation: bubbles 3s ease-in infinite; border-radius: 100%; } @-webkit-keyframes bubbles { 0% { opacity: 0; } 20% { opacity: 1; -webkit-transform: translate(0, -20%); transform: translate(0, -20%); } 100% { opacity: 0; -webkit-transform: translate(0, -1000%); transform: translate(0, -1000%); } } @keyframes bubbles { 0% { opacity: 0; } 20% { opacity: 1; -webkit-transform: translate(0, -20%); transform: translate(0, -20%); } 100% { opacity: 0; -webkit-transform: translate(0, -1000%); transform: translate(0, -1000%); } } function bubbles() { $.each($(\".particletext.bubbles\"), function(){ var bubblecount = ($(this).width()/50)*10; for(var i = 0; i .particle { opacity: 0; position: absolute; -webkit-animation: confetti 3s ease-in infinite; animation: confetti 3s ease-in infinite; } .confetti > .particle.c1 { background-color: rgba(76, 175, 80, 0.5); } .confetti > .particle.c2 { background-color: rgba(156, 39, 176, 0.5); } @-webkit-keyframes confetti { 0% { opacity: 0; -webkit-transform: translateY(0%) rotate(0deg); transform: translateY(0%) rotate(0deg); } 10% { opacity: 1; } 35% { -webkit-transform: translateY(-800%) rotate(270deg); transform: translateY(-800%) rotate(270deg); } 80% { opacity: 1; } 100% { opacity: 0; -webkit-transform: translateY(2000%) rotate(1440deg); transform: translateY(2000%) rotate(1440deg); } } @keyframes confetti { 0% { opacity: 0; -webkit-transform: translateY(0%) rotate(0deg); transform: translateY(0%) rotate(0deg); } 10% { opacity: 1; } 35% { -webkit-transform: translateY(-800%) rotate(270deg); transform: translateY(-800%) rotate(270deg); } 80% { opacity: 1; } 100% { opacity: 0; -webkit-transform: translateY(2000%) rotate(1440deg); transform: translateY(2000%) rotate(1440deg); } } function confetti() { $.each($(\".particletext.confetti\"), function(){ var confetticount = ($(this).width()/50)*10; for(var i = 0; i .particle { position: absolute; background-color: rgba(253, 216, 53, 0.5); -webkit-animation: sunbeams 3s linear infinite; animation: sunbeams 3s linear infinite; } @-webkit-keyframes sunbeams { 0% { -webkit-transform: translateY(40%) rotate(0deg); transform: translateY(40%) rotate(0deg); } 50% { -webkit-transform: translateY(-40%) rotate(180deg); transform: translateY(-40%) rotate(180deg); } 100% { -webkit-transform: translateY(40%) rotate(360deg); transform: translateY(40%) rotate(360deg); } 0%,14%,17%,43%,53%,71%,80%,94%,100% { opacity: 0; } 6%,15%,24%,28%,48%,55%,78%,82%,99% { opacity: 1; } } @keyframes sunbeams { 0% { -webkit-transform: translateY(40%) rotate(0deg); transform: translateY(40%) rotate(0deg); } 50% { -webkit-transform: translateY(-40%) rotate(180deg); transform: translateY(-40%) rotate(180deg); } 100% { -webkit-transform: translateY(40%) rotate(360deg); transform: translateY(40%) rotate(360deg); } 0%,14%,17%,43%,53%,71%,80%,94%,100% { opacity: 0; } 6%,15%,24%,28%,48%,55%,78%,82%,99% { opacity: 1; } } function sunbeams() { $.each($(\".particletext.sunbeams\"), function(){ var linecount = ($(this).width()/50)*10; for(var i = 0; i","categories":[{"name":"前端篇","slug":"前端篇","permalink":"https://macongmc.github.io/categories/%E5%89%8D%E7%AB%AF%E7%AF%87/"}],"tags":[{"name":"jQuery+CSS3","slug":"jQuery-CSS3","permalink":"https://macongmc.github.io/tags/jQuery-CSS3/"},{"name":"粒子特效","slug":"粒子特效","permalink":"https://macongmc.github.io/tags/%E7%B2%92%E5%AD%90%E7%89%B9%E6%95%88/"}],"author":"Luckey"},{"title":"PicGo+GitHub 图床搭建","slug":"PicGo-GitHub","date":"2020-03-14T16:00:00.000Z","updated":"2023-01-01T15:51:51.365Z","comments":true,"path":"posts/7a46f93c.html","link":"","permalink":"https://macongmc.github.io/posts/7a46f93c.html","excerpt":"","text":"前言用GitHub搭建图床，在很久之前我就有了解，但由于市面上有挺多免费的图床，比如我之前一直在用的 路过图床，所以一直懒得动手搭建GitHub图床。一直到前两天我在完善博客的相册时，发现 路过图床 免费版的有这么多限制，比如：每小时限制上传50张图片，每天限制上传100张图片，而且免费版用户的存储容量貌似不过300M，这才意识到有一个自己的GitHub图床是多么重要。 0x001 PicGO 介绍PicGo是一款图片上传工具，目前支持 SM.MS图床、腾讯云COS、GitHub图床、七牛图床、Imgur图床、阿里云OSS、又拍云图床，未来将支持更多图床。 在支持的这些图床中，SM.MS和Imgur有免费版和收费版，免费版的肯定有很多的使用限制，比如每小时限制上传次数，限制用户的上传容量等等；腾讯云COS、阿里云、有拍云都是要收费使用的；七牛云貌似前期使用免费，后期又要收费才能使用，就剩下的GitHub才是免费且最可靠的。 PicGo源项目GitHub地址已给出，但是去GitHub下载速度非常慢，这里额外提供一个蓝奏云的快速下载地址。 GitHub地址：https://github.com/Molunerfinn/PicGo 蓝奏云地址：https://luckyzmj.lanzous.com/id3e0id 0x002 GitHub 图床1. 创建GitHub图床仓库首先需要有一个登录GitHub的账号，没有的话去GitHub官网注册一个 创建一个新的图床仓库，点击右上角的New repository 填写如下配置信息，然后Create创建仓库 2. 获取GitHub token值点击右上的头像，选择设置Setting 点击选择Developer settings 点击 Generate New token 填写如下配置信息，只要勾选repo选项即可，然后页面拉到底部点击Generate token 即可 此时会跳转到带有token的页面，将token值复制记录下来，之后用PicGo绑定GitHub图床时会利用到 0x003 PicGo 配置1. 绑定GitHub图床首先下载安装好PicGo软件，然后在右列表找到GitHub图床配置 1. 设定仓库名(必填)： 按照“GitHub账户名/仓库名的格式填写”，比如我的是：Luckyzmj/imgbed 2. 设定分支名(必填)： 仓库分支名填写”master”或者”main”，视情况而定。因为GitHub 官方表示,从2020年10月1日起,在该平台上创建的所有新的源代码仓库将默认被命名为”main”,而不是原先的”master”。 3. 设定Token(必填)： 将之前步骤的Token值复制粘贴到这里 4. 指定存储路径： 这个选项可以为空，如果想将图片上传到仓库的指定目录下，可以填写目录名加/，比如我的imgbed仓库下有个posts文件夹，需设置为 posts/ 5. 设定自定义域名： 这里统一用jsdelivr的CDN加速域名，在上传图片后成功后，PicGo会将“自定义域名+上传的图片名”生成的访问链接 自定义域名格式：https://cdn.jsdelivr.net/gh/GitHub账户名/仓库名 以我的格式为例：https://cdn.jsdelivr.net/gh/Luckyzmj/imgbed 配置完全部信息后，点击 设为默认图床，最后点击确定即可 2. 上传图片到图床在上传区上传图片，可支持本地图片上传(可多选图片)、剪贴板上传、URL上传等三种方式。上传图片成功后，选择你想要生成的图片链接格式 在图片区，可以看到成功上传的图片，选择相应的图片进行操作即可 3. PicGo 注意事项如果配置完PicGo后却上传图片失败，可以参考以下方法： 检查自定义域名是否正确 仓库名不要有空格 图片名字不要带有特殊符号，如：%、+、*、空格等 建议开启时间戳重命名，防止图片名字重复 上传图片间歇太短，需在PicGo设置中关闭Server选项 PicGo应用不稳定因素，需重启应用 参考文章 https://blog.csdn.net/sunhwee/article/details/100109956","categories":[{"name":"博客篇","slug":"博客篇","permalink":"https://macongmc.github.io/categories/%E5%8D%9A%E5%AE%A2%E7%AF%87/"}],"tags":[{"name":"PicGo","slug":"PicGo","permalink":"https://macongmc.github.io/tags/PicGo/"},{"name":"GitHub图床","slug":"GitHub图床","permalink":"https://macongmc.github.io/tags/GitHub%E5%9B%BE%E5%BA%8A/"}],"author":"Luckey"},{"title":"阿里云服务器部署Hexo博客","slug":"blog-aliyun","date":"2020-02-26T16:00:00.000Z","updated":"2022-08-02T09:41:43.293Z","comments":true,"path":"posts/19d2a4e6.html","link":"","permalink":"https://macongmc.github.io/posts/19d2a4e6.html","excerpt":"","text":"前言 相信大部分人使用Hexo搭建个人博客都会部署到一些免费的代码托管平台上，但这些免费的平台总是差强人意，比如国外的GitHub平台虽然完全免费，但在国内访问加载速度非常慢，又或者是国内的码云平台免费版有许多功能被阉割掉了，比如不能自定义域名，不能每次自动刷新提交的代码，需要到码云平台上手动刷新，如此一来非常繁琐。 为了有效解决上诉的一些问题，有条件的话，不妨在自己的云服务器上搭建Hexo博客。 效果演示 这是Hexo博客部署到GitHub上的网站测速效果 这是Hexo博客部署到阿里云服务器后的网站测速效果 环境准备 本地环境：Windows 10 云服务器环境：阿里云ECS（CentOS7.x） 开始部署 本地环境搭建1.安装Git 到git官网上下载.exe文件,Download git,安装选项还是全部默认，最后一步添加路径时选择Use Git from the Windows Command Prompt。 Git下载地址 Git教程 2.安装Nodejs 到Node.js官网下载.exe文件，安装选项全部默认。安装好之后，按Win+R打开cmd命令提示符，输入node -v和npm -v，若出现版本号，则说明安装成功。 使用npm阿里的国内镜像进行加速下载 npm config set registry https://registry.npm.taobao.org 4.安装Hexo 先创建一个文件夹MyBlog，用来存放自己的博客文件，然后cd到这个文件夹下（或者在这个文件夹下直接右键git bash here打开）。 定位到该目录下，输入npm install -g hexo-cli安装Hexo。可能会有几个报错，不用理会。 npm install -g hexo-cli 安装完后输入hexo -v,若出现版本号则，说明安装成功。 接下来初始化一下hexo,即初始化我们的博客，输入hexo init初始化文件夹 hexo init MyBlog 新建完成后，指定文件夹MyBlog目录下有： node_modules: 依赖包 public：存放生成的页面 scaffolds：生成文章的一些模板 source：用来存放你的文章 themes：主题** _config.yml: 博客的配置文件** 输入hexo g生成静态网页，然后输入hexo s打开本地服务器预览 hexo g hexo s 生成ssh公钥在本地桌面点击右键Git Bash Here打开Git终端，执行如下命令`,一路回车 ssh-keygen -t rsa 这个时候它会告诉你已经生成了.ssh的文件夹。在git bash中输入 cat ~/.ssh/id_rsa.pub 输出的内容就是公钥信息了 阿里云服务器环境搭建安装Git yum install git 创建Git账户 adduser git 添加账户权限 chmod 740 /etc/sudoers vim /etc/sudoers 找到 ## Allow root to run any commands anywhere root ALL=(ALL) ALL 添加以下内容 git ALL=(ALL) ALL 保存退出并改回权限 chmod 400 /etc/sudoers 设置git账户密码 sudo passwd git 切换至git用户，创建 ~/.ssh 文件夹和 ~/.ssh/authorized_keys 文件，并赋予相应的权限 su git mkdir ~/.ssh vim ~/.ssh/authorized_keys # 然后将win10中生成的id_rsa.pub文件中的公钥复制到authorized_keys chmod 600 /home/git/.ssh/authorized_keys chmod 700 /home/git/.ssh 在本地Git终端中测试是否能免密登录git，其中SERVER为填写自己的云主机IP，执行输入yes后不用密码就说明好了 ssh -v git@SERVER 创建目录 #repo作为为Git仓库目录 mkdir /var/repo chown -R git:git /var/repo chmod -R 755 /var/repo #hexo作为网站根目录 mkdir /var/www/hexo chown -R git:git /var/www/hexo chmod -R 755 /var/www/hexo 然后创建一个裸的 Git 仓库 cd var/repo git init --bare hexoBlog.git 创建一个新的 Git 钩子，用于自动部署 在 /var/repo/hexoBlog.git 下，有一个自动生成的 hooks 文件夹。我们需要在里边新建一个新的钩子文件 post-receive。 vim /var/repo/hexoBlog.git/hooks/post-receive 按 i 键进入文件的编辑模式，在该文件中添加两行代码（将下边的代码粘贴进去)，指定 Git 的工作树（源代码）和 Git 目录（配置文件等） #!/bin/bash git --work-tree=/var/www/hexo --git-dir=/var/repo/hexoBlog.git checkout -f 然后，按 Esc 键退出编辑模式，输入”:wq” 保存退出。 修改文件权限，使得其可执行 chown -R git:git /var/repo/hexoBlog.git/hooks/post-receive chmod +x /var/repo/hexoBlog.git/hooks/post-receive 到此为止 Git 仓库就搭建完成了。 阿里云服务器配置Nginx用宝塔面板来一键部署Nginx Linux面板6.0安装命令(暂时仅兼容Centos7.x，其它系统版本请安装5.9稳定版)： yum install -y wget &amp;&amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; bash install.sh Linux面板6.0升级专业版 curl http://download.bt.cn/install/update6.sh|bash 安装完成后会显示面板后台地址·账号·密码。打开面板后台地址登陆面板，选择Nginx的部署方案，静静等待部署。 部署完成，点击网站-添加站点-输入域名(没有域名的输入自己的IP地址)-底部的PHP版本选择”纯静态”-提交。 网站创建完成后点击设置-配置文件 server { listen 80; # server_name 填写自己的域名 server_name luckyzmj.cn blog.luckyzmj.cn; index index.php index.html index.htm default.php default.htm default.html; # 这里root填写自己的网站根目录，修改为/var/www/hexo root /var/www/hexo; -保存 点击设置-网站目录，修改为/var/www/hexo ，保存 重启宝塔面板服务 service bt restart 本地Hexo部署到阿里云服务器进入到本地Hexo博客的文件夹MyBlog,右键点击Git Bash Here，输入命令 #定义邮箱(更换为你的邮箱地址就行) git config --global user.email \"you@example.com\" #定义名称(更换自定义一个名称就行) git config --global user.name \"Your Name\" 配置_config.yml,完成自动化部署 打开本地Hexo博客的文件夹MyBlog文件夹下的_config.yml, 找到deploy deploy: type: git #server改为你的服务IP地址或解析后的域名 #例如我改为repo: git@luckyzmj.cn:/var/repo/blog.git repo: git@server:/var/repo/blog.git branch: master 保存后，即可测试部署 再进入到本地Hexo博客的文件夹MyBlog,右键点击Git Bash Here，输入命令 hexo clean hexo g -d 不报错说明完成，打开浏览器输入你的域名或ip地址就可以看到你部署的Hexo博客了。 到此为止，我们已经成功部完成，并且访问自己的服务器端比访问Github快多了。 小贴士 在部署过程中，执行 hexo d发现部署老是出错，什么权限不允许之类的，这里我们需要检查我们在上述的git操作部署是否使用了git用户操作，若是没有，需要给相应的目录更改用户组 使用 chown -R git:git /var/repo/ 这条命令递归的将repo目录及其子目录用户组设置为git。 同时使用 chown -R git:git /var/www/hexo 这样即可解决此类问题。 还有一个问题就是绑定域名后不能访问。原因是在国内任何域名只要绑定到国内的服务器主机上都必须去工信部和公安部备案完后才能正常使用。如果是港澳台的服务器或者是国外的服务器则可以不需要备案。 参考文章 https://blog.csdn.net/weixin_33907511/article/details/91398208?utm_source=distribute.pc_relevant.none-task","categories":[{"name":"博客篇","slug":"博客篇","permalink":"https://macongmc.github.io/categories/%E5%8D%9A%E5%AE%A2%E7%AF%87/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://macongmc.github.io/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"https://macongmc.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"阿里云","slug":"阿里云","permalink":"https://macongmc.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"}],"author":"Luckey"},{"title":"个人博客搭建","slug":"Blog","date":"2019-08-27T03:41:03.000Z","updated":"2022-09-01T02:08:57.599Z","comments":true,"path":"posts/e3e08109.html","link":"","permalink":"https://macongmc.github.io/posts/e3e08109.html","excerpt":"","text":"0x001 效果演示 0x002 简单介绍 前前后后大概花了一周多的时间，目前个人博客已经完善的差不多了，现在写个文章做个阶段总结，后续如果有更新的地方，会及时补充。本博客基于Hexo框架，采用hexo-theme-matery主题，在这里非常感谢作者洪卫的hexo-blog-fly博客开源，极大简化了构建博客的工作量和复杂度。在此开源博客的基础上做了改进，修复了一些bug，顺利搭建完成了我的个人博客。大家对此主题有兴趣的可以下载源代码，搭建属于自己的个性化博客。 个人博客 演示：http://luckyzmj.cn 0x003 Hexo 初级搭建 1. 安装GitGit是目前世界上最先进的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。Git的作用是将本地的网页文件传到github上。 Git下载地址 Git教程 windows： 到git官网上下载.exe文件,Download git,安装选项还是全部默认，最后一步添加路径时选择Use Git from the Windows Command Prompt。 2. 安装node.jsHexo是基于node.js编写的，所以需要安装一下node.js和里面的npm工具。 windows： 到Node.js官网下载.exe文件，安装选项全部默认。安装好之后，按Win+R打开cmd命令提示符，输入node -v和npm -v，若出现版本号，则说明安装成功。 3. 添加npm国内源使用阿里的国内镜像进行加速下载 npm config set registry https://registry.npm.taobao.org 4. 安装Hexo前面git和nodejs安装好后，就可以安装hexo了，你可以先创建一个文件夹MyBlog，用来存放自己的博客文件，然后cd到这个文件夹下（或者在这个文件夹下直接右键git bash打开）。 比如我的博客文件都存放在E:\\MyBlog目录下。 在该目录下右键点击Git Bash Here，打开git的控制台窗口，以后我们所有的操作都在git控制台进行，就不用Windows自带的cmd了。 定位到该目录下，输入npm install -g hexo-cli安装Hexo。可能会有几个报错，不用理会。 npm install -g hexo-cli 安装完后输入hexo -v验证是否安装成功。 到此为止hexo就安装完了。 接下来初始化一下hexo,即初始化我们的网站，输入hexo init初始化文件夹 hexo init MyBlog 新建完成后，指定文件夹MyBlog目录下有： node_modules: 依赖包 public：存放生成的页面 scaffolds：生成文章的一些模板 source：用来存放你的文章 themes：主题** _config.yml: 博客的配置文件** 到此为止，本地的网站配置完成了。 输入hexo g生成静态网页，然后输入hexo s打开本地服务器 hexo g hexo s 5. 注册Github账号创建个人仓库接下来就去注册一个github账号，用来存放我们的网站。 打开https://github.com/，新建一个项目仓库New repository，如下所示： 然后如下图所示，输入自己的项目名字，后面一定要加.github.io后缀，README初始化也要勾上 要创建一个和你用户名相同的仓库，后面加.github.io，只有这样，将来要部署到GitHub page的时候，才会被识别，也就是http://xxxx.github.io，其中xxx就是你注册GitHub的用户名。例如我的：http://LuckyZmj.github.io 6. 生成SSH添加到GitHub生成SSH添加到GitHub，连接Github与本地。右键打开git bash here，然后输入下面命令： git config --global user.name \"注册GitHub用户名\" git config --global user.email \"注册GitHub的邮箱\" 用以下两条，检查一下你有没有输对 git config user.name git config user.email 然后创建SSH,一路回车 ssh-keygen -t rsa -C \"注册GitHub的邮箱\" 这个时候它会告诉你已经生成了.ssh的文件夹。在git bash中输入 cat ~/.ssh/id_rsa.pub 将输出的内容复制到框中，点击确定保存。 打开github，在头像下面点击settings，再点击SSH and GPG keys，新建一个SSH，名字随便取一个都可以，把你的id_rsa.pub里面的信息复制进去。如图： 在git bash输入ssh -T git@github.com，如果如下图所示，出现你的用户名，那就成功了。 ssh -T git@github.com 7. 将hexo部署到GitHub将hexo生成的文章部署到GitHub上，打开博客根目录下的_config.yml文件，这是博客的配置文件，在这里你可以修改与博客配置相关的各种信息。找到如下配置进行修改： deploy: type: git repository: https://github.com/LuckyZmj/LuckyZmj.github.io branch: master repository修改为你自己的github项目地址即可，就是部署时，告诉工具，将生成网页通过git方式上传到你对应的链接仓库中。 这个时候需要先安装deploy-git ，也就是部署的命令,这样你才能用命令部署到GitHub。 npm install hexo-deployer-git --save 然后就可以部署提交到github，过一会儿就可以在http://yourname.github.io 这个网站看到你的博客了 hexo clean hexo generate hexo deploy 其中 hexo clean清除了你之前生成的东西。 hexo generate，生成静态文章，可以用 hexo g缩写 ，hexo deploy部署文章，可以用hexo d缩写 注意deploy时可能要你输入username和password。 8. 写文章和发布文章首先在博客根目录下右键打开git bash here，安装一个扩展npm i hexo-deployer-git。 npm i hexo-deployer-git 然后输入hexo new post \"article title\"，新建一篇文章。 hexo new post \"article title\" 然后打开E:\\MyBlog\\source\\_posts的目录，可以发现下面多了一个文件夹和一个.md文件，一个用来存放你的图片等数据，另一个就是你的文章文件。 另外推荐直接使用有道云编写markdown文章，不仅可以实时预览，还可以快捷的生成markdown语法格式，具体效果如下图所示。 编写完markdown文件后，根目录下输入hexo g生成静态网页，然后输入hexo s可以本地预览效果，最后输入hexo d上传到github上。这时打开你的github.io主页就能看到发布的文章了。 到此为止，Hexo初级搭建就已经完成了。 0x004 Hexo 优化定制 1. Hexo相关目录文件1.1 博客目录构成介绍node_modules是node.js各种库的目录，public是生成的网页文件目录，scaffolds里面就三个文件，存储着新文章和新页面的初始设置，source是我们最常用到的一个目录，里面存放着文章、各类页面、图像等文件，themes存放着主题文件，一般也用不到。 我们平时写文章只需要关注source/_posts这个文件夹就行了。 - node_modules - public - scaffolds - source - _data - _posts - about - archives - categories - friends - tags - themes 1.2 hexo基本配置在文件根目录下的_config.yml，就是整个hexo框架的配置文件了。可以在里面修改大部分的配置。详细可参考官方的配置描述。 1.2.1 网站参数描述title网站标题subtitle网站副标题description网站描述author您的名字language网站使用的语言timezone网站时区。Hexo 默认使用您电脑的时区。时区列表。比如说：America/New_York, Japan, 和 UTC 。 其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。 1.2.2 网址参数描述url网址root网站根目录 permalink文章的永久链接格式permalink_defaults永久链接中各部分的默认值 在这里，你需要把url改成你的网站域名。 permalink，也就是你生成某个文章时的那个链接格式。 比如我新建一个文章叫temp.md，那么这个时候他自动生成的地址就是http://yoursite.com/2018/09/05/temp。 以下是官方给出的示例，关于链接的变量还有很多，需要的可以去官网上查找永久链接 。 参数结果 :year/:month/:day/:title /2019/08/10/hello-world :year-:month-:day-:title.html 2019-08-10-hello-world.html :category/:titlefoo /bar/hello-world 2. 定制主题这里推荐作者洪卫的hexo-blog-fly博客主题，该主题是基于hexo-theme-matery优化的，需要把博客相关信息换成您自己的就可以部署了，极大简化了构建博客的工作量和复杂度。 2.1 简单使用方法 安装Git, 安装nodeJS，安装Hexo 你可以直接fork一份源码到你的仓库，clone到本地博客文件夹内 在本地博客仓库运行npm i命令安装依赖包 直接修改配置信息，改成自己的信息 运行命令hexo clean（清除生成文件），hexo g（生成网页）， hexo s（本地预览），hexo d（部署） 2.2 原主题特性: 简单漂亮，文章内容美观易读 Material Design 设计 响应式设计，博客在桌面端、平板、手机等设备上均能很好的展现 首页轮播文章及每天动态切换 Banner 图片 瀑布流式的博客文章列表（文章无特色图片时会有 24 张漂亮的图片代替） 时间轴式的归档页 词云的标签页和雷达图的分类页 丰富的关于我页面（包括关于我、文章统计图、我的项目、我的技能、相册等） 可自定义的数据的友情链接页面 支持文章置顶和文章打赏 支持 MathJax TOC 目录 可设置复制文章内容时追加版权信息 可设置阅读文章时做密码验证 Gitalk、Gitment、Valine 和 Disqus 评论模块（推荐使用 Gitalk） 集成了不蒜子统计、谷歌分析（Google Analytics）和文章字数统计等功能 支持在首页的音乐播放和视频播放功能 2.3 新增加特性: 修改了原主题的一些很多bug 加入图片懒加载功能，在根目录配置文件开启和关闭 增加留言板功能 在关于板块,加入简历功能页 增加视听[视觉听觉影音]板块 支持emoji表情，用markdown emoji语法书写直接生成对应的能跳跃的表情。 增加网站运行时间显示 增加动漫模型 整体替换Banner图片和文章特色图片 增加分类相册功能 修改了一些控件的参数 修改部分样式,比如: 文章卡片,固定高度,使其不至于因为文章摘要的长短不同导致卡片大小不一使页面布局很不美观,类似的还有友链卡片,优化了页面内容布局,视觉更整齐美观 解决首页文章列表卡片上方 border-radius圆角失效的bug 添加页面樱花飘落动效 添加鼠标点击烟花爆炸动效 加入天气接口控件 加入鼠标点击文字特效 添加页面雪花飘落动效 添加在线聊天插件 调整线聊天插件参数，使之能够随着鼠标滑动位置自适应调整 持续更新… 2.4 切换主题如果想自己动手对hexo-theme-matery优化的话，可以修改Hexo根目录下的 _config.yml的 theme 的值 theme: hexo-theme-matery _config.yml 文件的其它修改建议: 请修改 _config.yml 的 url 的值为你的网站主 URL（如：http://xxx.github.io）。 建议修改两个 per_page 的分页条数值为 6 的倍数，如：12、18 等，这样文章列表在各个屏幕下都能较好的显示。 如果你是中文用户，则建议修改 language 的值为 zh-CN。 2.5 新建分类 categories 页categories 页是用来展示所有分类的页面，如果在你的博客 source 目录下还没有 categories/index.md 文件，那么你就需要新建一个，命令如下： hexo new page \"categories\" 编辑你刚刚新建的页面文件 /source/categories/index.md，至少需要以下内容： --- title: categories date: 2018-09-30 17:25:30 type: \"categories\" layout: \"categories\" --- 2.6 新建标签 tags 页tags 页是用来展示所有标签的页面，如果在你的博客 source 目录下还没有 tags/index.md 文件，那么你就需要新建一个，命令如下： hexo new page \"tags\" 编辑你刚刚新建的页面文件 /source/tags/index.md，至少需要以下内容： --- title: tags date: 2018-09-30 18:23:38 type: \"tags\" layout: \"tags\" --- 2.7 新建关于我 about 页about 页是用来展示关于我和我的博客信息的页面，如果在你的博客 source 目录下还没有 about/index.md 文件，那么你就需要新建一个，命令如下： hexo new page \"about\" 编辑你刚刚新建的页面文件 /source/about/index.md，至少需要以下内容： --- title: about date: 2018-09-30 17:25:30 type: \"about\" layout: \"about\" --- 2.8 新建留言板 contact 页（可选的）contact 页是用来展示留言板信息的页面，前提是已经开启了第三方评论系统才能显示。如果在你的博客 source 目录下还没有 contact/index.md 文件，那么你就需要新建一个，命令如下： hexo new page \"contact\" 编辑你刚刚新建的页面文件 /source/contact/index.md，至少需要以下内容： --- title: contact date: 2018-09-30 17:25:30 type: \"contact\" layout: \"contact\" --- 2.9 新建友情链接 friends 页（可选的）friends 页是用来展示友情链接信息的页面，如果在你的博客 source 目录下还没有 friends/index.md 文件，那么你就需要新建一个，命令如下： hexo new page \"friends\" 编辑你刚刚新建的页面文件 /source/friends/index.md，至少需要以下内容： --- title: friends date: 2018-12-12 21:25:30 type: \"friends\" layout: \"friends\" --- 同时，在你的博客 source 目录下新建 _data 目录，在 _data 目录中新建 friends.json 文件，文件内容如下所示： [{ \"avatar\": \"http://image.luokangyuan.com/1_qq_27922023.jpg\", \"name\": \"码酱\", \"introduction\": \"我不是大佬，只是在追寻大佬的脚步\", \"url\": \"http://luokangyuan.com/\", \"title\": \"前去学习\" }, { \"avatar\": \"http://image.luokangyuan.com/4027734.jpeg\", \"name\": \"闪烁之狐\", \"introduction\": \"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬\", \"url\": \"https://blinkfox.github.io/\", \"title\": \"前去学习\" }, { \"avatar\": \"http://image.luokangyuan.com/avatar.jpg\", \"name\": \"ja_rome\", \"introduction\": \"平凡的脚步也可以走出伟大的行程\", \"url\": \"https://me.csdn.net/jlh912008548\", \"title\": \"前去学习\" }] 2.10 一级菜单导航配置配置基本菜单导航的名称、路径url和图标icon 菜单导航名称可以是中文也可以是英文(如：Index或主页) 图标icon 可以在Font Awesome 中查找 menu: Index: url: / icon: fas fa-home Tags: url: /tags icon: fas fa-tags Categories: url: /categories icon: fas fa-bookmark Archives: url: /archives icon: fas fa-archive About: url: /about icon: fas fa-user-circle Friends: url: /friends icon: fas fa-address-book 2.11 二级菜单配置方法如果你需要二级菜单则可以在原基本菜单导航的基础上如下操作 在需要添加二级菜单的一级菜单下添加children关键字(如:About菜单下添加children) 在children下创建二级菜单的 名称name,路径url和图标icon. 注意每个二级菜单模块前要加 -. 注意缩进格式 menu: Index: url: / icon: fas fa-home Tags: url: /tags icon: fas fa-tags Categories: url: /categories icon: fas fa-bookmark Archives: url: /archives icon: fas fa-archive About: url: /about icon: fas fa-user-circle-o Friends: url: /friends icon: fas fa-address-book Medias: icon: fas fa-list children: - name: Musics url: /musics icon: fas fa-music - name: Movies url: /movies icon: fas fa-film - name: Books url: /books icon: fas fa-book - name: Galleries url: /galleries icon: fas fa-image 执行 hexo clean &amp;&amp; hexo g 重新生成博客文件。 2.12 代码高亮由于 Hexo 自带的代码高亮主题显示不好看，所以主题中使用到了 hexo-prism-plugin 的 Hexo 插件来做代码高亮，安装命令如下： npm i -S hexo-prism-plugin 然后，修改 Hexo 根目录下 _config.yml 文件中 highlight.enable 的值为 false，并新增 prism 插件相关的配置，主要配置如下： highlight: enable: false prism_plugin: mode: 'preprocess' # realtime/preprocess theme: 'tomorrow' line_number: false # default false custom_css: 更多代码块优化详细内容请访问：http://luckyzmj.cn/posts/1b9a9e28.html 2.13 搜索本主题中还使用到了 hexo-generator-search 的 Hexo 插件来做内容搜索，安装命令如下： npm install hexo-generator-search --save 在 Hexo 根目录下的 _config.yml 文件中，新增以下的配置项： search: path: search.xml field: post 2.14 文章字数统计插件（建议安装）如果你想要在文章中显示文章字数、阅读时长信息，可以安装 hexo-wordcount 插件。 安装命令如下： npm i --save hexo-wordcount 然后只需在本主题下的 _config.yml 文件中，将各个文章字数相关的配置激活即可： postInfo: date: true update: false wordCount: false # 设置文章字数统计为 true. totalCount: false # 设置站点文章总字数统计为 true. min2read: false # 阅读时长. readCount: false # 阅读次数. 2.15 添加emoji表情支持（可选的）本主题新增了对emoji表情的支持，使用到了 hexo-filter-github-emojis 的 Hexo 插件来支持 emoji表情的生成，把对应的markdown emoji语法（::,例如：:smile:）转变成会跳跃的emoji表情，安装命令如下： npm install hexo-filter-github-emojis --save 在 Hexo 根目录下的 _config.yml 文件中，新增以下的配置项： githubEmojis: enable: true className: github-emoji inject: true styles: customEmojis: 2.16 添加 RSS 订阅支持（可选的）本主题中还使用到了hexo-generator-feed 的 Hexo 插件来做 RSS，安装命令如下： npm install hexo-generator-feed --save 在 Hexo 根目录下的 _config.yml 文件中，新增以下的配置项： feed: type: atom path: atom.xml limit: 20 hub: content: content_limit: 140 content_limit_delim: ' ' order_by: -date 执行 hexo clean &amp;&amp; hexo g 重新生成博客文件，然后在 public 文件夹中即可看到 atom.xml 文件，说明你已经安装成功了。 2.17 添加 DaoVoice 在线聊天功能（可选的）前往 DaoVoice 官网注册并且获取 app_id，并将 app_id 填入主题的 _config.yml 文件中。 2.18 添加 Tidio 在线聊天功能（可选的）前往 Tidio 官网注册并且获取 Public Key，并将 Public Key 填入主题的 _config.yml 文件中。 2.19 修改页脚页脚信息可能需要做定制化修改，而且它不便于做成配置信息，所以可能需要你自己去再修改和加工。修改的地方在主题文件的 /layout/_partial/footer.ejs 文件中，包括站点、使用的主题、访问量等。 2.20 修改社交链接在主题的 _config.yml 文件中，默认支持 QQ、GitHub 和邮箱等的配置，你可以在主题文件的 /layout/_partial/social-link.ejs 文件中，新增、修改你需要的社交链接地址，增加链接可参考如下代码： &lt;% if (theme.socialLink.github) { %&gt; &lt;a href=\"&lt;%= theme.socialLink.github %&gt;\" class=\"tooltipped\" target=\"_blank\" data-tooltip=\"访问我的GitHub\" data-position=\"top\" data-delay=\"50\"&gt; &lt;i class=\"fab fa-github\"&gt;&lt;/i&gt; &lt;/a&gt; &lt;% } %&gt; 其中，社交图标（如：fa-github）你可以在 Font Awesome 中搜索找到。以下是常用社交图标的标识，供你参考： Facebook: fab fa-facebook Twitter: fab fa-twitter Google-plus: fab fa-google-plus Linkedin: fab fa-linkedin Tumblr: fab fa-tumblr Medium: fab fa-medium Slack: fab fa-slack Sina Weibo: fab fa-weibo Wechat: fab fa-weixin QQ: fab fa-qq Zhihu: fab fa-zhihu 注意: 本主题中使用的 Font Awesome 版本为 5.11.0。 2.21 修改打赏的二维码图片在主题文件的 source/medias/reward 文件中，你可以替换成你的的微信和支付宝的打赏二维码图片。 2.22 配置音乐播放器（可选的）要支持音乐播放，在主题的 _config.yml 配置文件中激活music配置即可 # 是否在首页显示音乐 music: enable: true title: #非吸底模式有效 enable: true show: 听听音乐 server: netease #require music platform: netease, tencent, kugou, xiami, baidu type: playlist #require song, playlist, album, search, artist id: 503838841 #require song id / playlist id / album id / search keyword fixed: false # 开启吸底模式 autoplay: false # 是否自动播放 theme: '#42b983' loop: 'all' # 音频循环播放, 可选值: 'all', 'one', 'none' order: 'random' # 音频循环顺序, 可选值: 'list', 'random' preload: 'auto' # 预加载，可选值: 'none', 'metadata', 'auto' volume: 0.7 # 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效 listFolded: true # 列表默认折叠 提示： server可选netease（网易云音乐），tencent（QQ音乐），kugou（酷狗音乐），xiami（虾米音乐），baidu（百度音乐）。 type可选song（歌曲），playlist（歌单），album（专辑），search（搜索关键字），artist（歌手） id获取示例: 浏览器打开网易云音乐，点击我喜欢的音乐歌单，地址栏有一串数字，playlist的id即为这串数字。 2.23文章 Front-matter 介绍Front-matter 选项中的所有内容均为非必填的。但我仍然建议至少填写 title 和 date 的值。 配置选项 默认值 描述 title Markdown 的文件标题 文章标题，强烈建议填写此选项 date 文件创建时的日期时间 发布时间，强烈建议填写此选项，且最好保证全局唯一 author 根 _config.yml 中的 author 文章作者 img featureImages 中的某个值 文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径.如: http://xxx.com/xxx.jpg top true 推荐文章（文章是否置顶），如果 top 值为 true，则会作为首页推荐文章 cover false v1.0.2版本新增，表示该文章是否需要加入到首页轮播封面中 coverImg 无 v1.0.2版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片 password 无 文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 password 的值，该值必须是用 SHA256 加密后的密码，防止被他人识破。前提是在主题的 config.yml 中激活了 verifyPassword 选项 toc true 是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 config.yml 中激活了 toc 选项 mathjax false 是否开启数学公式支持 ，本文章是否开启 mathjax，且需要在主题的 _config.yml 文件中也需要开启才行 summary 无 文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要 categories 无 文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类 tags 无 文章标签，一篇文章可以多个标签 keywords 文章标题 文章关键字，SEO 时需要 reprintPolicy cc_by 文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个 注意: 如果 img 属性不填写的话，文章特色图会根据文章标题的 hashcode 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章都的特色图各有特色。 date 的值尽量保证每篇文章是唯一的，因为本主题中 Gitalk 和 Gitment 识别 id 是通过 date 的值来作为唯一标识的。 如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 _config.yml 中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：开源中国在线工具、chahuo、站长工具。 您可以在文章md文件的 front-matter 中指定 reprintPolicy 来给单个文章配置转载规则 以下为文章的 Front-matter 示例。最简示例 --- title: typora-vue-theme主题介绍 date: 2018-09-07 09:25:00 --- 最全示例 --- title: theme主题介绍 date: 2018-09-07 09:25:00 author: 赵奇 img: /source/images/xxx.jpg top: true cover: true coverImg: /images/1.jpg password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92 toc: false mathjax: false summary: 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要 categories: Markdown tags: - Typora - Markdown --- 2.24 自定制修改在本主题的 _config.yml 中可以修改部分自定义信息，有以下几个部分： 菜单 我的梦想 首页的音乐播放器和视频播放器配置 是否显示推荐文章名称和按钮配置 favicon 和 Logo 个人信息 TOC 目录 文章打赏信息 复制文章内容时追加版权信息 MathJax 文章字数统计、阅读时长 点击页面的’爱心’效果 我的项目 我的技能 我的相册 Gitalk、Gitment、Valine 和 disqus 评论配置 不蒜子统计和谷歌分析（Google Analytics） 默认特色图的集合。当文章没有设置特色图时，本主题会根据文章标题的 hashcode 值取余，来选择展示对应的特色图 我认为个人博客应该都有自己的风格和特色。如果本主题中的诸多功能和主题色彩你不满意，可以在主题中自定义修改，很多更自由的功能和细节点的修改难以在主题的 _config.yml 中完成，需要修改源代码才来完成。以下列出了可能对你有用的地方：修改主题颜色 在主题文件的 /source/css/matery.css 文件中，搜索 .bg-color 来修改背景颜色： /* 整体背景颜色，包括导航、移动端的导航、页尾、标签页等的背景颜色. */ .bg-color { background-image: linear-gradient(to right, #4cbf30 0%, #0f9d58 100%); } @-webkit-keyframes rainbow { /* 动态切换背景颜色. */ } @keyframes rainbow { /* 动态切换背景颜色. */ } body { /* background-color: #eaeaea; */ /* 增加背景壁纸*/ background: url(\"https://ae01.alicdn.com/kf/H18a4b998752a4ae68b8e85d432a5aef0l.png\"), url(\"http://luckyzmj.cn/img/yun.jpg\") 0px 0px; background-attachment: fixed; margin: 0; color: #34495e; } 2.25 修改 banner 图和文章特色图你可以直接在 /source/medias/banner 文件夹中更换你喜欢的 banner 图片，主题代码中是每天动态切换一张，只需 7 张即可。如果你会 JavaScript 代码，可以修改成你自己喜欢切换逻辑，如：随机切换等，banner 切换的代码位置在 /layout/_partial/bg-cover-content.ejs 文件的 &lt;script&gt;&lt;/script&gt; 代码中： $('.bg-cover').css('background-image', 'url(/medias/banner/' + new Date().getDay() + '.jpg)'); 在 /source/medias/featureimages 文件夹中默认有 24 张特色图片，你可以再增加或者减少，并需要在 _config.yml 做同步修改。 2.26 优化目录栏在 themes\\Matery\\layout\\_partial\\post-detail-toc.ejs，修改内容如下： .toc-widget { padding-left: 20px; width: 345px; background-color: rgb(255, 255, 255,0.7); border-radius: 10px; box-shadow: 0 10px 35px 2px rgba(0, 0, 0, .15), 0 5px 15px rgba(0, 0, 0, .07), 0 2px 5px -5px rgba(0, 0, 0, .1) !important; } #toc-content { margin-bottom: 20px; } 0x005 更多详细教程以下几篇文章都是基于Hexo框架和hexo-theme-matery主题优化的教程，大家如果遇到问题，可以参考其中的方法。 Hexo+Github博客搭建完全教程 hexo-theme-matery作者教程 Hexo+github搭建博客(超级详细版，精细入微) hexo（matery）背景、滚动条优化+增加点击跳评论","categories":[{"name":"博客篇","slug":"博客篇","permalink":"https://macongmc.github.io/categories/%E5%8D%9A%E5%AE%A2%E7%AF%87/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://macongmc.github.io/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"https://macongmc.github.io/tags/Github/"},{"name":"博客","slug":"博客","permalink":"https://macongmc.github.io/tags/%E5%8D%9A%E5%AE%A2/"}],"author":"Luckey"}],"categories":[{"name":"docker","slug":"docker","permalink":"https://macongmc.github.io/categories/docker/"},{"name":"Linux","slug":"Linux","permalink":"https://macongmc.github.io/categories/Linux/"},{"name":"全文检索","slug":"全文检索","permalink":"https://macongmc.github.io/categories/%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/"},{"name":"mysql","slug":"mysql","permalink":"https://macongmc.github.io/categories/mysql/"},{"name":"sql","slug":"sql","permalink":"https://macongmc.github.io/categories/sql/"},{"name":"流","slug":"流","permalink":"https://macongmc.github.io/categories/%E6%B5%81/"},{"name":"Git","slug":"Git","permalink":"https://macongmc.github.io/categories/Git/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://macongmc.github.io/categories/RabbitMQ/"},{"name":"消息队列","slug":"消息队列","permalink":"https://macongmc.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"消息队列/RabbitMQ","permalink":"https://macongmc.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RabbitMQ/"},{"name":"Redis","slug":"Redis","permalink":"https://macongmc.github.io/categories/Redis/"},{"name":"分布式缓存","slug":"Redis/分布式缓存","permalink":"https://macongmc.github.io/categories/Redis/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"name":"持续集成","slug":"持续集成","permalink":"https://macongmc.github.io/categories/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"xxl-job","slug":"xxl-job","permalink":"https://macongmc.github.io/categories/xxl-job/"},{"name":"工具篇","slug":"工具篇","permalink":"https://macongmc.github.io/categories/%E5%B7%A5%E5%85%B7%E7%AF%87/"},{"name":"分布式事务","slug":"分布式事务","permalink":"https://macongmc.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"API","slug":"API","permalink":"https://macongmc.github.io/categories/API/"},{"name":"延时任务","slug":"延时任务","permalink":"https://macongmc.github.io/categories/%E5%BB%B6%E6%97%B6%E4%BB%BB%E5%8A%A1/"},{"name":"SDK","slug":"SDK","permalink":"https://macongmc.github.io/categories/SDK/"},{"name":"博客篇","slug":"博客篇","permalink":"https://macongmc.github.io/categories/%E5%8D%9A%E5%AE%A2%E7%AF%87/"},{"name":"前端篇","slug":"前端篇","permalink":"https://macongmc.github.io/categories/%E5%89%8D%E7%AB%AF%E7%AF%87/"}],"tags":[{"name":"容器","slug":"容器","permalink":"https://macongmc.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"linux","slug":"linux","permalink":"https://macongmc.github.io/tags/linux/"},{"name":"搜索引擎","slug":"搜索引擎","permalink":"https://macongmc.github.io/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"},{"name":"mysql","slug":"mysql","permalink":"https://macongmc.github.io/tags/mysql/"},{"name":"sql","slug":"sql","permalink":"https://macongmc.github.io/tags/sql/"},{"name":"java","slug":"java","permalink":"https://macongmc.github.io/tags/java/"},{"name":"git","slug":"git","permalink":"https://macongmc.github.io/tags/git/"},{"name":"消息队列","slug":"消息队列","permalink":"https://macongmc.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"API","slug":"API","permalink":"https://macongmc.github.io/tags/API/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://macongmc.github.io/tags/Jenkins/"},{"name":"多版本jdk","slug":"多版本jdk","permalink":"https://macongmc.github.io/tags/%E5%A4%9A%E7%89%88%E6%9C%ACjdk/"},{"name":"api","slug":"api","permalink":"https://macongmc.github.io/tags/api/"},{"name":"计算","slug":"计算","permalink":"https://macongmc.github.io/tags/%E8%AE%A1%E7%AE%97/"},{"name":"事务","slug":"事务","permalink":"https://macongmc.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"springcloud alibaba","slug":"springcloud-alibaba","permalink":"https://macongmc.github.io/tags/springcloud-alibaba/"},{"name":"kafka","slug":"kafka","permalink":"https://macongmc.github.io/tags/kafka/"},{"name":"redis","slug":"redis","permalink":"https://macongmc.github.io/tags/redis/"},{"name":"word","slug":"word","permalink":"https://macongmc.github.io/tags/word/"},{"name":"html","slug":"html","permalink":"https://macongmc.github.io/tags/html/"},{"name":"阿里云","slug":"阿里云","permalink":"https://macongmc.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"内容安全","slug":"内容安全","permalink":"https://macongmc.github.io/tags/%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8/"},{"name":"机审核","slug":"机审核","permalink":"https://macongmc.github.io/tags/%E6%9C%BA%E5%AE%A1%E6%A0%B8/"},{"name":"存储","slug":"存储","permalink":"https://macongmc.github.io/tags/%E5%AD%98%E5%82%A8/"},{"name":"工具使用","slug":"工具使用","permalink":"https://macongmc.github.io/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"},{"name":"sdk","slug":"sdk","permalink":"https://macongmc.github.io/tags/sdk/"},{"name":"aop","slug":"aop","permalink":"https://macongmc.github.io/tags/aop/"},{"name":"注解","slug":"注解","permalink":"https://macongmc.github.io/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"映射","slug":"映射","permalink":"https://macongmc.github.io/tags/%E6%98%A0%E5%B0%84/"},{"name":"hexo-blog-lucky","slug":"hexo-blog-lucky","permalink":"https://macongmc.github.io/tags/hexo-blog-lucky/"},{"name":"博客搭建教程","slug":"博客搭建教程","permalink":"https://macongmc.github.io/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"},{"name":"jQuery+CSS3","slug":"jQuery-CSS3","permalink":"https://macongmc.github.io/tags/jQuery-CSS3/"},{"name":"粒子特效","slug":"粒子特效","permalink":"https://macongmc.github.io/tags/%E7%B2%92%E5%AD%90%E7%89%B9%E6%95%88/"},{"name":"PicGo","slug":"PicGo","permalink":"https://macongmc.github.io/tags/PicGo/"},{"name":"GitHub图床","slug":"GitHub图床","permalink":"https://macongmc.github.io/tags/GitHub%E5%9B%BE%E5%BA%8A/"},{"name":"Hexo","slug":"Hexo","permalink":"https://macongmc.github.io/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"https://macongmc.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Github","slug":"Github","permalink":"https://macongmc.github.io/tags/Github/"}]}